@article{akada2025bring,
    author = {Akada, Hiroyasu and Wang, Jian and Golyanik, Vladislav and Theobalt, Christian},
    title = {Bring Your Rear Cameras for Egocentric 3D Human Pose Estimation},
    year = {2025},
    month = mar,
    day = {14},
    eprint = {2503.11652},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    doi = {10.48550/arXiv.2503.11652},
    url = {https://doi.org/10.48550/arXiv.2503.11652},
    abstract = {Egocentric 3D human pose estimation has been actively studied using cameras installed in front of a head-mounted device (HMD). While frontal placement is the optimal and the only option for some tasks, such as hand tracking, it remains unclear if the same holds for full-body tracking due to self-occlusion and limited field-of-view coverage. Notably, even the state-of-the-art methods often fail to estimate accurate 3D poses in many scenarios, such as when HMD users tilt their heads upward (a common motion in human activities). A key limitation of existing HMD designs is their neglect of the back of the body, despite its potential to provide crucial 3D reconstruction cues. Hence, this paper investigates the usefulness of rear cameras in the HMD design for full-body tracking. We also show that simply adding rear views to the frontal inputs is not optimal for existing methods due to their dependence on individual 2D joint detectors without effective multi-view integration. To address this issue, we propose a new transformer-based method that refines 2D joint heatmap estimation with multi-view information and heatmap uncertainty, thereby improving 3D pose tracking. Moreover, we introduce two new large-scale datasets, Ego4View-Syn and Ego4View-RW, for a rear-view evaluation. Our experiments show that the new camera configurations with back views provide superior support for 3D pose tracking compared to only frontal placements. The proposed method achieves significant improvement over the current state of the art (>10% on MPJPE). We will release the source code, trained models, and new datasets on our project page this https URL.},
    keywords = {Computer Vision and Pattern Recognition, cs.CV, Egocentric 3D human pose estimation, HMD, rear cameras, transformer-based method, multi-view integration},
    note = {arXiv:2503.11652v1 [cs.CV]},
    publisher = {arXiv},
    howpublished = {arXiv preprint},
    pages = {1--9302},
    numpages = {9302},
    journal = {arXiv preprint arXiv:2503.11652}
}
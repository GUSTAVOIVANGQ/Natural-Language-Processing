Clase	Etiqueta	Descripción	Distribución
0	"No Odio" (No Hate)	Contenido sin discurso de odio	86.2% (3,448 muestras)
1	"Discurso Odio" (Hate Speech)	Contenido que contiene discurso de odio	13.8% (552 muestras)

[TABLA 1: Visión General de la Configuración Experimental]
Componente	Opciones	Combinaciones Totales
Tipos de Normalización	7 estrategias	7
Algoritmos de ML	4 modelos	4
Vectorización	3 técnicas	3
Rango de N-gramas	3 configuraciones	3
Total de Experimentos	Por tipo de normalización	36
Gran Total	Todas las combinaciones	252

[TABLA 2: Mejores Resultados por Estrategia de Normalización]
Ranking	Tipo de Normalización	Mejor Modelo	Vectorización	N-gramas	F1-Macro	Media CV ± Desv. Est.
1	Tokenización	SVM	Frecuencia	(1,1)	0.7206	0.7025 ± 0.0176
2	Stopwords	SVM	Frecuencia	(1,1)	0.7152	0.7070 ± 0.0068
3	Tokenización + Stopwords	SVM	Frecuencia	(1,1)	0.7152	0.7070 ± 0.0068
4	Lemmatización	SVM	Binario	(1,1)	0.7031	0.6756 ± 0.0151
5	Tokenización + Lemmatización	SVM	Binario	(1,1)	0.7031	0.6756 ± 0.0151
6	Pipeline Completo	SVM	Binario	(1,1)	0.6888	0.6944 ± 0.0110
7	Stopwords + Lemmatización	SVM	Binario	(1,1)	0.6888	0.6944 ± 0.0110

[TABLA 3: Comparación de Rendimiento de Algoritmos (Mejores Configuraciones)]
Algoritmo	Mejor F1-Macro	Mejor Vectorización	N-gramas Óptimos	Frecuencia de Mejores Resultados
SVM	0.7206	Frecuencia/Binario	(1,1)	7/7 tipos de normalización
Regresión Logística	0.6950	TF-IDF	(1,1)	0/7 tipos de normalización
Random Forest	0.6820	Frecuencia	(1,1)	0/7 tipos de normalización
Naive Bayes	0.6750	TF-IDF	(1,1)	0/7 tipos de normalización

[TABLA 4: Métricas Detalladas de Rendimiento]
Métrica	Valor	Interpretación
F1-Score Macro	0.7206	Rendimiento equilibrado entre clases
Precisión	0.8840	Precisión general de predicción
Precisión Macro	0.7180	Precisión promedio entre clases
Recall Macro	0.7240	Recall promedio entre clases
Media CV	0.7025	Estabilidad de validación cruzada
Desv. Est. CV	0.0176	Baja varianza indica modelo robusto

[TABLA 5: Resultados de Validación Cruzada de 5 Pliegues (Mejor Modelo)]
Pliegue	F1-Macro	Precisión	Notas
1	0.7180	0.8867	Rendimiento consistente
2	0.7250	0.8900	Mejor resultado de pliegue
3	0.6980	0.8800	Ligera variación
4	0.7100	0.8833	Rendimiento estable
5	0.7015	0.8850	Dentro del rango esperado
Media	0.7105	0.8850	Modelo robusto
Desv. Est.	0.0110	0.0035	Baja varianza

[TABLA 6: Resumen de Rendimiento de LLM]
Modelo	Precisión	F1-Macro	Precisión Macro	Recall Macro	F1-Ponderado	Tiempo de Entrenamiento
RoBERTa	0.89	0.76	0.77	0.75	0.89	~4 min
BERT	0.88	0.75	0.75	0.74	0.88	~3 min
ELECTRA	0.88	0.64	0.80	0.61	0.85	~3 min

[TABLA 7: Análisis de Rendimiento por Clase]
RoBERTa (Mejor Modelo)
Clase	Precisión	Recall	F1-Score	Soporte
Discurso de Odio	0.61	0.56	0.58	138
Sin Odio	0.93	0.94	0.94	862
Macro Promedio	0.77	0.75	0.76	1000
Promedio Ponderado	0.89	0.89	0.89	1000

BERT (Segundo Mejor)
Clase	Precisión	Recall	F1-Score	Soporte
Discurso de Odio	0.58	0.55	0.57	138
Sin Odio	0.93	0.94	0.93	862
Macro Promedio	0.75	0.74	0.75	1000
Promedio Ponderado	0.88	0.88	0.88	1000

ELECTRA (Tercero)
Clase	Precisión	Recall	F1-Score	Soporte
Discurso de Odio	0.72	0.22	0.34	138
Sin Odio	0.89	0.99	0.93	862
Macro Promedio	0.80	0.61	0.64	1000
Promedio Ponderado	0.87	0.88	0.85	1000

[TABLA 8: Análisis de Convergencia de Entrenamiento]
Modelo	Mejor Época	Pérdida de Entrenamiento	F1 de Validación	Parada Temprana	Estabilidad
RoBERTa	3	0.156	0.76	No	Alta
BERT	3	0.168	0.75	No	Alta
ELECTRA	4	0.142	0.64	No	Moderada

[TABLA 9: Comparación General de Rendimiento]
Enfoque	Mejor Modelo	F1-Macro	Precisión	Ventaja Clave	Limitación
ML Tradicional	SVM + Tokenización	0.72	0.88	Entrenamiento rápido, interpretable	Comprensión de contexto limitada
LLMs	RoBERTa ajustado	0.76	0.89	Comprensión contextual	Mayor costo computacional
Mejora	+4 puntos porcentuales	+0.04	+0.01	Mejor análisis semántico	Intensivo en recursos

[TABLA 10: Análisis de Mejora del Rendimiento]
Métrica	ML Tradicional	LLMs	Mejora	Ganancia Porcentual
F1-Macro	0.7206	0.7600	+0.0394	+5.47%
Precisión	0.8840	0.8900	+0.0060	+0.68%
Precisión (Odio)	0.6500	0.6100	-0.0400	-6.15%
Recall (Odio)	0.6200	0.5600	-0.0600	-9.68%

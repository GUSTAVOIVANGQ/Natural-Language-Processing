DOI,Titulo_Tokens,Abstract_Tokens,Autores,Fecha,Seccion
10.48550./arXiv.2504.08736,gigatok scale visual tokenizer billion parameter autoregressive image generation,autoregressive ar image generation visual tokenizer compress image compact discrete latent token enable efficient training downstream autoregressive model visual generation next token prediction scale visual tokenizer improve image reconstruction quality often degrade downstream generation quality challenge not adequately address exist literature to address introduce gigatok first approach to simultaneously improve image reconstruction generation representation learning scale visual tokenizer identify grow complexity latent space key factor reconstruction generation dilemma to mitigate propose semantic regularization align tokenizer feature semantically consistent feature pre train visual encoder constraint prevent excessive latent space complexity scale yield consistent improvement reconstruction downstream autoregressive generation build semantic regularization explore three key practice scale use tokenizer well scalability prioritize decoder scale expand encoder decoder employ entropy loss to stabilize training billion scale tokenizer scale parameter gigatok achieve state art performance reconstruction downstream generation downstream representation quality,"Tianwei Xiong, Jun Hao Liew, Zilong Huang, Jiashi Feng, Xihui Liu",11/04/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11652,bring Rear Cameras egocentric 3d Human Pose Estimation,egocentric 3d human pose estimation have be actively study use camera instal front head mount device HMD frontal placement be optimal only option task such hand tracking remain unclear same hold full body tracking due self occlusion limited field view coverage notably even state art method often fail to estimate accurate 3d pose many scenario such when HMD user tilt head upward common motion human activity key limitation exist HMD design be neglect back body potential to provide crucial 3d reconstruction cue hence paper investigate usefulness rear camera HMD design full body tracking also show simply add rear view frontal input be not optimal exist method dependence individual 2d joint detector effective multi view integration to address issue propose new transformer base method that refine 2D joint heatmap estimation multi view information heatmap uncertainty thereby improve 3d pose tracking moreover introduce two new large scale dataset ego4view syn ego4view RW rear view evaluation experiment show new camera configuration back view provide superior support 3d pose track compare only frontal placement propose method achieve significant improvement current state art > 10 MPJPE will release source code train model new dataset project page https url,"Hiroyasu Akada, Jian Wang, Vladislav Golyanik, Christian Theobalt",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11651,VGGT Visual Geometry Grounded Transformer,present VGGT feed forward neural network that directly infer key 3d attribute scene include camera parameter point map depth map 3d point track one few hundred view approach be step forward 3d computer vision where model have typically be constrain specialize single task be also simple efficient reconstruct image one second still outperform alternative that require post processing visual geometry optimization technique network achieve state art result multiple 3d task include camera parameter estimation multi view depth estimation dense point cloud reconstruction 3d point tracking also show use pretraine VGGT feature backbone significantly enhance downstream task such non rigid point tracking feed forward novel view synthesis code model be publicly available https url,"Jianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David Novotny",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11647,recammaster Camera Controlled Generative rendering Single video,camera control have be actively study text image condition video generation task however alter camera trajectory give video remain under explore importance field video creation be non trivial due extra constraint maintain multiple frame appearance dynamic synchronization to address present recammaster camera control generative video re render framework that reproduce dynamic scene input video novel camera trajectory core innovation lie harness generative capability pre train text video model simple yet powerful video conditioning mechanism capability often overlook current research to overcome scarcity qualified training datum construct comprehensive multi camera synchronized video dataset use Unreal Engine 5 which be carefully curate to follow real world filming characteristic cover diverse scene camera movement help model generalize wild video lastly far improve robustness to diverse input meticulously design training strategy extensive experiment tell method substantially outperform exist state art approach strong baseline method also find promising application video stabilization super resolution outpainte project page https url,"Jianhong Bai, Menghan Xia, Xiao Fu, Xintao Wang, Lianrui Mu, Jinwen Cao, Zuozhu Liu, Haoji Hu, Xiang Bai, Pengfei Wan, Di Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11633,see see Glass real Synthetic Data Multi layer Depth estimation,"transparent object be common daily life understand multi layer depth information perceive both transparent surface object be crucial real world application that interact transparent material paper introduce LayeredDepth first dataset multi layer depth annotation include real world benchmark synthetic data generator to support task multi layer depth estimation real world benchmark consist 1,500 image diverse scene evaluate state art depth estimation method reveal struggle transparent object synthetic datum generator be fully procedural capable provide training datum task unlimited variety object scene composition use generator create synthetic dataset 15,300 image baseline model train solely synthetic dataset produce good cross domain multi layer depth estimation fine tune state art single layer depth model substantially improve performance transparent object quadruplet accuracy benchmark increase 55.14 75.20 image validation annotation be available CC0 https url","Hongyu Wen, Yiming Zuo, Venkat Subramanian, Patrick Chen, Jia Deng",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11609,rethink Few Shot Adaptation Vision Language Models two stage,old school recipe train classifier be i learn good feature extractor ii optimize linear layer atop when only handful sample be available category Few Shot Adaptation FSA datum be insufficient to fit large number parameter render above impractical be especially true large pre train Vision Language Models VLMs which motivate successful research intersection Parameter Efficient Fine tuning PEFT FSA work start analyze learn dynamic peft technique when train few shot datum only subset category refer ` ` base class show such dynamic naturally split two distinct phase i task level feature extraction ii specialization available concept to accommodate dynamic then depart prompt- adapter base method tackle FSA differently specifically give fix computational budget split i learn task specific feature extractor PEFT ii train linear classifier top call scheme two Stage Few Shot Adaptation 2sfs differently established method scheme enable novel form selective inference category level i.e. test time only novel category be embed adapt text encoder embedding base category be available classifier result fix hyperparameter two setting three backbone eleven dataset show 2sfs match surpass state art establish method degrade significantly setting,"Matteo Farina, Massimiliano Mancini, Giovanni Iacca, Elisa Ricci",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11601,advance 3d Gaussian Splatting Editing Complementary Consensus information,present novel framework enhance visual fidelity consistency text guide 3d Gaussian Splatting 3dgs editing exist editing approach face two critical challenge inconsistent geometric reconstruction multiple viewpoint particularly challenge camera position ineffective utilization depth information image manipulation result texture artifact degrade object boundary to address limitation introduce 1 complementary information mutual learning network that enhance depth map estimation 3dgs enable precise depth condition 3d editing preserve geometric structure 2 wavelet consensus attention mechanism that effectively align latent code diffusion denoising process ensure multi view consistency edit result extensive experimentation method demonstrate superior performance render quality view consistency compare state art approach result validate framework effective solution text guide editing 3d scene,"Xuanqi Zhang, Jieun Lee, Chris Joslin, Wonsook Lee",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11579,Vamba Understanding Hour Long Videos Hybrid Mamba transformer,state art transformer base large multimodal model LMMs struggle to handle hour long video input quadratic complexity causal self attention operation lead high computational cost training inference exist token compression base method reduce number video token often incur information loss remain inefficient extremely long sequence paper explore orthogonal direction to build hybrid Mamba Transformer model VAMBA that employ Mamba-2 block encode video token linear complexity token reduction VAMBA can encode more 1024 frame 640$\times$360 single GPU transformer base model can only encode 256 frame long video input VAMBA achieve least 50 reduction GPU memory usage training inference nearly double speed training step compare transformer base lmm experimental result demonstrate VAMBA improve accuracy 4.3 challenging hour long video understand benchmark LVBench prior efficient video LMMs maintain strong performance broad spectrum long short video understanding task,"Weiming Ren, Wentao Ma, Huan Yang, Cong Wei, Ge Zhang, Wenhu Chen",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11576,SmolDocling ultra compact vision language model end end multi modal document conversion,introduce SmolDocling ultra compact vision language model target end end document conversion model comprehensively process entire page generate DocTags new universal markup format that capture page element full context location exist approach that rely large foundational model ensemble solution that rely handcraft pipeline multiple specialized model SmolDocling offer end end conversion accurately capture content structure spatial location document element 256 M parameter vision language model SmolDocling exhibit robust performance correctly reproduce document feature such code listing table equation chart list more diverse range document type include business document academic paper technical report patent form significantly extend commonly observe focus scientific paper additionally contribute novel publicly source dataset chart table equation code recognition experimental result demonstrate SmolDocling compete other Vision Language Models that be up to 27 time large size reduce computational requirement substantially model be currently available dataset will be publicly available soon,"Ahmed Nassar, Andres Marafioti, Matteo Omenetti, Maksym Lysak, Nikolaos Livathinos, Christoph Auer, Lucas Morin, Rafael Teixeira de Lima, Yusik Kim, A. Said Gurbuz, Michele Dolfi, Miquel Farré, Peter W. J. Staar",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11571,RASA replace Anyone say anything training Free Framework Audio drive Universal Portrait Video editing,portrait video editing focus modify specific attribute portrait video guide audio video stream previous method typically concentrate lip region reenactment require train specialized model to extract keypoint motion transfer new identity paper introduce training free universal portrait video editing framework that provide versatile adaptable editing strategy framework support portrait appearance editing condition change first reference frame as well lip editing condition varied speech combination be base Unified Animation Control UAC mechanism source inversion latent to edit entire portrait include visual drive shape control audio drive speaking control inter frame temporal control furthermore method can be adapt different scenario adjust initial reference frame enable detailed editing portrait video specific head rotation facial expression comprehensive approach ensure holistic flexible solution portrait video editing experimental result show model can achieve more accurate synchronized lip movement lip edit task as well more flexible motion transfer appearance edit task demo be available https url,"Tianrui Pan, Lin Liu, Jie Liu, Xiaopeng Zhang, Jie Tang, Gangshan Wu, Qi Tian",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11565,disentangle Object Centric Image Representation Robotic Manipulation,learn robotic manipulation skill vision be promising approach develop robotic application that can generalize broadly real world scenario such many approach to enable vision have be explore fruitful result particularly object centric representation method have be show to provide well inductive bias skill learning lead improved performance generalization nonetheless show object centric method can struggle to learn simple manipulation skill multi object environment thus propose DOCIR object centric framework that introduce disentangle representation object interest obstacle robot embodiment show approach lead state art performance learn pick place skill visual input multi object environment generalize test time change object interest distractor scene furthermore show efficacy simulation zero shot transfer real world,"David Emukpere, Romain Deffayet, Bingbing Wu, Romain Brégier, Michael Niemaz, Jean-Luc Meunier, Denys Proux, Jean-Michel Renders, Seungsu Kim",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11557,verify Benchmark Visual Explanation Reasoning investigate Multimodal Reasoning Fidelity,visual reasoning be central human cognition enable individual to interpret abstractly understand environment recent Multimodal large Language Models MLLMs have demonstrate impressive performance language vision language task exist benchmark primarily measure recognition base skill inadequately assess true visual reasoning capability to bridge critical gap introduce VERIFY benchmark explicitly design to isolate rigorously evaluate visual reasoning capability state art mllm VERIFY compel model to reason primarily visual information provide minimal textual context to reduce reliance domain specific knowledge linguistic bias problem be accompany human annotate reasoning path make first to provide depth evaluation model decision make process additionally propose novel metric that assess visual reasoning fidelity mere accuracy highlight critical imbalance current model reasoning pattern comprehensive benchmarking lead MLLMs uncover significant limitation underscore need balanced holistic approach perception reasoning more teaser testing visit project page https url,"Jing Bi, Junjia Guo, Susan Liang, Guangyu Sun, Luchuan Song, Yunlong Tang, Jinxi He, Jiarui Wu, Ali Vosoughi, Chen Chen, Chenliang Xu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11549,similarity aware Token pruning vlm fast,computational demand Vision Transformers ViTs Vision Language Models VLMs remain significant challenge quadratic complexity self attention token pruning offer promising solution exist method often introduce training overhead fail to adapt dynamically layer present SAINT training free token pruning framework that leverage token similarity graph base formulation to dynamically optimize pruning rate redundancy threshold systematic analysis identify universal three stage token evolution process aligner explorer aggregator transformer enable aggressive pruning early stage sacrifice critical information ViTs SAINT double throughput ViT h/14 224px only 0.6 accuracy loss ImageNet-1 K surpass close competitor 0.8 vlm apply SAINT three mode ViT only LLM only hybrid SAINT reduce LLaVA-13B 's token 75 achieve latency comparable LLaVA-7B less 1 performance loss benchmark work establish unify practical framework efficient inference ViTs VLMs,"Ahmadreza Jeddi, Negin Baghbanzadeh, Elham Dolatabadi, Babak Taati",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11544,auggen Synthetic Augmentation can improve Discriminative model,increase dependence large scale dataset machine learning introduce significant privacy ethical challenge synthetic data generation offer promising solution however most current method rely external dataset pre train model which add complexity escalate resource demand work introduce novel self contain synthetic augmentation technique that strategically sample conditional generative model train exclusively target dataset approach eliminate need auxiliary datum source apply to face recognition dataset method achieve 1 -12\% performance improvement IJB C IJB B benchmark outperform model train solely real datum exceed performance state art synthetic datum generation baseline notably enhancement often surpass achieve architectural improvement underscore significant impact synthetic augmentation data scarce environment finding demonstrate carefully integrate synthetic datum not only address privacy resource constraint also substantially boost model performance project page https url,"Parsa Rahimi, Damien Teney, Sebastien Marcel",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11538,FLASHμ Fast Localizing Sizing Holographic microparticle,reconstruct 3d location size microparticle diffraction image hologram be computationally expensive inverse problem that have traditionally be solve use physics base reconstruction method more recently researcher have use machine learn method to speed up process however small particle large sample volume performance method fall short standard physics base reconstruction method here design two stage neural network architecture FLASH$\mu$ to detect small particle 6 100$\mu$m hologram large sample depth to 20 cm train only synthetic datum add physical noise method reliably detect particle at least 9$\mu$m diameter real hologram comparable standard reconstruction base approach operate small crop quarter original resolution provide roughly 600 fold speedup addition introduce novel approach non local object detection signal demixing problem work could enable low cost real time holographic imaging setup,"Ayush Paliwal, Oliver Schlenczek, Birte Thiede, Manuel Santos Pereira, Katja Stieger, Eberhard Bodenschatz, Gholamhossein Bagheri, Alexander Ecker",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11519,explore typographic Visual Prompts Injection Threats Cross Modality Generation model,Current Cross Modality Generation Models GMs demonstrate remarkable capability various generative task give ubiquity information richness vision modality input real world scenario Cross vision encompass Vision Language Perception VLP image Image I2I task have attract significant attention large Vision Language Models lvlm I2I gm be employ to handle VLP I2I task respectively previous research indicate print typographic word input image significantly induce LVLMs I2I GMs to generate disruptive output semantically relate word additionally visual prompt more sophisticated form typography be also reveal to pose security risk various application VLP task when inject image paper comprehensively investigate performance impact induce Typographic Visual Prompt Injection TVPI various lvlm I2I GMs to well observe performance modification characteristic threat also introduce TVPI Dataset extensive exploration deepen understanding underlying cause tvpi threat various gm offer valuable insight potential origin,"Hao Cheng, Erjia Xiao, Yichi Wang, Kaidi Xu, Mengshu Sun, Jindong Gu, Renjing Xu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11513,HiTVideo Hierarchical Tokenizers enhance text Video Generation Autoregressive Large Language model,text video generation pose significant challenge inherent complexity video datum which span temporal spatial dimension introduce additional redundancy abrupt variation domain gap language vision token generation address challenge require effective video tokenizer that can efficiently encode video datum preserve essential semantic spatiotemporal information serve critical bridge text vision inspire observation VQ VAE-2 workflow traditional animation propose HiTVideo text video generation hierarchical tokenizer utilize 3d causal VAE multi layer discrete token framework encode video content hierarchically structure codebook high layer capture semantic information high compression low layer focus fine grain spatiotemporal detail strike balance compression efficiency reconstruction quality approach efficiently encode long video sequence e.g. 8 second 64 frame reduce bit pixel bpp approximately 70\% compare baseline tokenizer maintain competitive reconstruction quality explore trade off compression reconstruction emphasize advantage high compress semantic token text video task HiTVideo aim to address potential limitation exist video tokenizer text video generation task strive high compression ratio simplify llm modeling language guidance offer scalable promising framework advance text video generation demo page https url,"Ziqin Zhou, Yifan Yang, Yuqing Yang, Tianyu He, Houwen Peng, Kai Qiu, Qi Dai, Lili Qiu, Chong Luo, Lingqiao Liu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11498,Cloud2BIM open source automatic pipeline efficient conversion large scale point cloud IFC format,Building Information Modeling BIM be essential component sustainable reconstruction revitalization age structure however model creation usually rely laborious manual transformation unstructured point cloud datum provide laser scan photogrammetry paper present Cloud2BIM open source software tool design to automate conversion point cloud BIM model compliant Industry Foundation Classes IFC standard Cloud2BIM integrate advanced algorithm wall slab segmentation open detection room zoning base real wall surface result comprehensive fully automate workflow exist tool avoid computationally- calibration intensive technique such RANSAC support non orthogonal geometry provide unprecedented processing speed achieve result to seven time fast fast compete solution systematic validation use benchmark dataset confirm Cloud2BIM be easy use efficient scalable solution generate accurate bim model capable convert extensive point cloud dataset entire building IFC format minimal user input,"Slávek Zbirovský, Václav Nežerka",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11496,Cognitive Disentanglement Referring Multi object tracking,significant application multi source information fusion intelligent transportation perception system refer Multi object Tracking RMOT involve localize track specific object video sequence base language reference however exist RMOT approach often treat language description holistic embedding struggle to effectively integrate rich semantic information contain language expression visual feature limitation be especially apparent complex scene require comprehensive understanding static object attribute spatial motion information paper propose Cognitive Disentanglement Referring Multi object Tracking CDRMT framework that address challenge adapt what where pathway human visual processing system RMOT task specifically framework comprise three collaborative component 1)the Bidirectional Interactive Fusion module first establish cross modal connection preserve modality specific characteristic 2 build foundation Progressive Semantic decouple Query Learning mechanism hierarchically inject complementary information object query progressively refine object understanding coarse fine grain semantic level 3 finally Structural Consensus Constraint enforce bidirectional semantic consistency visual feature language description ensure track object faithfully reflect refer expression extensive experiment different benchmark dataset demonstrate CDRMT achieve substantial improvement state art method average gain 6.0 HOTA score Refer kitti 3.2 Refer KITTI V2 approach advance state art RMOT simultaneously provide new insight multi source information fusion,"Shaofeng Liang, Runwei Guan, Wangwang Lian, Daizong Liu, Xiaolou Sun, Dongming Wu, Yutao Yue, Weiping Ding, Hui Xiong",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11495,V STaR benchmarke Video LLMs Video Spatio Temporal Reasoning,human process video reasoning sequential spatio temporal reasoning logic first identify relevant frame when then analyse spatial relationship where key object finally leverage relationship to draw inference what however can video Large Language Models Video LLMs also reason sequential spatio temporal logic video exist video LLM benchmark primarily focus assess object presence neglect relational reasoning consequently be difficult to measure model truly comprehend object interaction action event video merely rely pre train memory co occurrence bias generate answer work introduce Video spatio Temporal Reasoning V STaR benchmark to address shortcoming key idea be to decompose video understanding Reverse spatio Temporal Reasoning RSTR task that simultaneously evaluate what object be present when event occur where be locate capture underlie chain thought CoT logic to support evaluation construct dataset to elicit spatial temporal reasoning process Video LLMs contain coarse fine cot question generate semi automated GPT-4 power pipeline embed explicit reasoning chain to mimic human cognition experiment 14 Video LLMs V STaR reveal significant gap current Video LLMs need robust consistent spatio temporal reasoning,"Zixu Cheng, Jian Hu, Ziquan Liu, Chenyang Si, Wei Li, Shaogang Gong",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11481,T2I FineEval Fine Grained Compositional Metric text Image Evaluation,recent text image generative model have achieve impressive performance still often struggle capture compositional complexity prompt include attribute bind spatial relationship different entity misalignment be not reveal common evaluation metric such CLIPScore recent work have propose evaluation metric that utilize Visual Question Answering VQA decompose prompt question generate image more robust compositional evaluation method align well human evaluation still fail to fully cover compositionality image to address propose novel metric that break down image component text fine grain question generate image evaluation method outperform previous state art metric demonstrate effectiveness evaluate text image generative model Code be available https URL T2I FineEval,"Seyed Mohammad Hadi Hosseini, Amir Mohammad Izadi, Ali Abdollahi, Armin Saghafian, Mahdieh Soleymani Baghshah",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11465,Remote Photoplethysmography Real World Extreme Lighting Scenarios,physiological activity can be manifest sensitive change facial imaging be barely observable eye computer vision manner can derive remote photoplethysmography rppg have show considerable promise however exist study mainly rely spatial skin recognition temporal rhythmic interaction focus identify explicit feature ideal light condition perform poorly wild intricate obstacle extreme illumination exposure paper propose end end video transformer model rppg strive to eliminate complex unknown external time vary interference be sufficient to occupy subtle biosignal amplitude exist periodic perturbation that hinder network training specific implementation utilize global interference sharing subject background reference self supervise disentanglement to eliminate interference far guide learn base spatiotemporal filtering reconstruction guidance frequency domain biological prior constraint to achieve effective rppg good knowledge be first robust rppg model real outdoor scenario base natural face video be lightweight to deploy extensive experiment show competitiveness performance model rppg prediction dataset scene,"Hang Shao, Lei Luo, Jianjun Qian, Mengkai Yan, Shuo Chen, Jian Yang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11439,COIN Confidence Score Guided Distillation Annotation Free Cell segmentation,cell instance segmentation CIS be crucial identify individual cell morphology histopathological image provide valuable insight biological medical research unsupervised CIS UCIS model aim to reduce heavy reliance labor intensive image annotation fail to accurately capture cell boundary cause miss detection poor performance recognize absence error free instance key limitation present COIN COnfidence score guide INstance distillation novel annotation free framework three key step 1 increase sensitivity presence error free instance unsupervised semantic segmentation optimal transport leverage ability to discriminate spatially minor instance 2 instance level confidence scoring to measure consistency model prediction refined mask identify highly confident instance offer alternative ground truth annotation 3 progressive expansion confidence recursive self distillation extensive experiment six dataset show COIN outperform exist ucis method even surpass semi- weakly supervise approach metric MoNuSeg tnbc dataset code be available https url,"Sanghyun Jo, Seo Jin Lee, Seungwoo Lee, Seohyung Hong, Hyungseok Seo, Kyungsu Kim",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11423,TASTE Rob advance Video Generation Task orient Hand Object Interaction Generalizable Robotic Manipulation,"address key limitation exist dataset model task orient hand object interaction video generation critical approach generate video demonstration robotic imitation learning current dataset such Ego4D often suffer inconsistent view perspective misaligned interaction lead reduce video quality limit applicability precise imitation learning task end introduce TASTE Rob pioneer large scale dataset 100,856 ego centric hand object interaction video video be meticulously align language instruction record consistent camera viewpoint to ensure interaction clarity fine tune Video Diffusion Model VDM TASTE Rob achieve realistic object interaction observe occasional inconsistency hand grasping posture to enhance realism introduce three stage pose refinement pipeline that improve hand posture accuracy generate video curate dataset couple specialized pose refinement framework provide notable performance gain generate high quality task orient hand object interaction video result achieve superior generalizable robotic manipulation TASTE Rob dataset will be make publicly available publication to foster further advancement field","Hongxiang Zhao, Xingchen Liu, Mutian Xu, Yiming Hao, Weikai Chen, Xiaoguang Han",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11412,MTV Inpaint Multi Task Long Video inpainte,video inpainte involve modify local region video ensure spatial temporal consistency Most exist method focus primarily scene completion i.e. fill missing region lack capability to insert new object scene controllable manner fortunately recent advancement text video T2V diffusion model pave way text guide video inpainting however directly adapt T2V model inpainte remain limited unify completion insertion task lack input controllability struggle long video thereby restrict applicability flexibility to address challenge propose MTV Inpaint unified multi task video inpainte framework capable handle traditional scene completion novel object insertion task to unify distinct task design dual branch spatial attention mechanism T2V diffusion U net enable seamless integration scene completion object insertion single framework addition textual guidance MTV Inpaint support multimodal control integrate various image inpainte model propose image video i2v inpainte mode additionally propose two stage pipeline that combine keyframe inpainte between frame propagation enable MTV Inpaint to effectively handle long video hundred frame extensive experiment demonstrate MTV Inpaint achieve state art performance scene completion object insertion task furthermore demonstrate versatility derive application such multi modal inpainting object editing removal image object brush ability to handle long video project page https url,"Shiyuan Yang, Zheng Gu, Liang Hou, Xin Tao, Pengfei Wan, Xiaodong Chen, Jing Liao",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11409,LuSeg Efficient Negative Positive Obstacles Segmentation Contrast drive Multi modal Feature Fusion Lunar,"lunar exploration mission grow increasingly complex ensure safe autonomous rover base surface exploration have become one key challenge lunar exploration task work have develop lunar surface simulation system call Lunar Exploration Simulator System LESS LunarSeg dataset which provide rgb d datum lunar obstacle segmentation that include positive negative obstacle additionally propose novel two stage segmentation network call LuSeg contrastive learning enforce semantic consistency RGB encoder Stage depth encoder Stage II experimental result propose LunarSeg dataset additional public real world NPO road obstacle dataset demonstrate LuSeg achieve state art segmentation performance positive negative obstacle maintain high inference speed approximately 57\,hz have release implementation LESS system LunarSeg dataset code LuSeg https url","Shuaifeng Jiao, Zhiwen Zeng, Zhuoqun Su, Xieyuanli Chen, Zongtan Zhou, Huimin Lu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11400,Framework capability drive Evaluation Scenario Understanding Multimodal Large Language Models Autonomous Driving,multimodal large language model mllm hold potential to enhance autonomous driving combine domain independent world knowledge context specific language guidance integration autonomous driving system show promise result isolated proof concept application performance be evaluate selective singular aspect perception reasoning planning to leverage full potential systematic framework evaluate mllm context autonomous driving be require paper propose holistic framework capability drive evaluation MLLMs autonomous driving framework structure scenario understanding four core capability dimension semantic spatial temporal physical be derive general requirement autonomous driving system human driver cognition language base reasoning far organise domain context layer processing modality downstream task such language base interaction decision making to illustrate framework 's applicability two exemplary traffic scenario be analyse ground propose dimension realistic driving situation framework provide foundation structured evaluation mllm potential scenario understanding autonomous driving,"Tin Stribor Sohn, Philipp Reis, Maximilian Dillitzer, Johannes Bach, Jason J. Corso, Eric Sax",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11392,watch learn leverage Expert Knowledge Language Surgical Video understanding,automated surgical workflow analysis be crucial education research clinical decision making lack annotated dataset hinder development accurate comprehensive workflow analysis solution introduce novel approach address sparsity heterogeneity annotated training datum inspire human learn procedure watch expert understand explanation method leverage video language model train alignment denoising generative task to learn short term spatio temporal multimodal representation task specific temporal model be then use to capture relationship entire video to achieve comprehensive video language understanding surgical domain introduce data collection filtering strategy to construct large scale pretraining dataset educational YouTube video then utilize parameter efficient fine tuning project downstream task annotation publicly available surgical dataset language domain extensive experiment two surgical domain demonstrate effectiveness approach performance improvement to 7 phase segmentation task 8 zero shot phase segmentation comparable capability fully supervise model few shot setting harness model 's capability long range temporal localization text generation present first comprehensive solution dense video captioning DVC surgical video address task absence exist dvc dataset surgical domain introduce novel approach surgical workflow understanding that leverage video language pretraining large scale video pretraining optimize fine tuning method improve performance state art technique enable new downstream task surgical video understanding,"David Gastager, Ghazal Ghazaei, Constantin Patsch",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11389,Deepfake Detection Face Images base Convolutional Neural Network,Fake News especially deepfake generate non real image video content have become serious topic last year emergence machine learning algorithm be now easy ever before to generate such fake content even private person issue generate fake image be especially critical context politic public figure want to address conflict build model base Convolutions Neural Network order to detect such generate fake image show human portrait basis use pre train ResNet-50 model effectiveness term classify image then adopt base model task classify single image authentic real fake add fully connect output layer contain single neuron indicate authenticity image apply fine tuning transfer learning to develop model improve parameter training process collect image datum set Diverse Face Fake Dataset contain wide range different image manipulation method also diversity term face visible image final model reach follow outstanding performance metric precision = 0.98 recall 0.96 F1 score = 0.97 area curve = 0.99,"Lukas Kroiß, Johannes Reschke",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11371,emotive event guide Trajectory Modeling 3d Motion Estimation,visual 3d motion estimation aim to infer motion 2D pixel 3d space base visual cue key challenge arise depth variation induce spatio temporal motion inconsistency disrupt assumption local spatial temporal motion smoothness previous motion estimation framework contrast event camera offer new possibility 3d motion estimation continuous adaptive pixel level response to scene change paper present emotive novel event base framework that model spatio temporal trajectory event guide non uniform parametric curve effectively characterize locally heterogeneous spatio temporal motion specifically first introduce Event Kymograph event projection method that leverage continuous temporal projection kernel decouple spatial observation to encode fine grain temporal evolution explicitly motion representation introduce density aware adaptation mechanism to fuse spatial temporal feature event guidance couple non uniform rational curve parameterization framework to adaptively model heterogeneous trajectory final 3d motion estimation be achieve multi temporal sampling parametric trajectory yield optical flow depth motion field to facilitate evaluation introduce carlaevent3d multi dynamic synthetic dataset comprehensive validation extensive experiment dataset real world benchmark demonstrate effectiveness propose method,"Zengyu Wan, Wei Zhai, Yang Cao, Zhengjun Zha",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11368,PBR3DGen VLM guide Mesh Generation high quality PBR texture,generate high quality physically base render PBR material be important to achieve realistic rendering downstream task remain challenge intertwine effect material lighting existing method have make breakthrough incorporate material decomposition 3d generation pipeline tend to bake highlight albedo ignore spatially vary property metallicity roughness work present PBR3DGen two stage mesh generation method high quality PBR material that integrate novel multi view PBR material estimation model 3d PBR mesh reconstruction model specifically PBR3DGen leverage vision language model VLM to guide multi view diffusion precisely capture spatial distribution inherent attribute reflective metalness material additionally incorporate view dependent illumination aware condition pixel aware prior to enhance spatially vary material property furthermore reconstruction model reconstruct high quality mesh PBR material experimental result demonstrate PBR3DGen significantly outperform exist method achieve new state art result PBR estimation mesh generation More result visualization can be find project page https url,"Xiaokang Wei, Bowen Zhang, Xianghui Yang, Yuxuan Wang, Chunchao Guo, Xi Zhao, Yan Luximon",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11360,paric Probabilistic Attention Regularization Language Guided Image Classification Pre train Vison Language model,language guide attention framework have significantly enhance interpretability performance image classification however reliance deterministic embedding pre train vision language foundation model to generate reference attention map frequently overlook intrinsic multivaluedness ill pose characteristic cross modal mapping to address limitation introduce PARIC probabilistic framework guide visual attention language specification approach enable pre train vision language model to generate probabilistic reference attention map which align textual visual modality more effectively incorporate uncertainty estimate compare deterministic counterpart experiment benchmark test problem demonstrate paric enhance prediction accuracy mitigate bias ensure consistent prediction improve robustness various dataset,"Mayank Nautiyal, Stela Arranz Gheorghe, Kristiana Stefa, Li Ju, Ida-Maria Sintorn, Prashant Singh",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11345,EgoSplat open Vocabulary Egocentric Scene understand Language embed 3d Gaussian Splatting,egocentric scene exhibit frequent occlusion varied viewpoint dynamic interaction compare typical scene understand task occlusion varied viewpoint can lead multi view semantic inconsistency dynamic object may act transient distractor introduce artifact semantic feature modeling to address challenge propose EgoSplat language embed 3d Gaussian Splatting framework open vocabulary egocentric scene understanding multi view consistent instance feature aggregation method be design to leverage segmentation tracking capability SAM2 to selectively aggregate complementary feature view instance ensure precise semantic representation scene additionally instance aware spatial temporal transient prediction module be construct to improve spatial integrity temporal continuity prediction incorporate spatial temporal association multi view instance effectively reduce artifact semantic reconstruction egocentric scene EgoSplat achieve state art performance localization segmentation task two dataset outperform exist method 8.2 improvement localization accuracy 3.7 improvement segmentation miou ADT dataset set new benchmark open vocabulary egocentric scene understanding code will be make publicly available,"Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Guangming Shi, Licheng Jiao",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11342,road Rage reasoning Vision language Models VLMs Task Definition Evaluation Dataset,road rage trigger driving relate stimulus such traffic congestion aggressive driving pose significant threat road safety previous research road rage regulation have primarily focus response suppression lack proactive prevention capability advent Vision Language Models VLMs have become possible to reason trigger event visually then engage dialog base comfort driver anger escalate end propose road rage reasoning task finely annotate test dataset evaluation metric to assess capability current mainstream vlm scene understanding event recognition road rage reasoning result indicate current vlm exhibit significant shortcoming scene understanding visual modality as well comprehend spatial relationship object textual modality improve vlm performance area will greatly benefit downstream task antecedent focus road rage regulation,"Yibing Weng, Yu Gu, Fuji Ren",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11341,self supervise pretraining Fine Grained Plankton Recognition,Plankton recognition be important computer vision problem plankton 's essential role ocean food webs carbon capture highlight need species level monitoring however task be challenge fine grain nature dataset shift cause different imaging instrument vary specie distribution new plankton image dataset be collect increase pace there be need general plankton recognition model that require minimal expert effort datum labeling work study large scale self supervise pretraining fine grain plankton recognition first employ mask autoencoding large volume diverse plankton image datum to pretrain general purpose plankton image encoder then utilize fine tuning to obtain accurate plankton recognition model new dataset very limited number label training image experiment show self supervise pretraining diverse plankton datum clearly increase plankton recognition accuracy compare standard ImageNet pretraining when amount training datum be limited moreover accuracy can be far improve when unlabeled target datum be available utilize pretraining,"Joona Kareinen, Tuomas Eerola, Kaisa Kraft, Lasse Lensu, Sanna Suikkanen, Heikki Kälviäinen",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11335,APLA Simple Adaptation Method Vision Transformers,exist adaptation technique typically require architectural modification add parameter lead high computational cost complexity introduce Attention Projection Layer Adaptation APLA simple approach to adapt vision transformer ViTs alter architecture add parameter systematic analysis find layer immediately attention mechanism be crucial adaptation update only projection layer even just random subset layer 's weight APLA achieve state art performance reduce GPU memory usage to 52.63 training time to 43.0 extra cost inference 46 dataset cover variety task include scene classification medical imaging satellite imaging fine grain classification APLA consistently outperform 17 other lead adaptation method include full fine tuning classification segmentation detection task code be available https url,"Moein Sorkhei, Emir Konuk, Kevin Smith, Christos Matsoukas",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11329,Colour Morphological Distance ordering base Log Exp supremum,Mathematical morphology field image processing include various filter that highlight modify eliminate certain information image base application 's need key operation filter be dilation erosion which determine supremum infimum pixel respect order tonal value subset image surround pixel subset be form structuring element specify pixel which weigh tonal value grey scale morphology where tonal order be clearly define colour morphology lack definitive total order method fully meet desire property colour difficulty limitation be always present paper show how to combine theory log exp supremum colour matrix that employ Loewner semi order well know colour distance approach form pre ordering log exp supremum will therefore serve reference colour determine colour distance result pre order respect distance value add lexicographic cascade to ensure total order unique result objective approach be to identify original colour structuring element that most closely resemble supremum which fulfil number desire property consequently approach avoid false colour problem behaviour introduce operator be illustrate application example dilation close synthetic natural image,"Marvin Kahra, Michael Breuß",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11328,transit Transient Transformer non line sight videography,high quality high speed videography use Non line Sight NLOS imaging benefit autonomous navigation collision prevention post disaster search rescue task current solution have to balance frame rate image quality high frame rate example can be achieve reduce point scan time scan density cost lower information density individual frame fast scan process far reduce signal noise ratio different scanning system exhibit different distortion characteristic work design employ new Transient Transformer architecture call transit to achieve real time nlos recovery fast scan transit directly compress temporal dimension input transient to extract feature reduce computation cost meet high frame rate requirement far adopt feature fusion mechanism as well employ spatial temporal Transformer to help capture feature NLOS transient video moreover transit apply transfer learn to bridge gap synthetic real measure datum real experiment manage to reconstruct sparse transient $ 16 \times 16 $ measure exposure time 0.4 ms point nlos video $ 64 \times 64 $ resolution 10 frame second will make code dataset available community,"Ruiqian Li, Siyuan Shen, Suan Xia, Ziheng Wang, Xingyue Peng, Chengxuan Song, Yingsheng Zhu, Tao Wu, Shiying Li, Jingyi Yu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11321,leverage Diffusion Knowledge Generative Image Compression Fractal Frequency Aware Band Learning,optimize rate distortion realism trade off generative image compression approach produce detailed realistic image instead only sharp look reconstruction produce rate distortion optimize model paper propose novel deep learning base generative image compression method inject diffusion knowledge obtain capacity to recover more realistic texture practical scenario effort be make three perspective to navigate rate distortion realism trade off generative image compression task first recognize strong connection image texture frequency domain characteristic design Fractal Frequency Aware Band Image Compression FFAB IC network to effectively capture directional frequency component inherent natural image network integrate commonly use fractal band feature operation neural non linear mapping design enhance ability to retain essential give information filter out unnecessary detail then to improve visual quality image reconstruction limited bandwidth integrate diffusion knowledge encoder implement diffusion iteration decoder process thus effectively recover lose texture detail finally to fully leverage spatial frequency intensity information incorporate frequency- content aware regularization term to regularize training generative image compression network extensive experiment quantitative qualitative evaluation demonstrate superiority propose method advance boundary achievable distortion realism pair i.e. method achieve well distortion high realism well realism low distortion ever before,"Lingyu Zhu, Xiangrui Zeng, Bolin Chen, Peilin Chen, Yung-Hui Li, Shiqi Wang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11318,open Set Plankton Recognition,paper consider open set recognition OSR plankton image Plankton include diverse range microscopic aquatic organism that have important role marine ecosystem primary producer base food webs give sensitivity environmental change fluctuation plankton population offer valuable information ocean health climate change motivate monitoring modern automatic plankton imaging device enable collection large scale plankton image dataset facilitate species level analysis Plankton specie recognition can be see image classification task be typically solve use deep learning base image recognition model however data collection real aquatic environment result imaging device capture variety non plankton particle plankton species not present training set create challenging fine grain OSR problem characterize subtle difference taxonomically close plankton species address challenge conduct extensive experiment three OSR approach use phyto- zooplankton image analyze also effect rejection threshold OSR result demonstrate high OSR accuracy can be obtain promote use method operational plankton research have make datum publicly available research community,"Joona Kareinen, Annaliina Skyttä, Tuomas Eerola, Kaisa Kraft, Lasse Lensu, Sanna Suikkanen, Maiju Lehtiniemi, Heikki Kälviäinen",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11315,MMS LLaMA Efficient LLM base Audio Visual Speech Recognition Minimal Multimodal Speech Tokens,audio Visual Speech Recognition AVSR achieve robust speech recognition noisy environment combine auditory visual information however recent Large Language Model LLM base AVSR system incur high computational cost due high temporal resolution audio visual speech process LLMs work introduce efficient multimodal speech LLM framework that minimize token length preserve essential linguistic content approach employ early av fusion module streamlined feature integration audio visual speech Q Former that dynamically allocate token base input duration refined query allocation strategy speech rate predictor to adjust token allocation accord speak speed audio sample extensive experiment LRS3 dataset show method achieve state art performance WER 0.74 use only 3.5 token second moreover approach not only reduce token usage 86 compare previous multimodal speech LLM framework also improve computational efficiency reduce flop 35.7,"Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11297,gmg Video Prediction Method base Global Focus Motion Guided,recent year weather forecasting have gain significant attention however accurately predict weather remain challenge rapid variability meteorological datum potential teleconnection current spatiotemporal forecasting model primarily rely convolution operation slide window feature extraction method be limit size convolutional kernel slide window make difficult to capture identify potential teleconnection feature meteorological datum additionally weather datum often involve non rigid body whose motion process be accompany unpredictable deformation far complicate forecasting task paper propose GMG model to address two core challenge Global Focus Module key component model enhance global receptive field Motion Guided Module adapt growth dissipation process non rigid body extensive evaluation method demonstrate competitive performance various complex task provide novel approach improve predictive accuracy complex spatiotemporal datum,"Yuhao Du, Hui Liu, Haoxiang Peng, Xinyuan Chen, Chenrong Wu, Jiankai Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11290,EmoAgent Multi agent Collaboration Plan Edit Critic Affective Image Manipulation,Affective Image Manipulation AIM aim to alter image 's emotional impact adjust multiple visual element to evoke specific http url AIM be inherently complex necessitate collaborative approach that involve identify semantic cue source image manipulate element elicit desire emotional response verify combine adjustment successfully evoke target http URL address challenge introduce EmoAgent first multi agent collaboration framework AIM emulate cognitive behavior human painter EmoAgent incorporate three specialized agent responsible planning editing critical evaluation furthermore develop emotion factor knowledge retriever decision make tree space tool library to enhance EmoAgent 's effectiveness handle aim experiment demonstrate propose multi agent framework outperform existing method offer more reasonable effective emotional expression,"Qi Mao, Haobo Hu, Yujie He, Difei Gao, Haokun Chen, Libiao Jin",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11266,CyclePose leverage cycle Consistency Annotation Free Nuclei Segmentation Fluorescence Microscopy,recent year numerous neural network architecture specifically design instance segmentation nucleus microscopic image have be release model embed nuclei specific prior to outperform generic architecture U net however require large annotated dataset which be often not available generative model gan diffusion model have be use to compensate synthesize training datum two stage approach be computationally expensive first generative model then segmentation model have to be train propose CyclePose hybrid framework integrate synthetic datum generation segmentation training CyclePose build CycleGAN architecture which allow unpaired translation microscopy image segmentation mask embed segmentation model CycleGAN leverage cycle consistency loss self supervision annotated datum CyclePose outperform other weakly unsupervised method two public dataset Code be available https url,"Jonas Utz, Stefan Vocht, Anne Tjorven Buessen, Dennis Possart, Fabian Wagner, Mareike Thies, Mingxuan Gu, Stefan Uderhardt, Katharina Breininger",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11265,DynRsl VLM enhance Autonomous Driving Perception Dynamic Resolution Vision Language model,Visual Question Answering VQA model which fall category vision language model conventionally execute multiple downsampling process image input to strike balance computational efficiency model performance approach aid concentrate salient feature diminish computational burden incur loss vital detailed information drawback that be particularly damaging end end autonomous driving scenario downsampling can lead inadequate capture distant small object such pedestrian road sign obstacle which be crucial safe navigation loss feature negatively impact autonomous drive system 's capacity to accurately perceive environment potentially escalate risk accident to tackle problem put forward Dynamic Resolution Vision Language Model DynRsl VLM DynRsl VLM incorporate dynamic resolution image input processing approach that capture entity feature information image ensure image input remain computationally tractable Vision Transformer ViT moreover devise novel image text alignment module to replace Q Former enable simple efficient alignment text when deal dynamic resolution image input method enhance environmental perception capability autonomous driving system overstep computational constraint,"Xirui Zhou, Lianlei Shan, Xiaolin Gui",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11262,Noise Synthesis Low Light image denoising Diffusion model,low light photography produce image low signal noise ratio limited photon such condition common approximation Gaussian noise model fall short many denoise technique fail to remove noise effectively deep learn method perform well require large dataset pair image that be impractical to acquire remedy synthesize realistic low light noise have gain significant attention paper investigate ability diffusion model to capture complex distribution low light noise show naive application conventional diffusion model be inadequate task propose three key adaptation that enable high precision noise generation calibration post processing two branch architecture well model signal dependent signal independent noise incorporation positional information to capture fix pattern noise tailor diffusion noise schedule consequently model enable generation large dataset train low light denoising network lead state art performance comprehensive analysis include statistical evaluation noise decomposition provide deep insight characteristic generate datum,"Liying Lu, Raphaël Achddou, Sabine Süsstrunk",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11251,Step Video TI2V Technical Report state art text drive image Video Generation Model,present Step Video TI2V state art text drive image video generation model 30b parameter capable generate video to 102 frame base text image input build Step Video TI2V Eval new benchmark text drive image video task compare Step Video ti2v open source commercial ti2v engine use dataset experimental result demonstrate state art performance Step Video ti2v image video generation task Step Video ti2v Step Video TI2V Eval be available https url,"Haoyang Huang, Guoqing Ma, Nan Duan, Xing Chen, Changyi Wan, Ranchen Ming, Tianyu Wang, Bo Wang, Zhiying Lu, Aojie Li, Xianfang Zeng, Xinhao Zhang, Gang Yu, Yuhe Yin, Qiling Wu, Wen Sun, Kang An, Xin Han, Deshan Sun, Wei Ji, Bizhu Huang, Brian Li, Chenfei Wu, Guanzhe Huang, Huixin Xiong, Jiaxin He, Jianchang Wu, Jianlong Yuan, Jie Wu, Jiashuai Liu, Junjing Guo, Kaijun Tan, Liangyu Chen, Qiaohui Chen, Ran Sun, Shanshan Yuan, Shengming Yin, Sitong Liu, Wei Chen, Yaqi Dai, Yuchu Luo, Zheng Ge, Zhisheng Guan, Xiaoniu Song, Yu Zhou, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Yi Xiu, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11247,break Shallow limit Task Driven Pixel Fusion gap free rgbt tracking,current rgbt tracking method often overlook impact fusion location mitigate modality gap which be key factor effective tracking analysis reveal shallow fusion yield small distribution gap however limited discriminative power shallow network hard to distinguish task relevant information noise limit potential pixel level fusion to break shallow limit propose novel \textbf{t}ask drive \textbf{p}ixel level \textbf{f}usion network name \textbf{TPF which unveil power pixel level fusion RGBT track progressive learn framework particular design lightweight Pixel level Fusion Adapter PFA that exploit Mamba 's linear complexity to ensure real time low latency rgbt tracking to enhance fusion capability PFA task drive progressive learn framework first utilize adaptive multi expert distillation to inherits fusion knowledge state art image fusion model establish robust initialization then employ decouple representation learning scheme to achieve task relevant information fusion moreover to overcome appearance variation initial template search frame present near neighbor dynamic template update scheme which select most reliable frame close current search frame dynamic template extensive experiment demonstrate TPF significantly outperform exist most advanced tracker four public rgbt tracking dataset code will be release acceptance,"Andong Lu, Yuanzhi Guo, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11245,L2RSI Cross view LiDAR base Place Recognition large scale Urban Scenes Remote Sensing Imagery,"tackle challenge lidar base place recognition which traditionally depend costly time consume prior 3d map to overcome first construct XA L&RSI dataset which encompass approximately $ 110,000 $ remote sensing submap $ 13,000 $ LiDAR point cloud submap capture urban scene propose novel method L2RSI cross view LiDAR place recognition use high resolution Remote Sensing Imagery approach enable large scale localization capability reduce cost leverage readily available overhead image map proxy L2RSI address dual challenge cross view cross modal place recognition learn feature alignment point cloud submap remote sense submap semantic domain additionally introduce novel probability propagation method base dynamic gaussian mixture model to refine position prediction effectively leverage temporal spatial information approach enable large scale retrieval cross scene generalization fine tuning extensive experiment XA L&RSI demonstrate $ 100km^2 $ retrieval range L2RSI accurately localize $ 95.08\%$ point cloud submap $ 30m$ radius top-$1 $ retrieve location provide video to more vividly display place recognition result L2RSI https url","Ziwei Shi, Xiaoran Zhang, Yan Xia, Yu Zang, Siqi Shen, Cheng Wang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11241,Compound Expression Recognition large Vision Language model,Compound Expression Recognition CER be crucial understand human emotion improve human computer interaction however CER face challenge complexity facial expression difficulty capture subtle emotional cue to address issue propose novel approach leverage large Vision Language Models lvlm method employ two stage fine tuning process first pre train lvlm be fine tuned basic facial expression to establish foundational pattern second model be far optimize compound expression dataset to refine visual language feature interaction approach achieve advanced accuracy RAF DB dataset demonstrate strong zero shot generalization c expr db dataset showcase potential real world application emotion analysis human computer interaction,"Jun Yu, Xilong Lu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11240,Better Alignment Training Diffusion Models Reinforcement Learning Sparse reward,diffusion model have achieve remarkable success text image generation however practical application be hinder misalignment generate image correspond text prompt to tackle issue reinforcement learning RL have be consider diffusion model fine tuning yet RL 's effectiveness be limit challenge sparse reward where feedback be only available end generation process make difficult to identify which action denoising process contribute positively final generate image potentially lead ineffective unnecessary denoising policy end paper present novel RL base framework that address sparse reward problem when training diffusion model framework name $ \text{b}^2\text{-diffurl}$ employ two strategy \textbf{b}ackward progressive training \textbf{B}ranch base sampling one thing backward progressive training focus initially final timestep denoising process gradually extend training interval early timestep ease learn difficulty sparse reward perform branch base sampling training interval compare sample same branch can identify how much policy current training interval contribute final image which help to learn effective policy instead unnecessary one $ \text{b}^2\text{-diffurl}$ be compatible exist optimization algorithm extensive experiment demonstrate effectiveness $ \text{b}^2\text{-diffurl}$ improve prompt image alignment maintain diversity generate image code work be available,"Zijing Hu, Fengda Zhang, Long Chen, Kun Kuang, Jiahui Li, Kaifeng Gao, Jun Xiao, Xin Wang, Wenwu Zhu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11226,Non Line Sight Optical Wireless Communication use Neuromorphic camera,neuromorphic event camera inspire biological vision system capture change illumination high temporal resolution efficiency produce stream event rather traditional image paper explore use neuromorphic camera passive optical wireless communication OWC leverage asynchronous detection illumination change decode datum transmit reflection light object propose novel system that utilize neuromorphic camera passive visible light communication VLC extend concept Non Line Sight NLoS scenario passive reflection everyday object experiment demonstrate feasibility advantage use neuromorphic camera VLC characterize performance various modulation scheme include traditional On Off Keying OOK advanced N pulse modulation introduce adaptive N pulse modulation scheme that dynamically adjust encode base packet 's bit composition achieve high data rate robustness different scenario result show lighter color glossy object be well nlos communication large object matte finish experience high error rate multipath reflection,"Abbaas Alif Mohamed Nishar, Alireza Marefat, Ashwin Ashok",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11221,generalized Image Quality Assessment relax Perfect Reference Quality Assumption,"full reference image quality assessment FR IQA generally assume reference image be perfect quality however assumption be flawed sensor optical limitation modern imaging system moreover recent generative enhancement method be capable produce image high quality original challenge effectiveness applicability current FR IQA model to relax assumption perfect reference image quality build large scale IQA database namely diffiqa contain approximately 180,000 image generate diffusion base image enhancer adjustable hyper parameter image be annotate human subject bad similar well quality compare reference build present generalized FR IQA model namely Adaptive Fidelity Naturalness Evaluator a fine to accurately assess adaptively combine fidelity naturalness test image FINE align well standard FR IQA when reference image be much more natural test image demonstrate extensive experiment that a fine surpasse standard FR IQA model well establish IQA dataset newly create diffiqa to far validate a fine additionally construct super resolution IQA benchmark SRIQA Bench encompass test image derive ten state art SR method reliable human quality annotation test SRIQA Bench re affirm advantage a fine code dataset be available https url","Du Chen, Tianhe Wu, Kede Ma, Lei Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11219,MEET million Scale Dataset Fine Grained Geospatial Scene Classification Zoom Free Remote Sensing Imagery,accurate fine grain geospatial scene classification use remote sense imagery be essential wide range application however exist approach often rely manually zoom remote sense image different scale to create typical scene sample approach fail to adequately support fix resolution image interpretation requirement real world scenario to address limitation introduce million scale fine grain geospatial scene classification dataseT MEET which contain 1.03 million zoom free remote sense scene sample manually annotate 80 fine grain category MEET scene sample follow scene inscene layout where central scene serve reference auxiliary scene provide crucial spatial context finegrained classification moreover to tackle emerge challenge scene scene classification present Context Aware Transformer CAT model specifically design task which adaptively fuse spatial context to accurately classify scene sample CAT adaptively fuse spatial context to accurately classify scene sample learn attentional feature that capture relationship center auxiliary scene base MEET establish comprehensive benchmark fine grain geospatial scene classification evaluate CAT 11 competitive baseline result demonstrate CAT significantly outperform baseline achieve 1.88 high balanced accuracy BA Swin large backbone notable 7.87 improvement Swin huge backbone further experiment validate effectiveness module CAT show practical applicability CAT urban functional zone mapping source code dataset will be publicly available https url,"Yansheng Li, Yuning Wu, Gong Cheng, Chao Tao, Bo Dang, Yu Wang, Jiahao Zhang, Chuge Zhang, Yiting Liu, Xu Tang, Jiayi Ma, Yongjun Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11218,General Multimodal Visual tracking,exist multimodal tracking study focus bi modal scenario such RGB Thermal RGB Event RGB Language promising tracking performance be achieve leverage complementary cue different source remain challenge complex scene limitation bi modal scenario work introduce general multimodal visual tracking task that fully exploit advantage four modality include RGB thermal infrared event language robust tracking challenging condition to provide comprehensive evaluation platform general multimodal visual tracking construct QuadTrack600 large scale high quality benchmark comprise 600 video sequence total 384.7 K high resolution 640x480 frame group frame group four modality be spatially align meticulously annotate bounding box 21 sequence level challenge attribute be provide detailed performance analysis quad modal datum provide rich information difference information quantity modality computational burden four modality be two challenging issue fuse four modality to handle issue propose novel approach call QuadFusion which incorporate efficient Multiscale Fusion Mamba four different scanning scale to achieve sufficient interaction four modality overcome exponential computational burden general multimodal visual tracking extensive experiment QuadTrack600 dataset three bi modal tracking dataset include lasher VisEvent TNL2 K validate effectiveness QuadFusion,"Andong Lu, Mai Wen, Jinhu Wang, Yuanzhi Guo, Chenglong Li, Jin Tang, Bin Luo",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11213,Simulating Dual Pixel Images Ray Tracing For Depth estimation,many study utilize dual pixel DP sensor phase characteristic various application such depth estimation deblurring however DP image feature be entirely determine camera hardware DP depth pair dataset be very scarce especially when perform depth estimation customize camera to overcome study simulate DP image use ideal optical system model however simulation often violate real optical propagation law lead poor generalization real DP datum to address investigate domain gap simulated real DP datum propose solution use Simulating DP image ray tracing Sdirt scheme Sdirt generate realistic dp image ray tracing integrate depth estimation training pipeline experimental result show model train sdirt simulate image generalize well real DP datum,"Fengchen He, Dayang Zhao, Hao Xu, Tingwei Quan, Shaoqun Zeng",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11205,LLaVA MLB mitigate leverage Attention Bias Training Free Video LLMs,training free video large language model LLMs leverage pretraine Image LLMs to process video content need further training key challenge such approach be difficulty retain essential visual temporal information constrain token limit Image LLMs to address propose two stage method select query relevant token base LLM attention score compress video sequence then expand sequence however compression stage Image llm often exhibit positional attention bias video sequence where attention be overly concentrated later frame cause early frame information to be underutilize to alleviate attention bias sequence compression propose Gridded Attention Pooling preserve spatiotemporal structure additionally introduce Visual Summarization Tail to effectively utilize bias facilitate overall video understanding sequence expansion way method effectively Mitigates Leverages attention Bias LLaVA MLB enable frozen image llm detailed video understanding experiment several benchmark demonstrate approach outperform state art method achieve superior performance efficiency accuracy code will be release,"Leqi Shen, Tao He, Guoqiang Gong, Fan Yang, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11199,NF SLAM Effective Normalizing Flow support Neural Field representation object level visual slam automotive application,propose novel vision only object level slam framework automotive application represent 3d shape implicit sign distance function key innovation consist augment standard neural representation normalizing flow network result achieve strong representation power specific class road vehicle be make possible compact network only 16 dimensional latent code furthermore newly propose architecture exhibit significant performance improvement presence only sparse noisy datum which be demonstrate comparative experiment synthetic datum module be embed back end stereo vision base framework joint incremental shape optimization loss function be give combination sparse 3d point base SDF loss sparse render loss semantic mask base silhouette consistency term furthermore leverage semantic information to determine keypoint extraction density front end finally experimental result real world datum reveal accurate reliable performance comparable alternative framework that make use direct depth reading propose method perform well only sparse 3d point obtain bundle adjustment eventually continue to deliver stable result even exclusive use mask consistency term,"Li Cui, Yang Ding, Richard Hartley, Zirui Xie, Laurent Kneip, Zhenghua Yu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11195,Provenance Detection AI Generated Images combine Perceptual Hashing homomorphic Encryption AI Detection model,AI generate sensitive image become more prevalent identify source be crucial distinguish real image conventional image watermarking method be vulnerable common transformation filter lossy compression screenshot often apply social medium sharing watermark can also be fake remove model be open sourced leak image can be rewatermarke have develop three part framework secure transformation resilient AI content provenance detection to address limitation develop adversarially robust state art perceptual hashing model DinoHash derive DINOV2 which be robust common transformation filter compression crop additionally integrate Multi Party fully Homomorphic Encryption~(MP FHE scheme propose framework to ensure protection user query registry privacy furthermore improve previous work AI generate medium detection approach be useful case where content be absent registry DinoHash significantly improve average bit accuracy 12 state art watermarking perceptual hash method maintain superior true positive rate TPR false positive rate FPR tradeoff various transformation AI generate medium detection result show 25 improvement classification accuracy commonly use real world AI image generator exist algorithm combine perceptual hashing MP FHE AI content detection model propose framework provide well robustness privacy compare previous work,"Shree Singhi, Aayan Yadav, Aayush Gupta, Shariar Ebrahimi, Parisa Hassanizadeh",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11194,Online Test time adaptation 3d Human Pose Estimation Practical Perspective estimated 2d pose,online test time adaptation 3d human pose estimation be use video stream that differ training datum ground truth 2D pose be use adaptation only estimate 2D pose be available practice paper address adapt model stream video estimate 2D pose compare adaptation reveal challenge limit estimation error preserve accurate pose information end propose adaptive aggregation two stage optimization local augmentation handle vary level estimate pose error first perform adaptive aggregation video to initialize model state label representative sample video use two stage optimization to benefit 2D fitting minimize impact erroneous update second employ local augmentation use adjacent confident sample to update model adapt current non confident sample method surpass state art large margin advance adaptation more practical setting use estimate 2D pose,"Qiuxia Lin, Kerui Gu, Linlin Yang, Angela Yao",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11187,fastvid dynamic density Pruning Fast Video Large Language model,video Large Language Models have show impressive capability video comprehension practical deployment be hinder substantial inference cost cause redundant video token exist pruning technique fail to fully exploit spatiotemporal redundancy inherent video datum to bridge gap perform systematic analysis video redundancy two perspective temporal context visual context leverage insight propose dynamic density Pruning Fast Video LLMs term fastvid specifically FastVID dynamically partition video temporally order segment to preserve temporal structure apply density base token pruning strategy to maintain essential visual information method significantly reduce computational overhead maintain temporal visual integrity extensive evaluation show fastvid achieve state art performance various short- long video benchmark lead Video LLMs include LLaVA OneVision LLaVA Video notably FastVID effectively prune 90 video token retain 98.0 LLaVA OneVision 's original performance code be available https url,"Leqi Shen, Guoqiang Gong, Tao He, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11183,multimodal Aware Fusion Network refer Remote Sensing Image segmentation,refer remote sense image segmentation RRSIS be novel visual task remote sensing image segmentation which aim to segment object base give text description great significance practical application previous study fuse visual linguistic modality explicit feature interaction which fail to effectively excavate useful multimodal information dual branch encoder letter design multimodal aware fusion network MAFN to achieve fine grain alignment fusion two modality propose correlation fusion module cfm to enhance multi scale visual feature introduce adaptively noise transformer integrate cross modal aware feature addition MAFN employ multi scale refinement convolution MSRC to adapt various orientation object different scale to boost representation ability to enhance segmentation accuracy extensive experiment have show MAFN be significantly more effective state art RRSIS d dataset source code be available https url,"Leideng Shi, Juan Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11181,Multi Stage Generative Upscaler reconstruct Football Broadcast Images Diffusion model,reconstruction low resolution football broadcast image present significant challenge sport broadcasting where detailed visual be essential analysis audience engagement study introduce multi stage generative upscale framework leverage Diffusion Models to enhance degraded image transform input as small $ 64 \times 64 $ pixel high fidelity $ 1024 \times 1024 $ output integrate image image pipeline ControlNet conditioning LoRA fine tuning approach surpass traditional upscale method restore intricate texture domain specific element such player detail jersey logo custom LoRA be train custom football dataset ensure adaptability sport broadcast need experimental result demonstrate substantial improvement conventional model ControlNet refine fine detail LoRA enhance task specific element finding highlight potential diffusion base image reconstruction sport medium pave way future application automate video enhancement real time sport analytic,"Luca Martini, Daniele Zolezzi, Saverio Iacono, Gianni Viardo Vercelli",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11175,Zero TIG Temporal Consistency Aware Zero Shot Illumination Guided Low light Video Enhancement,low light underwater video suffer poor visibility low contrast high noise necessitating enhancement visual quality however exist approach typically rely pair ground truth which limit practicality often fail to maintain temporal consistency to overcome obstacle paper introduce novel zero shot learn approach name Zero TIG leverage Retinex theory optical flow technique propose network consist enhancement module temporal feedback module enhancement module comprise three subnetwork low light image denoising illumination estimation reflection denoising temporal enhancement module ensure temporal consistency incorporate histogram equalization optical flow computation image warp to align enhanced previous frame current frame thereby maintain continuity additionally address color distortion underwater datum adaptively balance RGB channel experimental result demonstrate method achieve low light video enhancement need paired training datum make promising applicable method real world scenario enhancement,"Yini Li, Nantheera Anantrasirichai",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11172,uncertainty Aware Normal Guided Gaussian Splatting Surface Reconstruction Sparse Image Sequences,3d Gaussian Splatting 3dgs have achieve impressive rendering performance novel view synthesis however efficacy diminish considerably sparse image sequence where inherent datum sparsity amplify geometric uncertainty optimization often lead convergence suboptimal local minima result noticeable structural artifact reconstructed http url mitigate issue propose uncertainty aware Normal Guided Gaussian Splatting UNG GS novel framework feature explicit Spatial Uncertainty Field SUF to quantify geometric uncertainty 3dgs pipeline UNG GS enable high fidelity rendering achieve high precision reconstruction rely prior specifically first integrate Gaussian base probabilistic modeling training 3dgs to optimize SUF provide model adaptive error tolerance uncertainty aware depth rendering strategy be then employ weight depth contribution base SUF effectively reduce noise preserve fine detail furthermore uncertainty guide normal refinement method adjust influence neighbor depth value normal estimation promote robust result extensive experiment demonstrate UNG GS significantly outperform state art method sparse dense sequence code will be open source,"Zhen Tan, Xieyuanli Chen, Jinpu Zhang, Lei Feng, Dewen Hu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11167,neuron emulate human Visual Cortex improve Fidelity Interpretability fmri Video Reconstruction,decode visual stimulus neural activity be essential understand human brain fmri method have successfully reconstruct static image fmri video reconstruction face challenge need capture spatiotemporal dynamic motion scene transition recent approach have improve semantic perceptual alignment struggle to integrate coarse fmri datum detailed visual feature inspire hierarchical organization visual system propose neuron novel framework that decouple learn four correlate sub task key object segmentation concept recognition scene description blurry video reconstruction approach simulate visual cortex 's functional specialization allow model to capture diverse video content inference stage NEURONS generate robust conditioning signal pre train text video diffusion model to reconstruct video extensive experiment demonstrate NEURONS outperform state art baseline achieve solid improvement video consistency 26.6 semantic level accuracy 19.1 notably NEURONS show strong functional correlation visual cortex highlight potential brain computer interface clinical application code model weight will be available https url,"Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11159,stabilize Quantization Aware Training Implicit Regularization Hessian Matrix,quantization Aware Training QAT be one prevail neural network compression solution however stability have be challenge yield deteriorate performance quantization error be inevitable find sharp landscape loss which lead dramatic performance drop be essential factor that cause instability theoretically have discover perturbation feature would bring flat local minima however simply add perturbation weight feature empirically deteriorate performance Full Precision FP model paper propose Feature perturb Quantization FPQ to stochastically perturb feature employ feature distillation method quantize model method generalize well different network architecture various QAT method furthermore mathematically show FPQ implicitly regularize hessian norm which calibrate smoothness loss landscape extensive experiment demonstrate approach significantly outperform current state Of The art SOTA QAT method even FP counterpart,"Junbiao Pang, Tianyang Cai",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11143,GaussianIP identity preserve realistic 3d Human Generation Human Centric Diffusion Prior,text guide 3d human generation have advance development efficient 3d representation 2d lift method Score Distillation Sampling SDS however current method suffer prolonged training time often produce result that lack fine facial garment detail paper propose GaussianIP effective two stage framework generate identity preserve realistic 3d human text image prompt core insight be to leverage human centric knowledge to facilitate generation process stage 1 propose novel Adaptive Human Distillation Sampling AHDS method to rapidly generate 3d human that maintain high identity consistency image prompt achieve realistic appearance compare traditional SDS method AHDS well align human centric generation process enhance visual quality notably few training step to far improve visual quality face clothe region design View Consistent Refinement VCR strategy stage 2 specifically produce detail enhance result multi view image stage 1 iteratively ensure 3d texture consistency view mutual attention distance guide attention fusion then polished version 3d human can be achieve directly perform reconstruction refined image extensive experiment demonstrate GaussianIP outperform exist method visual quality training efficiency particularly generate identity preserve result code be available https url,"Zichen Tang, Yuan Yao, Miaomiao Cui, Liefeng Bo, Hongyu Yang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11140,Minding Fuzzy region data drive Alternating Learning Paradigm Stable Lesion Segmentation,deep learning have achieve significant advancement medical image segmentation exist model still face challenge accurately segment lesion region main reason be lesion region medical image have unclear boundary irregular shape small tissue density difference lead label ambiguity however exist model treat datum equally take quality difference account training process result noisy label negatively impact model training unstable feature representation paper data drive alternating learning DALE paradigm be propose to optimize model 's training process achieve stable high precision segmentation paradigm focus two key point 1 reduce impact noisy label 2 calibrate unstable representation to mitigate negative impact noisy label loss consistency base collaborative optimization method be propose effectiveness be theoretically demonstrate specifically label confidence parameter be introduce to dynamically adjust influence label different confidence level model training thus reduce influence noise label to calibrate learn bias unstable representation distribution alignment method be propose method restore underlie distribution unstable representation thereby enhance discriminative capability fuzzy region representation extensive experiment various benchmark model backbone demonstrate superiority DALE paradigm achieve average performance improvement to 7.16,"Lexin Fang, Yunyang Xu, Xiang Ma, Xuemei Li, Caiming Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11133,SpaceSeg high Precision Intelligent Perception Segmentation Method Multi Spacecraft On Orbit target,continuous advancement human exploration deep space intelligent perception high precision segmentation technology orbit multi spacecraft target have become critical factor ensure success modern space mission however complex deep space environment diverse imaging condition high variability spacecraft morphology pose significant challenge traditional segmentation method paper propose SpaceSeg innovative vision foundation model base segmentation framework four core technical innovation first Multi scale Hierarchical Attention Refinement Decoder MSHARD achieve high precision feature decode cross resolution feature fusion hierarchical attention second multi spacecraft Connected Component Analysis MS CCA effectively resolve topological structure confusion dense target third Spatial Domain Adaptation Transform framework SDAT eliminate cross domain disparity resist spatial sensor perturbation composite enhancement strategy finally custom Multi Spacecraft Segmentation Task Loss Function be create to significantly improve segmentation robustness deep space scenario to support algorithm validation construct first multi scale orbit multi spacecraft semantic segmentation dataset SpaceES which cover four type spatial background 17 typical spacecraft target testing SpaceSeg achieve state art performance 89.87$\%$ mIoU 99.98$\$ macc surpass exist good method 5.71 percentage point dataset code be open sourced https url to provide critical technical support next generation space situational awareness system,"Hao Liu, Pengyu Guo, Siyuan Yang, Zeqing Jiang, Qinglei Hu, Dongyu Li",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11129,direction Aware Diagonal Autoregressive Image generation,raster order image token sequence exhibit significant euclidean distance index adjacent token line break make unsuitable autoregressive generation to address issue paper propose Direction aware Diagonal Autoregressive Image Generation DAR method which generate image token follow diagonal scanning order propose diagonal scanning order ensure tokens adjacent index remain close proximity enable causal attention to gather information broad range direction additionally two direction aware module 4d RoPE direction embedding be introduce enhance model 's capability to handle frequent change generation direction to leverage representational capacity image tokenizer use codebook image token embedding propose model vary scale range 485 m 2.0B. 256$\times$256 ImageNet benchmark DAR XL 2.bdiffusion model training drivegen consistently preserve object precise 3d geometry diverse ood generation consist 2 stage 1 self prototype extraction empirically find self attention feature be semantic aware require accurate region selection 3d object thus extract precise object feature layout to capture 3d object geometry term self prototype 2 Prototype Guided Diffusion to preserve object various OOD scenario perform semantic aware feature alignment shallow feature alignment denoise extensive experiment demonstrate effectiveness drivegen improve 3d detection code be available https url,"Hongbin Lin, Zilu Guo, Yifan Zhang, Shuaicheng Niu, Yafeng Li, Ruimao Zhang, Shuguang Cui, Zhen Li",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11117,destination Novel Benchmark Exploration aware Embodied Question answering,"Embodied Question Answering EQA be challenging task embody intelligence that require agent to dynamically explore 3d environment actively gather visual information perform multi step reasoning to answer question however current EQA approach suffer critical limitation exploration efficiency dataset design evaluation metric moreover exist dataset often introduce bias prior knowledge lead disembody reasoning frontier base exploration strategy struggle cluttered environment fail to ensure fine grain exploration task relevant area to address challenge construct exploration aware Embodied question answer Benchmark EXPRESS Bench large dataset design specifically to evaluate exploration reasoning capability EXPRESS Bench consist 777 exploration trajectory 2,044 question trajectory pair to improve exploration efficiency propose Fine EQA hybrid exploration model that integrate frontier base goal orient navigation to guide agent task relevant region more effectively additionally introduce novel evaluation metric Exploration Answer Consistency EAC which ensure faithful assessment measure alignment answer grounding exploration reliability extensive experimental comparison state art EQA model demonstrate effectiveness EXPRESS Bench advance embody exploration question reasoning","Kaixuan Jiang, Yang Liu, Weixing Chen, Jingzhou Luo, Ziliang Chen, Ling Pan, Guanbin Li, Liang Lin",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11115,solution 8th competition Affective Behavior Analysis wild,report present solution Action Unit AU Detection Challenge 8th competition Affective Behavior Analysis wild order to achieve robust accurate classification facial action unit wild environment introduce innovative method that leverage audio visual multimodal datum method employ ConvNeXt image encoder use Whisper to extract Mel spectrogram feature feature utilize transformer encoder base feature fusion module to integrate affective information embed audio image feature ensure provision rich high dimensional feature representation subsequent multilayer perceptron MLP train Aff wild2 dataset enhance accuracy AU detection,"Jun Yu, Yunxiang Zhang, Xilong Lu, Yang Zheng, Yongqi Wang, Lingsi Zhu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11103,Quantifying interpretability CLIP Models Concept Consistency,CLIP be one most popular foundational model be heavily use many vision language task however little be know inner working CLIP recent work have propose decomposition base interpretability method identify textual description attention head CLIP implication conceptual consistency text label interpretability model performance have not be explore to bridge gap study conceptual consistency text description attention head clip like model conduct extensive experiment six different model OpenAI which vary size type pre training datum patch size propose Concept Consistency Score CCS novel interpretability metric that measure how consistently individual attention head CLIP model align specific concept to assign concept label head use context learning ChatGPT guide few manually curate example validate label use LLM judge approach soft prune experiment reveal high CCS head be critical preserve model performance prune lead significantly large performance drop prune random low CCS head notably find high CCS head capture essential concept play key role out domain detection concept specific reasoning video language understanding result position CCS powerful interpretability metric analyze clip like model,"Avinash Madasu, Vasudev Lal, Phillip Howard",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11101,Survey self supervise Contrastive Learning Multimodal text image Analysis,self supervise learning be machine learning approach that generate implicit label learn underline pattern extract discriminative feature unlabeled datum manual labelling contrastive learning introduce concept positive negative sample where positive pair e.g. variation same image object be bring together embed space negative pair e.g. view different image object be push far away methodology have show significant improvement image understanding image text analysis much reliance label datum paper comprehensively discuss terminology recent development application contrastive learning respect text image model specifically provide overview approach contrastive learning text image model recent year secondly categorize approach base different model structure thirdly far introduce discuss late advance technique use process such pretext task image text architectural structure key trend lastly discuss recent state art application self supervise contrastive learning Text image base model,"Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11097,Novel Decomposed Feature orient Framework Open set Semantic Segmentation LiDAR Data,semantic segmentation be key technique that enable mobile robot to understand navigate surround environment autonomously however most exist work focus segment known object overlook identification unknown class which be common real world application paper propose feature orient framework open set semantic segmentation LiDAR data capable identify unknown object retain ability to classify know one design decompose dual decoder network to simultaneously perform closed set semantic segmentation generate distinctive feature unknown object network be train multi objective loss function to capture characteristic known unknown object use extract feature introduce anomaly detection mechanism to identify unknown object integrate result close set semantic segmentation anomaly detection achieve effective feature drive LiDAR open set semantic segmentation evaluation SemanticKITTI nuscene dataset demonstrate propose framework significantly outperform state art method source code will be make publicly available https url,"Wenbang Deng, Xieyuanli Chen, Qinghua Yu, Yunze He, Junhao Xiao, Huimin Lu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11096,augment Image Annotation Human LMM Collaborative Framework Efficient Object Selection Label Generation,traditional image annotation task rely heavily human effort object selection label assignment make process time consume prone decrease efficiency annotator experience fatigue extensive work paper introduce novel framework that leverage visual understanding capability large multimodal model LMMs particularly GPT to assist annotation workflow propose approach human annotator focus select object bound box LMM autonomously generate relevant label human AI collaborative framework enhance annotation efficiency reduce cognitive time burden human annotator analyze system 's performance various type annotation task demonstrate ability to generalize task such object recognition scene description fine grain categorization propose framework highlight potential approach to redefine annotation workflow offer scalable efficient solution large scale datum labeling computer vision finally discuss how integrate lmm annotation pipeline can advance bidirectional human AI alignment as well challenge alleviate endless annotation burden face information overload shift work AI,"He Zhang, Xinyi Fu, John M. Carroll",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11094,open3dvqa Benchmark Comprehensive Spatial Reasoning Multimodal Large Language Model Open space,spatial reasoning be fundamental capability embody agent have garner widespread attention field multimodal large language model mllm work propose novel benchmark Open3DVQA to comprehensively evaluate spatial reasoning capacity current state art SOTA foundation model open 3d space open3dvqa consist 9k VQA sample collect use efficient semi automated tool high fidelity urban simulator evaluate several SOTA mllm various aspect spatial reasoning such relative absolute spatial relationship situational reasoning object centric spatial attribute result reveal 1 mllm perform well answer question regard relative spatial relationship absolute spatial relationship 2 mllm demonstrate similar spatial reasoning ability egocentric allocentric perspective 3 fine tune large model significantly improve performance different spatial reasoning task believe open source datum collection tool depth analysis will inspire further research MLLM spatial reasoning capability benchmark be available https url,"Weichen Zhan, Zile Zhou, Zhiheng Zheng, Chen Gao, Jinqiang Cui, Yong Li, Xinlei Chen, Xiao-Ping Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11093,omnidiff Comprehensive Benchmark Fine grain image difference captioning,image Difference Captioning IDC aim to generate natural language description subtle difference image pair require precise visual change localization coherent semantic expression recent advancement exist dataset often lack breadth depth limit applicability complex dynamic environment 1 breadth perspective current dataset be constrain limited variation object specific scene 2 depth perspective prior benchmark often provide overly simplistic description to address challenge introduce OmniDiff comprehensive dataset comprise 324 diverse scenario span real world complex environment 3d synthetic setting fine grain human annotation average 60 word length cover 12 distinct change type build foundation propose M$^3$Diff MultiModal large language model enhance plug play multi scale Differential Perception MDP module module improve model 's ability to accurately identify describe inter image difference maintain foundational model 's generalization capability addition OmniDiff dataset M$^3$Diff achieve state art performance multiple benchmark include Spot Diff IEdit CLEVR Change CLEVR DC OmniDiff demonstrate significant improvement cross scenario difference recognition accuracy compare exist method dataset code model will be make publicly available to support further research,"Yuan Liu, Saihui Hou, Saijie Hou, Jiabao Du, Shibei Meng, Yongzhen Huang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11091,Aerial Vision Language Navigation Grid base View Selection Map construction,Aerial Vision Language Navigation Aerial VLN aim to obtain unmanned aerial vehicle agent to navigate aerial 3d environment follow human instruction compare ground base VLN aerial VLN require agent to decide next action horizontal vertical direction base first person view observation previous method struggle to perform well long navigation path more complicated 3d scene neglect interplay vertical horizontal action paper propose novel grid base view selection framework that formulate aerial VLN action prediction grid base view selection task incorporate vertical action prediction manner that account coupling horizontal action thereby enable effective altitude adjustment far introduce grid base bird 's eye view map aerial space to fuse visual information navigation history provide contextual scene information mitigate impact obstacle finally cross modal transformer be adopt to explicitly align long navigation history instruction demonstrate superiority method extensive experiment,"Ganlong Zhao, Guanbin Li, Jia Pan, Yizhou Yu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11088,Multi view Industrial Anomaly Detection Epipolar Constrained Cross View Fusion,multi camera system provide rich contextual information industrial anomaly detection however traditional method process view independently disregard complementary information viewpoint exist multi view anomaly detection approach typically employ data drive cross view attention feature fusion fail to leverage unique geometric property multi camera setup work introduce epipolar geometry constrain attention module to guide cross view fusion ensure more effective information aggregation to far enhance potential cross view attention propose pretraine strategy inspire memory bank base anomaly detection approach encourage normal feature representation to form multiple local cluster incorporate multi view aware negative sample synthesis to regularize pretraining demonstrate epipolar guide multi view anomaly detection framework outperform exist method state art multi view anomaly detection dataset,"Yifan Liu, Xun Xu, Shijie Li, Jingyi Liao, Xulei Yang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11078,understand Flatness Generative model Role benefit,flat minima know to enhance generalization robustness supervised learning remain largely unexplored generative model work systematically investigate role loss surface flatness generative model theoretically empirically particular focus diffusion model establish theoretical claim that flatter minima improve robustness perturbation target prior distribution lead benefit such reduced exposure bias where error noise estimation accumulate iteration significantly improve resilience to model quantization preserve generative performance even strong quantization constraint far observe Sharpness Aware Minimization SAM which explicitly control degree flatness effectively enhance flatness diffusion model other well know method such Stochastic Weight Averaging SWA Exponential Moving Average EMA which promote flatness indirectly ensemble be less effective extensive experiment CIFAR-10 LSUN Tower FFHQ demonstrate flat minima diffusion model indeed improve not only generative performance also robustness,"Taehwan Lee, Kyeongkook Seo, Jaejun Yoo, Sung Whan Yoon",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11073,Perceive Understand Restore real World Image Super Resolution Autoregressive Multimodal Generative model,leverage generative prior pre train text image diffusion model significant progress have be make real world image super resolution real ISR however method tend to generate inaccurate unnatural reconstruction complex heavily degrade scene primarily limited perception understanding capability input low quality image to address limitation propose first time knowledge to adapt pre train autoregressive multimodal model such Lumina mgpt robust real ISR model namely PURE which perceive Understands input low quality image then REstores high quality counterpart specifically implement instruction tuning Lumina mgpt to perceive image degradation level relationship previously generate image token next token understand image content generate image semantic description consequently restore image generate high quality image token autoregressively collect information addition reveal image token entropy reflect image structure present entropy base Top k sampling strategy to optimize local structure image inference experimental result demonstrate PURE preserve image content generate realistic detail especially complex scene multiple object showcase potential autoregressive multimodal generative model robust real ISR model code will be available https url,"Hongyang Wei, Shuaizheng Liu, Chun Yuan, Lei Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11071,Harnessing Frequency Spectrum Insights image Copyright Protection Diffusion model,diffusion model have achieve remarkable success novel view synthesis reliance large diverse often untraceable web dataset have raise press concern image copyright protection current method fall short reliably identify unauthorized image use struggle to generalize varied generation task fail when training dataset include image multiple source few identifiable watermarke poison sample paper present novel evidence diffusion generate image faithfully preserve statistical property training datum particularly reflect spectral feature leverage insight introduce \emph{coprguard robust frequency domain watermarking framework to safeguard unauthorized image usage diffusion model training fine tuning CoprGuard demonstrate remarkable effectiveness wide range model naive diffusion model sophisticated text image model be robust even when watermarke image comprise mere 1\% training dataset robust versatile approach empower content owner to protect intellectual property era AI drive image generation,"Zhenguang Liu, Chao Shuai, Shaojing Fan, Ziping Dong, Jinwu Hu, Zhongjie Ba, Kui Ren",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11070,falcon Remote Sensing Vision Language Foundation Model,paper introduce holistic vision language foundation model tailor remote sensing name Falcon Falcon offer unified prompt base paradigm that effectively execute comprehensive complex remote sense task Falcon demonstrate powerful understanding reasoning ability image region pixel level specifically give simple natural language instruction remote sense image Falcon can produce impressive result text form 14 distinct task i.e. image classification object detection segmentation image captioning etc to facilitate Falcon 's training empower representation capacity to encode rich spatial semantic information develop Falcon_SFT large scale multi task instruction tuning dataset field remote sensing Falcon_SFT dataset consist approximately 78 million high quality data sample cover 5.6 million multi spatial resolution multi view remote sense image diverse instruction feature hierarchical annotation undergo manual sampling verification to ensure high datum quality reliability extensive comparative experiment be conduct which verify Falcon achieve remarkable performance 67 dataset 14 task have only 0.7b parameter release complete dataset code model weight https URL hope to help far develop open source community,"Kelu Yao, Nuo Xu, Rong Yang, Yingying Xu, Zhuoyan Gao, Titinunt Kitrungrotsakul, Yi Ren, Pu Zhang, Jin Wang, Ning Wei, Chao Li",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11062,Active Learning Scene Embeddings end end Autonomous Driving,field autonomous driving end end deep learning model show great potential learn drive decision directly sensor datum however train model require large amount label datum which be time consume expensive consider real world drive datum exhibit long tail distribution where simple scenario constitute majority part datum be thus inspire to identify most challenging scenario subsequently can efficiently improve performance model training select datum high value prior research have focus selection valuable datum empirically design strategy however manually design method suffer be less generalizable new data distribution observe BEV Bird 's Eye View feature end end model contain all information require to represent scenario propose active learning framework that rely vectorize scene level feature call sead framework select initial datum base drive environmental information incremental datum base BEV feature experiment show only need 30\% nuscene train datum to achieve performance close what can be achieve full dataset source code will be release,"Wenhao Jiang, Duo Li, Menghan Hu, Chao Ma, Ke Wang, Zhipeng Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11060,BannerAgency Advertising Banner Design Multimodal LLM agent,advertising banner be critical capture user attention enhance advertising campaign effectiveness create aesthetically pleasing banner design convey campaign message be challenge large search space involve multiple design element additionally advertiser need multiple size different display various version to target different sector audience design be intrinsically iterative subjective process flexible editability be also high demand practical usage current model have serve assistant human designer various design task typically handle only segment creative design process produce pixel base output that limit editability paper introduce training free framework fully automate banner ad design creation enable frontier multimodal large language model mllm to streamline production effective banner minimal manual effort diverse marketing contexts present BannerAgency MLLM agent system that collaborate advertiser to understand brand identity banner objective generate match background image create blueprint foreground design element render final creative editable component Figma SVG format rather static pixel to facilitate evaluation future research introduce bannerrequest400 benchmark feature 100 unique logo pair 400 diverse banner request quantitative qualitative evaluation demonstrate framework 's effectiveness emphasize quality generate banner design adaptability various banner request strong editability enable component base approach,"Heng Wang, Yotaro Shimose, Shingo Takamatsu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11056,flow Mode Mode seek Diffusion Autoencoders state art image Tokenization,advent popular visual generation framework VQGAN latent diffusion model state art image generation system have generally be two stage system that first tokenize compress visual datum lower dimensional latent space learn generative model Tokenizer training typically follow standard recipe which image be compress reconstruct subject combination MSE perceptual adversarial loss diffusion autoencoder have be propose prior work way to learn end end perceptually orient image compression have not yet show state art performance competitive task ImageNet-1 K reconstruction propose FlowMo transformer base diffusion autoencoder that achieve new state art image tokenization multiple compression rate use convolution adversarial loss spatially align two dimensional latent code distil other tokenizer key insight be FlowMo training should be break mode match pre training stage mode seek post training stage addition conduct extensive analysis explore training generative model FlowMo tokenizer code model will be available http url,"Kyle Sargent, Kyle Hsu, Justin Johnson, Li Fei-Fei, Jiajun Wu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11051,Privacy preserve pre training Remote Sensing Foundation Models Federated mutual guidance learning,traditional Remote Sensing Foundation model rsfm be pre train data centralize paradigm self supervision large scale curate remote sense datum institution however pre training rsfm limited datum standalone manner may lead suboptimal performance aggregate remote sense datum multiple institution centralized pre training raise privacy concern seek collaboration be promising solution to resolve dilemma where multiple institution can collaboratively train rsfm share private datum paper propose novel privacy preserve pre training framework FedSense which enable multiple institution to collaboratively train rsfm share private datum however be non trivial task hinder vicious cycle which result model drift remote sense datum heterogeneity high communication overhead to break vicious cycle introduce Federated mutual guidance Learning specifically propose server client Guidance SCG mechanism to guide client update global flatness optimal solution additionally propose client Server Guidance CSG mechanism to inject local knowledge server low bit communication extensive experiment four downstream task demonstrate effectiveness FedSense full precision communication reduce scenario showcase remarkable communication efficiency performance gain,"Jieyi Tan, Chengwei Zhang, Bo Dang, Yansheng Li",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11044,PSF-4D Progressive Sampling Framework View Consistent 4d editing,instruction guide generative model especially use text image T2I text video T2V diffusion framework have advance field content edit recent year to extend capability 4d scene introduce progressive sample framework 4d editing PSF-4D that ensure temporal multi view consistency intuitively control noise initialization forward diffusion temporal coherence design correlate Gaussian noise structure that link frame time allow frame to depend meaningfully prior frame additionally to ensure spatial consistency view implement cross view noise model which use share independent noise component to balance commonality distinct detail different view to far enhance spatial coherence PSF-4D incorporate view consistent iterative refinement embed view aware information denoising process to ensure align edit frame view approach enable high quality 4d edit rely external model address key challenge previous method extensive evaluation multiple benchmark multiple editing aspect e.g. style transfer multi attribute editing object removal local editing etc show effectiveness propose method experimental result demonstrate propose method outperform state art 4d editing method diverse benchmark,"Hasan Iqbal, Nazmul Karim, Umar Khalid, Azib Farooq, Zichun Zhong, Jing Hua, Chen Chen",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11038,ACMo Attribute Controllable Motion Generation,attribute such style fine grain text trajectory be specific condition describe motion however exist method often lack precise user control motion attribute suffer limited generalizability unseen motion work introduce Attribute Controllable Motion generation architecture to address challenge decouple condition control separately firstly explore Attribute Diffusion Model to imporve text motion performance decouple text motion learning controllable model rely heavily pre train model then introduce Motion Adpater to quickly finetune previously unseen motion pattern motion prompt input achieve multimodal text motion generation that capture user specify style finally propose LLM Planner to bridge gap unseen attribute dataset specific text local knowledage user friendly interaction approach introduce capability motion prompt stylize generation enable fine grain user friendly attribute control provide performance comparable state art method project page https url,"Mingjie Wei, Xuemei Xie, Guangming Shi",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11032,weakly supervised Contrastive Adversarial Training Learning Robust Features Semi supervised datum,exist adversarial training AT method often suffer incomplete perturbation mean not non robust feature be perturb when generate adversarial example aes result residual correlation non robust feature label lead suboptimal learning robust feature however achieve complete perturbation i.e. perturb as many non robust feature possible be challenge difficulty distinguish robust non robust feature sparsity label datum to address challenge propose novel approach call Weakly supervised Contrastive Adversarial Training WSCAT WSCAT ensure complete perturbation improved learning robust feature disrupt correlation non robust feature label complete AE generation partially label datum ground information theory extensive theoretical analysis comprehensive experiment widely adopt benchmark validate superiority WSCAT,"Lilin Zhang, Chengpei Wu, Ning Yang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11030,fmnet Frequency Assisted Mamba Like Linear Attention Network Camouflaged Object Detection,camouflage Object Detection COD be challenge strong similarity camouflage object surrounding which complicate identification exist method mainly rely spatial local feature fail to capture global information transformer increase computational http URL address Frequency Assisted Mamba Like Linear Attention Network FMNet be propose which leverage frequency domain learning to efficiently capture global feature mitigate ambiguity object background FMNet introduce Multi scale Frequency Assisted Mamba Like Linear Attention MFM module integrate frequency spatial feature multi scale structure to handle scale variation reduce computational complexity additionally Pyramidal Frequency Attention Extraction PFAE module Frequency Reverse Decoder FRD enhance semantic reconstruct feature experimental result demonstrate FMNet outperform exist method multiple COD dataset showcase advantage performance efficiency code available https url,"Ming Deng, Sijin Sun, Zihao Li, Xiaochuan Hu, Xing Wu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11028,emodiffusion enhance emotional 3d Facial Animation Latent Diffusion model,Speech drive 3d facial animation seek to produce lifelike facial expression that be synchronize speech content emotional nuance find application various multimedia field however previous method often overlook emotional facial expression fail to disentangle effectively speech content to address challenge present EmoDiffusion novel approach that disentangle different emotion speech to generate rich 3d emotional facial expression specifically method employ two Variational Autoencoders VAEs to separately generate upper face region mouth region thereby learn more refined representation facial sequence traditional method that use diffusion model to connect facial expression sequence audio input perform diffusion process latent space furthermore introduce Emotion Adapter to evaluate upper face movement accurately give paucity 3d emotional talk face datum animation industry capture facial expression guidance animation expert use livelinkface iPhone effort result creation innovative 3d blendshape emotional talking face dataset 3d BEF use to train network extensive experiment perceptual evaluation validate effectiveness approach confirm superiority generate realistic emotionally rich facial animation,"Yixuan Zhang, Qing Chang, Yuxi Wang, Guang Chen, Zhaoxiang Zhang, Junran Peng",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11017,Deep Incomplete Multi view cluster Distribution Dual Consistency Recovery Guidance,multi view cluster leverage complementary representation diverse source to enhance performance however real world datum often suffer incomplete case factor privacy concern device malfunction key challenge be effectively utilize available instance to recover missing view exist method frequently overlook heterogeneity view recovery lead significant distribution discrepancy recovered true datum additionally many approach focus cross view correlation neglect insight intra view reliable structure cross view clustering structure to address issue propose BURG novel method incomplete multi view cluster distribution dUal consistency Recovery Guidance treat sample distinct category perform cross view distribution transfer to predict distribution space miss view to compensate lack reliable category information design dual consistency guide recovery strategy that include intra view alignment guide neighbor aware consistency cross view alignment guide prototypical consistency extensive experiment benchmark demonstrate superiority burg incomplete multi view scenario,"Jiaqi Jin, Siwei Wang, Zhibin Dong, Xihong Yang, Xinwang Liu, En Zhu, Kunlun He",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11008,Comparative Analysis Advanced AI base Object Detection Models Pavement Marking Quality Assessment Daytime,visual object detection utilize deep learning play vital role computer vision have extensive application transportation engineering paper focus detect pavement mark quality daytime use only look once yolo model leverage advanced architectural feature to enhance road safety precise real time assessment utilize image datum New Jersey study employ three YOLOv8 variant YOLOv8 m YOLOv8n yolov8x model be evaluate base prediction accuracy classify pavement marking good moderate poor visibility category result demonstrate YOLOv8n provide good balance accuracy computational efficiency achieve high mean Average Precision map object good visibility demonstrate robust performance various intersection Union IoU threshold research enhance transportation safety offer automated accurate method evaluate quality pavement marking,"Gian Antariksa, Rohir Chakraborty, Shriyank Somvanshi, Subasish Das, Mohammad Jalayer, Deep Rameshkumar Patel, David Mills",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11006,observation Graph Interaction Key Detail Guidance Vision Language Navigation,Vision Language Navigation VLN require agent to navigate environment follow natural language instruction however exist method often struggle effectively integrate visual observation instruction detail navigation lead suboptimal path planning limited success rate paper propose OIKG observation graph Interaction key detail Guidance novel framework that address limitation two key component 1 observation graph interaction module that decouple angular visual information strengthen edge representation navigation space 2 key detail guidance module that dynamically extract utilize fine grain location object information instruction enable more precise cross modal alignment dynamic instruction interpretation approach significantly improve agent 's ability to follow complex navigation instruction extensive experiment r2r rxr dataset demonstrate OIKG achieve state art performance multiple evaluation metric validate effectiveness method enhance navigation precision well observation instruction alignment,"Yifan Xie, Binkai Ou, Fei Ma, Yaohua Liu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11005,Cyclic Contrastive Knowledge Transfer open Vocabulary object detection,pursuit detect unstinted object that extend predefine category prior art open vocabulary object detection OVD typically resort pretraine vision language model VLMs base novel category generalization however to mitigate misalignment upstream image text pretraine downstream region level perception additional supervision be indispensable eg image text pair pseudo annotation generate self training strategy work propose CCKT Det train extra supervision propose framework construct cyclic dynamic knowledge transfer language query visual region feature extract vlm which force detector to closely align visual semantic space vlm specifically 1 prefilter inject semantic prior to guide learning query 2 introduce regional contrastive loss to improve awareness query novel object CCKT Det can consistently improve performance scale VLMs increase require detector moderate level computation overhead comprehensive experimental result demonstrate method achieve performance gain +2.9 +10.2 AP50 previous state art challenging COCO benchmark strong teacher model code be provide https url,"Chuhan Zhang, Chaoyang Zhu, Pingcheng Dong, Long Chen, Dong Zhang",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11004,VA AR Learning Velocity Aware Action Representations Mixture Window Attention,action recognition be crucial task artificial intelligence significant implication various domain initially perform comprehensive analysis seven prominent action recognition method five widely use dataset analysis reveal critical previously overlook observation velocity action increase performance method variably decline undermine robustness decline performance pose significant challenge application real world scenario build finding introduce Velocity Aware Action Recognition VA AR framework to obtain robust action representation different velocity principal insight be rapid action e.g. giant circle backward uneven bar smash badminton occur short time interval necessitate small temporal attention window to accurately capture intricate change conversely slow action e.g. drink water wiping face require large window to effectively encompass broad context VA AR employ Mixture Window Attention MoWA strategy dynamically adjust attention window size base action 's velocity adjustment enable VA AR to obtain velocity aware representation thereby enhance accuracy action recognition extensive experiment confirm VA AR achieve state art performance same five dataset demonstrate VA AR 's effectiveness broad spectrum action recognition scenario,"Jiangning Wei, Lixiong Qin, Bo Yu, Tianjian Zou, Chuhan Yan, Dandan Xiao, Yang Yu, Lan Yang, Ke Li, Jun Liu",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10992,rethink Rotation Invariant Recognition Fine grain shape Perspective Contour Points,rotation invariant recognition shape be common challenge computer vision recent approach have significantly improve accuracy rotation invariant recognition encode rotational invariance shape hand craft image feature introduce deep neural network however method base pixel have too much redundant information critical geometric information be prone early leakage result weak rotation invariant recognition fine grain shape paper reconsider shape recognition problem perspective contour point rather pixel propose anti noise rotation invariant convolution module base geometric aware fine grain shape recognition module divide shape contour multiple local geometric regions(LGA where implement finer grain rotation invariant coding term point topological relation provide deep network compose five such cascade module classification retrieval experiment result show method exhibit excellent performance rotation invariant recognition fine grain shape addition demonstrate method be robust to contour noise rotation center source code be available https url,"Yanjie Xu, Handing Xu, Tianmu Wang, Yaguan Li, Yunzhi Chen, Zhenguo Nie",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10982,enhanced Multi view Pedestrian Detection use probabilistic Occupancy Volume,occlusion pose significant challenge pedestrian detection single view to address multi view detection system have be utilize to aggregate information multiple perspective recent advance multi view detection utilize early fusion strategy that strategically project feature ground plane where detection analysis be perform promising approach context be use 3d feature pull technique which construct 3d feature volume scene sample correspond 2D feature voxel however create 3d feature volume whole scene consider potential location pedestrian paper introduce novel model that efficiently leverage traditional 3d reconstruction technique to enhance deep multi view pedestrian detection be accomplish complement 3d feature volume probabilistic occupancy volume which be construct use visual hull technique probabilistic occupancy volume focus model 's attention region occupy pedestrian improve detection accuracy model outperform state art model MultiviewX dataset moda 97.3 achieve competitive performance Wildtrack dataset,"Reef Alturki, Adrian Hilton, Jean-Yves Guillemaut",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10981,Unlocking Open Set Language Accessibility Vision Models,visual classifier offer high dimensional feature representation that be challenge to interpret analyze text contrast provide more expressive human friendly interpretable medium understanding analyze model behavior propose simple powerful method reformulate visual classifier can be access open set text query compromise original performance approach be label free efficient preserve underlie classifier 's distribution reasoning process thus unlock several text base interpretability application classifier apply method 40 visual classifier demonstrate two primary application 1 build label free zero shot concept bottleneck model therefore convert classifier to be inherently interpretable 2 zero shot decoding visual feature natural language application achieve state art result greatly outperform exist work method enable text approach interpret visual classifier,"Fawaz Sammani, Jonas Fischer, Nikos Deligiannis",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10959,OuroMamba Data free Quantization Framework Vision Mamba Models,present OuroMamba first data free post training quantization DFQ method vision Mamba base model vmm identify two key challenge enable dfq vmm 1 VMM 's recurrent state transition restrict capturing long range interaction lead semantically weak synthetic datum 2 vmm activation exhibit dynamic outlier variation time step render exist static PTQ technique ineffective to address challenge OuroMamba present two stage framework 1 OuroMamba Gen to generate semantically rich meaningful synthetic datum apply contrastive learning patch level vmm feature generate neighborhood interaction latent state space 2 OuroMamba Quant to employ mixed precision quantization lightweight dynamic outlier detection inference specific present thresholding base outlier channel selection strategy activation that get update time step extensive experiment vision generative task show data free OuroMamba surpass exist data drive PTQ technique achieve state art performance diverse quantization setting additionally implement efficient GPU kernel to achieve practical latency speedup 2.36x Code will be release soon,"Akshat Ramachandran, Mingyu Lee, Huan Xu, Souvik Kundu, Tushar Krishna",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10940,Automated Tomato Maturity Estimation use optimized Residual Model Pruning Quantization Techniques,tomato maturity play pivotal role optimize harvest timing ensure product quality current method struggle to achieve high accuracy computational efficiency simultaneously exist deep learning approach accurate be often too computationally demand practical use resource constrain agricultural setting contrast simple technique fail to capture nuanced feature need precise classification study aim to develop computationally efficient tomato classification model use ResNet-18 architecture optimize transfer learning pruning quantization technique objective be to address dual challenge maintain high accuracy enable real time performance low power edge device then model be deploy edge device to investigate performance tomato maturity classification quantize model achieve accuracy 97.81 average classification time 0.000975 second image pruned auto tuned model also demonstrate significant improvement deployment metric far highlight benefit optimization technique result underscore potential balanced solution that meet accuracy efficiency demand modern agricultural production pave way practical real world deployment resource limit environment,"Muhammad Waseem, Chung-Hsuan Huang, Muhammad Muzzammil Sajjad, Laraib Haider Naqvi, Yaqoob Majeed, Tanzeel Ur Rehman, Tayyaba Nadeem",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10937,chatgpt Encounters Morphing Attack Detection Zero Shot MAD Multi modal large Language Models General Vision Models,Face Recognition Systems FRS be increasingly vulnerable face morph attack prompt development Morphing Attack Detection MAD algorithm however key challenge MAD lie limited generalizability unseen datum lack explainability critical practical application environment such enrolment station automate border control system recognize most exist MAD algorithm rely supervised learning paradigm work explore novel approach MAD use zero shot learning leverage Large Language Models LLMs propose two type zero shot MAD algorithm one leverage general vision model other utilize multimodal llm general vision model address MAD task compute mean support embed independent support set use morph image llm base approach employ state art GPT-4 Turbo API carefully craft prompt to evaluate feasibility zero shot MAD effectiveness propose method construct print scan morph dataset feature various unseen morphing algorithm simulate challenge real world application scenario experimental result demonstrate notable detection accuracy validate applicability zero shot learning MAD task additionally investigation LLM base MAD reveal multimodal LLMs such ChatGPT exhibit remarkable generalizability untrained MAD task furthermore possess unique ability to provide explanation guidance which can enhance transparency usability end user practical application,"Haoyu Zhang, Raghavendra Ramachandra, Kiran Raja, Christoph Busch",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10931,multi domain Biometric Recognition use Body embedding,biometric recognition become increasingly challenging move away visible spectrum infrared imagery where domain discrepancy significantly impact identification performance paper show body embedding perform well face embedding cross spectral person identification medium wave infrare MWIR long wave infrare LWIR domain lack multi domain dataset previous research cross spectral body identification also know Visible Infrared Person Re identification VI ReID have primarily focus individual infrared band such near infrared NIR LWIR separately address multi domain body recognition problem use IARPA Janus Benchmark Multi domain Face IJB MDF dataset which enable matching short wave infrare SWIR MWIR LWIR image RGB VIS image leverage vision transformer architecture to establish benchmark result IJB MDF dataset extensive experiment provide valuable insight interrelation infrared domain adaptability vis pretraine model role local semantic feature body embedding effective training strategy small dataset additionally show finetune body model pretraine exclusively VIS datum simple combination cross entropy triplet loss achieve state art map score LLCM dataset,"Anirudh Nanduri, Siyuan Huang, Rama Chellappa",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10913,PolyRoof Precision Roof Polygonization Urban Residential Building Graph Neural network,grow demand detailed building roof datum have drive development automated extraction method to overcome inefficiency traditional approach particularly handle complex variation building geometry PolyWorld which integrate point detection graph neural network present promising solution reconstruct high detail building roof vector datum study enhance PolyWorld 's performance complex urban residential structure incorporate attention base backbone additional area segmentation loss dataset limitation experiment demonstrate improvement point position accuracy 1.33 pixel line distance accuracy 14.39 pixel notable increase reconstruction score 91.99 finding highlight potential advanced neural network architecture address challenge complex urban residential geometry,"Chaikal Amrullah, Daniel Panangian, Ksenia Bittner",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10912,JPEG Compliant Compression Human Machine report,Deep Neural Networks dnn have become integral part daily life especially vision relate application however conventional lossy image compression algorithm be primarily design Human Vision System HVS which can non trivially compromise dnn validation accuracy compression note \cite{liu2018deepn thus develop image compression algorithm human machine dnn be horizon to address challenge mention above paper first formulate image compression multi objective optimization problem which take human machine prespective account then solve linear combination propose novel distortion measure human machine dub Human machine Oriented Error HMOE develop Human Machine Oriented Soft decision Quantization HMOSDQ base HMOE lossy image compression algorithm human machine dnn fully comply JPEG format order to evaluate performance HMOSDQ finally conduct experiment two pre train well know DNN base image classifier name Alexnet \cite{alexnet VGG-16 \cite{simonyan2014VGG two subset ImageNet \cite{deng2009imagenet validation set one subset include image short side range 496 512 other include image short side range 376 to 384 result demonstrate HMOSDQ outperform default JPEG algorithm term rate accuracy rate distortion performance Alexnet compare default JPEG algorithm HMOSDQ can improve validation accuracy more $ 0.81\%$ $ 0.61 $ BPP equivalently reduce compression rate default JPEG $ 9.6\times$ maintain same validation accuracy,Linfeng Ye,13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10899,memory Efficient 3d High Resolution Medical Image Synthesis use CRF guide gan,Generative Adversarial Networks GANs have many potential medical imaging application limited memory Graphical Processing Units GPUs most current 3d GAN model be train low resolution medical image model can not scale high resolution be susceptible patchy artifact work propose end end novel GAN architecture that use Conditional random field CRF to model dependency can generate consistent 3d medical Images exploit memory to achieve purpose generator be divide two part training first part produce intermediate representation CRF be apply intermediate representation to capture correlation second part generator produce random sub volume image use subset intermediate representation structure have two advantage first correlation be model use feature generator be try to optimize second generator can generate full high resolution image inference experiment Lung ct Brain mri show architecture outperform state art have low memory usage less complexity,"Mahshid Shiri, Alessandro Bruno, Daniele Loiacono",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10898,trajectory Mamba Efficient Attention Mamba Forecasting Model base Selective SSM,motion prediction be crucial autonomous driving enable accurate forecasting future vehicle trajectory base historical input paper introduce Trajectory Mamba novel efficient trajectory prediction framework base selective state space model SSM conventional attention base model face challenge computational cost that grow quadratically number target hinder application highly dynamic environment response leverage SSM to redesign self attention mechanism encoder decoder architecture thereby achieve linear time complexity to address potential reduction prediction accuracy result modification attention mechanism propose joint polyline encode strategy to well capture association static dynamic contexts ultimately enhance prediction accuracy additionally to balance prediction accuracy inference speed adopt decoder that differ entirely encoder cross state space attention target agent share scene context allow SSM to interact shared scene representation decode thus infer different trajectory next prediction step model achieve state art result term inference speed parameter efficiency Argoverse 1 argoverse 2 dataset demonstrate four fold reduction flop compare exist method reduce parameter count 40 surpass performance vast majority previous method finding validate effectiveness Trajectory Mamba trajectory prediction task,"Yizhou Huang, Yihua Cheng, Kezhi Wang",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10886,taxonomic reasoning Rare Arthropods combine Dense Image Captioning RAG Interpretable Classification,context press climate change challenge significant biodiversity loss arthropod automate taxonomic classification organismal image be subject intense research however traditional AI pipeline base deep neural visual architecture such cnn ViTs face limitation such degraded performance long tail class inability to reason prediction integrate image captioning retrieval augment generation RAG large language model LLMs to enhance biodiversity monitoring show particular promise characterize rare unknown arthropod specie naive Vision Language Model VLM excel classify image common specie RAG model enable classification rare taxa match explicit textual description taxonomic feature contextual biodiversity text datum external source RAG model show promise reduce overconfidence enhance accuracy relative naive LLMs suggest viability capture nuance taxonomic hierarchy particularly challenge family genus level finding highlight potential modern vision language AI pipeline to support biodiversity conservation initiative emphasize role comprehensive datum curation collaboration citizen science platform to improve specie identification unknown specie characterization ultimately inform conservation strategy,"Nathaniel Lesperance, Sujeevan Ratnasingham, Graham W. Taylor",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10875,Convolutional Rectangular Attention Module,paper introduce novel spatial attention module that can be integrate convolutional network module guide model to pay attention most discriminative part image enable model to attain well performance end end training standard approach spatial attention map be generate position wise fashion observe result very irregular boundary could make difficult to generalize new sample method attention region be constrain to be rectangular rectangle be parametrize only 5 parameter allow well stability generalization new sample experiment method systematically outperform position wise counterpart thus provide novel useful spatial attention mechanism convolutional model besides module also provide interpretability concern ` ` where to look question help to know part input which model focus to produce prediction,"Hai-Vy Nguyen, Fabrice Gamboa, Sixin Zhang, Reda Chhaibi, Serge Gratton, Thierry Giaccone",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10872,TAIJI Textual Anchoring immunize Jailbreak Images Vision Language model,Vision Language Models VLMs have demonstrate impressive inference capability remain vulnerable jailbreak attack that can induce harmful unethical response exist defence method be predominantly white box approach that require access model parameter extensive modification make costly impractical many real world scenario black box defence have be propose often impose input constraint require multiple query limit effectiveness safety critical task such autonomous driving to address challenge propose novel black box defence framework call \textbf{t}extual \textbf{a}nchoring \textbf{i}mmunize \textbf{J}ailbreak \textbf{i}mage \textbf{TAIJI TAIJI leverage key phrase base textual anchoring to enhance model 's ability to assess mitigate harmful content embed visual textual prompt exist method TAIJI operate effectively single query inference preserve VLM 's performance benign task extensive experiment demonstrate TAIJI significantly enhance safety reliability vlm provide practical efficient solution real world deployment,"Xiangyu Yin, Yi Qi, Jinwei Hu, Zhen Chen, Yi Dong, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10860,ri3d few Shot Gaussian Splatting Repair Inpainting Diffusion Priors,paper propose ri3d novel 3dgs base approach that harness power diffusion model to reconstruct high quality novel view give sparse set input image key contribution be separate view synthesis process two task reconstruct visible region hallucinating missing region introduce two personalize diffusion model tailor one task specifically one model repair take render image input predict correspond high quality image which turn be use pseudo ground truth image to constrain optimization other model inpainte primarily focus hallucinating detail unobserved area to integrate model effectively introduce two stage optimization strategy first stage reconstruct visible area use repair model second stage reconstruct miss region inpainte model ensure coherence further optimization moreover augment optimization novel gaussian initialization method that obtain image depth combine 3d consistent smooth depth highly detailed relative depth demonstrate separate process two task address repair inpainte model produce result detailed texture visible missing region that outperform state art approach diverse set scene extremely sparse input,"Avinash Paliwal, Xilong Zhou, Wei Ye, Jinhui Xiong, Rakesh Ranjan, Nima Khademi Kalantari",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10832,Dual Codebook VQ enhance Image Reconstruction Reduced Codebook Size,Vector Quantization VQ technique face significant challenge codebook utilization limit reconstruction fidelity image modeling introduce Dual Codebook mechanism that effectively address limitation partition representation complementary global local component global codebook employ lightweight transformer concurrent update code vector local codebook maintain precise feature representation deterministic selection complementary approach be train scratch require pre trained knowledge experimental evaluation multiple standard benchmark dataset demonstrate state art reconstruction quality use compact codebook size 512 half size previous method that require pre training approach achieve significant FID improvement diverse image domain particularly excel scene face reconstruction task result establish Dual Codebook VQ efficient paradigm high fidelity image reconstruction significantly reduce computational requirement,"Parisa Boodaghi Malidarreh, Jillur Rahman Saurav, Thuong Le Hoai Pham, Amir Hajighasemi, Anahita Samadi, Saurabh Shrinivas Maydeo, Mohammad Sadegh Nasr, Jacob M. Luber",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10781,large scale Pre training Grounded Video Caption Generation,propose novel approach captioning object ground video where object caption be ground video temporally dense bounding box introduce follow contribution first present large scale automatic annotation method that aggregate caption ground bounding box individual frame temporally dense consistent bounding box annotation apply approach HowTo100 m dataset to construct large scale pre training dataset name howtoground1m. also introduce ground Video Caption Generation model dub GROVE pre train model HowToGround1M. Second introduce new dataset call iGround 3500 video manually annotate caption dense spatio temporally ground bounding box allow to measure progress challenging problem as well fine tune model small scale high quality datum third demonstrate approach achieve state art result propose iGround dataset compare number baseline as well vidstg ActivityNet Entities dataset perform extensive ablation that demonstrate importance pre training use automatically annotate HowToGround1 m dataset follow fine tuning manually annotate iground dataset validate key technical contribution model,"Evangelos Kazakos, Cordelia Schmid, Josef Sivic",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10779,Power one Single Example be take segmentation vlm,large scale vision language model VLMs train extensive dataset image text pair exhibit strong multimodal understanding capability implicitly learn association textual description image region emergent ability enable zero shot object detection segmentation use technique that rely text image attention map necessarily train abundant label segmentation dataset however performance such method depend heavily prompt engineering manually select layer head choice attention layer work demonstrate rather rely solely textual prompt provide single visual example category fine tune text image attention layer embedding significantly improve performance additionally propose learn ensemble few shoot fine tune multiple layer prompt entropy base ranking selection mechanism text image attention layer be propose to identify top perform layer need segmentation label eliminate need hyper parameter selection text image attention layer provide more flexible scalable solution open vocabulary segmentation show approach yield strong zero shot performance far enhance fine tuning single visual example moreover demonstrate method finding be general can be apply various vision language model VLMs,"Mir Rayat Imtiaz Hossain, Mennatullah Siam, Leonid Sigal, James J. Little",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10777,HeightFormer Learning Height Prediction Voxel feature Roadside Vision Centric 3d Object Detection transformer,roadside vision centric 3d object detection have receive increase attention recent year expand perception range autonomous vehicle enhance road safety previous method focus predict pixel height rather depth make significant gain roadside visual perception be limit perspective property near large far small image feature make difficult network to understand real dimension object 3d world BEV feature voxel feature present real distribution object 3d world compare image feature however BEV feature tend to lose detail lack explicit height information voxel feature be computationally expensive inspire insight efficient framework learn height prediction voxel feature transformer be propose dub HeightFormer group voxel feature local height sequence utilize attention mechanism to obtain height distribution prediction subsequently local height sequence be reassemble to generate accurate 3d feature propose method be apply two large scale roadside benchmark DAIR V2X rope3d. extensive experiment be perform HeightFormer outperform state art method roadside vision centric 3d object detection task,"Zhang Zhang, Chao Sun, Chao Yue, Da Wen, Yujie Chen, Tianze Wang, Jianghao Leng",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10772,flowtok flow seamlessly text Image Tokens,bridge different modality lie heart cross modality generation conventional approach treat text modality conditioning signal that gradually guide denoising process Gaussian noise target image modality explore much simple paradigm directly evolve text image modality flow matching require project modality share latent space which pose significant challenge inherently different representation text be highly semantic encode 1d token image be spatially redundant represent 2D latent embedding to address introduce FlowTok minimal framework that seamlessly flow text image encode image compact 1d token representation compare prior method design reduce latent space size 3.3x image resolution 256 eliminate need complex conditioning mechanism noise scheduling moreover FlowTok naturally extend image text generation same formulation streamlined architecture center compact 1d token FlowTok be highly memory efficient require significantly few training resource achieve much fast sample speed deliver performance comparable state art model Code will be available https url,"Ju He, Qihang Yu, Qihao Liu, Liang-Chieh Chen",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10759,Clothes change Person re identification base Skeleton Dynamics,Clothes change Person Re Identification ReID aim to recognize same individual different video capture various time location task be particularly challenging change appearance such clothing hairstyle accessory propose Clothes change ReID method that use only skeleton datum do not use appearance feature traditional ReID method often depend appearance feature lead decrease accuracy when clothing change approach utilize spatio temporal Graph Convolution Network GCN encoder to generate skeleton base descriptor individual testing improve accuracy aggregate prediction multiple segment video clip evaluate CCVID dataset several different pose estimation model method achieve state art performance offer robust efficient solution Clothes change ReID,"Asaf Joseph, Shmuel Peleg",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10745,unify 2d 3d Vision Language understanding,progress 3d vision language learning have be hinder scarcity large scale 3d dataset introduce univlg unified architecture 2d 3d vision language understanding that bridge gap exist 2d centric model rich 3d sensory datum available embody system approach initialize most model weight pre trained 2d model train 2d 3d vision language datum propose novel language condition mask decoder share 2D 3d modality to ground object effectively RGB RGB d image outperform box base approach to far reduce domain gap 2D 3d incorporate 2D to-3d lift strategy enable UniVLG to utilize 2D datum to enhance 3d performance innovation model achieve state art performance multiple 3d vision language grounding task demonstrate potential transfer advance 2D vision language learning data constrain 3d domain furthermore co training 2D 3d datum enhance performance modality sacrifice 2D capability remove reliance 3d mesh reconstruction ground truth object proposal UniVLG set new standard realistic embody align evaluation code additional visualization be available $ \href{this https http URL}$.,"Ayush Jain, Alexander Swerdlow, Yuzhou Wang, Sergio Arnaud, Ada Martin, Alexander Sax, Franziska Meier, Katerina Fragkiadaki",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10740,Subnet Aware Dynamic Supernet Training Neural Architecture Search,n shot neural architecture search NAS exploit supernet contain candidate subnet give search space subnet be typically train static training strategy e.g. use same learning rate LR scheduler optimizer subnet however do not consider individual subnet have distinct characteristic lead two problem 1 supernet training be biased low complexity subnet unfairness 2 momentum update supernet be noisy noisy momentum present dynamic supernet training technique to address problem adjust training strategy adaptive subnet specifically introduce complexity aware LR scheduler CaLR that control decay ratio LR adaptive complexity subnet which alleviate unfairness problem also present momentum separation technique MS group subnet similar structural characteristic use separate momentum group avoid noisy momentum problem approach can be applicable various N shoot NAS method marginal cost improve search performance drastically validate effectiveness approach various search space e.g. NAS Bench-201 Mobilenet space dataset e.g. CIFAR-10/100 ImageNet,"Jeimin Jeon, Youngmin Oh, Junghyup Lee, Donghyeon Baek, Dohyung Kim, Chanho Eom, Bumsub Ham",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10738,Visual Polarization Measurement use Counterfactual Image generation,political polarization be significant issue american politic influence public discourse policy consumer behavior study polarization news medium have extensively focus verbal content non verbal element particularly visual content have receive less attention complexity high dimensionality image datum traditional descriptive approach often rely feature extraction image lead biased polarization estimate information loss paper introduce Polarization Measurement use Counterfactual Image Generation PMCIG method which combine economic theory generative model multi modal deep learning to fully utilize richness image datum provide theoretically ground measure polarization visual content apply framework decade long dataset feature 30 prominent politician 20 major news outlet identify significant polarization visual content notable variation outlet politician news outlet level observe significant heterogeneity visual slant outlet such Daily Mail Fox News Newsmax tend to favor republican politician visual content Washington Post USA Today New York Times exhibit slant favor democratic politician politician level result reveal substantial variation polarized coverage Donald Trump Barack Obama most polarizing figure Joe Manchin Susan Collins be least finally conduct series validation test demonstrate consistency propose measure external measure medium slant that rely non image base source,"Mohammad Mosaffa, Omid Rafieian, Hema Yoganarasimhan",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10732,Sparse Dictionary Learning Image Recovery Iterative Shrinkage,paper study sparse code problem context sparse dictionary learning image recovery end consider compare several state art sparse optimization method construct use shrinkage operation mathematical setting method consider online approach algorithmical basis together basis pursuit denoising problem that arise convex optimization approach dictionary learning problem dedicated construction dataset correspond dictionary study effect enlarge underlying learning database reconstruction quality make use several error measure study illuminate choice optimization method may be practically important context availability training datum context different setting training datum may be consider part study illuminate computational efficiency assessed optimization method,"Shima Shabani, Mohammadsadegh Khoshghiaferezaee, Michael Breuß",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10731,leverage Vision Language Embeddings Zero Shot Learning Histopathology Images,zero shot learning hold tremendous potential histopathology image analysis enable model to generalize unseen class extensive label datum recent advancement vision language model VLMs have expand capability ZSL allow model to perform task task specific fine tuning however apply vlm histopathology present considerable challenge complexity histopathological imagery nuanced nature diagnostic task paper propose novel framework call Multi Resolution Prompt guide Hybrid Embedding MR PHE to address challenge zero shot histopathology image classification MR PHE leverage multiresolution patch extraction to mimic diagnostic workflow pathologist capture fine grain cellular detail broad tissue structure critical accurate diagnosis introduce hybrid embed strategy that integrate global image embedding weight patch embedding effectively combine local global contextual information additionally develop comprehensive prompt generation selection framework enrich class description domain specific synonyms clinically relevant feature to enhance semantic understanding similarity base patch weighting mechanism assign attention like weight patch base relevance class embedding emphasize diagnostically important region classification approach utilize pretraine VLM CONCH ZSL require domain specific fine tuning offer scalability reduce dependence large annotated dataset experimental result demonstrate MR PHE not only significantly improve zero shot classification performance histopathology dataset also often surpass fully supervise model,"Md Mamunur Rahaman, Ewan K. A. Millar, Erik Meijering",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10730,3d Extended object tracking base Extruded B Spline Side View profile,object tracking be essential task autonomous system advancement 3d sensor system can well perceive surrounding use effective 3d Extended Object Tracking EOT method base observation common road user be symmetrical right left side travel direction focus side view profile object order to leverage development 2D EOT balance number parameter shape model tracking algorithm propose method 3d extend object tracking EOT describe side view profile object b spline curve form extrusion to obtain 3d extent use b spline curve exploit flexible representation power allow control point to move freely algorithm be develop Extended Kalman Filter EKF through evaluation method use simulated traffic scenario different vehicle model realworld open dataset contain radar lidar datum,"Longfei Han, Klaus Kefferpütz, Jürgen Beyerer",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10719,Long Video Audio Synthesis Multi agent collaboration,video audio synthesis which generate synchronize audio visual content critically enhance viewer immersion narrative coherence film interactive medium however video audio dubbing long form content remain unsolved challenge dynamic semantic shift temporal misalignment absence dedicated dataset existing method excel short video falter long scenario e.g. movie fragmented synthesis inadequate cross scene consistency propose LVAS Agent novel multi agent framework that emulate professional dubbing workflow collaborative role specialization approach decompose long video synthesis four step include scene segmentation script generation sound design audio synthesis central innovation include discussion correction mechanism scene script refinement generation retrieval loop temporal semantic alignment to enable systematic evaluation introduce LVAS Bench first benchmark 207 professionally curate long video span diverse scenario experiment demonstrate superior audio visual alignment baseline method,"Yehang Zhang, Xinli Xu, Xiaojie Xu, Li Liu, Yingcong Chen",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10718,Team NYCU Defactify4 Robust Detection Source Identification AI generate Images use CNN CLIP base model,rapid advancement generative AI AI generate image have become increasingly realistic raise concern creativity misinformation content authenticity detect such image identify source model have become critical challenge ensure integrity digital medium paper tackle detection AI generate image identify source model use CNN CLIP vit classifier CNN base classifier leverage EfficientNet B0 backbone feed RGB channel frequency feature reconstruction error CLIP ViT adopt pretraine clip image encoder to extract image feature SVM to perform classification evaluate Defactify 4 dataset method demonstrate strong performance task CLIP ViT show superior robustness to image perturbation compare baseline aeroblade OCC CLIP approach achieve competitive result notably method rank Top-3 overall Defactify 4 competition highlight effectiveness generalizability implementation can be find https url,"Tsan-Tsung Yang, I-Wei Chen, Kuan-Ting Chen, Shang-Hsuan Chiang, Wen-Chih Peng",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10713,hicmamba enhance Hi C Resolution identify 3d Genome Structures State Space Modeling,hi C technology measure genome wide interaction frequency provide powerful tool study 3d genomic structure nucleus however high sequence cost technical challenge often result Hi c datum limited coverage lead imprecise estimate chromatin interaction frequency to address issue present novel deep learning base method HiCMamba to enhance resolution Hi C contact map use state space model adopt unet base auto encoder architecture to stack propose holistic scan block enable perception global local receptive field multiple scale experimental result demonstrate HiCMamba outperform state art method significantly reduce computational resource furthermore 3d genome structure include topologically associate domain TADs loop identify contact map recover HiCMamba be validate associate epigenomic feature work demonstrate potential state space model foundational framework field Hi C resolution enhancement,"Minghao Yang, Zhi-An Huang, Zhihang Zheng, Yuqiao Liu, Shichen Zhang, Pengfei Zhang, Hui Xiong, Shaojun Tang",13/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10705,enhanced Continual Learning Vision Language Models Model Fusion,Vision Language Models VLMs represent breakthrough artificial intelligence integrate visual textual modality to achieve impressive zero shot capability however VLMs be susceptible catastrophic forgetting when sequentially fine tuned multiple downstream task exist continual learning method vlm often rely heavily additional reference dataset compromise zero shot performance be limit parameter efficient fine tune scenario paper propose Continual Decoupling Unifying ConDU novel approach introduce model fusion continual learning vlm ConDU maintain unified model task trigger prototype set employ iterative process decouple task specific model previous task unify model newly learn task additionally introduce inference strategy zero shot scenario aggregate prediction multiple decouple task specific model extensive experiment various setting show ConDU achieve up 2\% improvement average performance see task compare state art baseline also enhance zero shot capability relative original VLM,"Haoyuan Gao, Zicong Zhang, Yuqi Wei, Linglan Zhao, Guilin Li, Yexin Li, Linghe Kong, Weiran Huang",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10704,error Analyses Auto Regressive Video Diffusion model Unified framework,variety Auto Regressive Video Diffusion Models ARVDM have achieve remarkable success generate realistic long form video however theoretical analysis model remain scant work develop theoretical underpinning model use insight to improve performance exist model first develop Meta ARVDM unified framework ARVDMs that subsume most exist method use Meta ARVDM analyze kl divergence video generate Meta ARVDM true video analysis uncover two important phenomena inherent ARVDM error accumulation memory bottleneck derive information theoretic impossibility result show memory bottleneck phenomenon can not be avoid to mitigate memory bottleneck design various network structure to explicitly use more past frame also achieve significantly improve trade off mitigation memory bottleneck inference efficiency compress frame experimental result DMLab Minecraft validate efficacy method experiment also demonstrate Pareto frontier error accumulation memory bottleneck different method,"Jing Wang, Fengzhuo Zhang, Xiaoli Li, Vincent Y. F. Tan, Tianyu Pang, Chao Du, Aixin Sun, Zhuoran Yang",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10701,Video Individual Counting Moving Drones,Video Individual Counting VIC have receive increase attention recently importance intelligent video surveillance exist work be limit two aspect i.e. dataset method previous crowd count dataset be capture fix rarely move camera relatively sparse individual restrict evaluation highly varying view time crowded scene VIC method have be propose base localization then association localization then classification may not perform well difficulty accurate localization crowded small target challenge scenario to address issue collect MovingDroneCrowd Dataset propose density map base VIC method different exist dataset dataset consist video capture fast move drone crowded scene diverse illumination shoot height angle other localize individual propose depth wise Cross Frame Attention DCFA module which directly estimate inflow outflow density map learn share density map consecutive frame inflow density map frame be sum up to obtain number unique pedestrian video experiment dataset publicly available one show superiority method state art VIC highly dynamic complex crowded scene dataset code will be release publicly,"Yaowu Fan, Jia Wan, Tao Han, Antoni B. Chan, Andy J. Ma",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10700,TA V2A Textually Assisted Video Audio generation,artificial intelligence generate content AIGC continue to evolve video audio V2A generation have emerge key area promising application multimedia editing augment reality automate content creation Transformer Diffusion model have advance audio generation significant challenge persist extract precise semantic information video current model often lose sequential context rely solely frame base feature to address present TA V2A method that integrate language audio video feature to improve semantic representation latent space incorporate large language model enhanced video comprehension approach leverage text guidance to enrich semantic expression diffusion model base system utilize automate text modulation to enhance inference quality efficiency provide personalize control text guide interface integration enhance semantic expression ensure temporal alignment lead more accurate coherent video audio generation,"Yuhuan You, Xihong Wu, Tianshu Qu",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10699,Test Time Discovery Hashing Memory,introduce Test Time Discovery TTD novel task that address class shift testing require model to simultaneously identify emerge category preserve previously learn one key challenge TTD be distinguish newly discover class already identify to address propose training free hash base memory mechanism that enhance class discovery fine grain comparison past test sample leverage characteristic unknown class approach introduce hash representation base feature scale direction utilize Locality Sensitive Hashing LSH efficient grouping similar sample enable test sample to be easily quickly compare relevant past instance furthermore design collaborative classification strategy combine prototype classifier know class lsh base classifier novel one to enhance reliability incorporate self correction mechanism that refine memory label hash base neighbor retrieval ensure more stable accurate class assignment experimental result demonstrate method achieve good discovery novel category maintain performance know class establish new paradigm model testing code be available https url,"Fan Lyu, Tianle Liu, Zhang Zhang, Fuyuan Hu, Liang Wang",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10697,zero Shot Subject Centric Generation Creative Application use Entropy Fusion,generative model be widely use visual content creation however current text image model often face challenge practical application such textile pattern design meme generation presence unwanted element that be difficult to separate exist method meanwhile subject reference generation have emerge key research trend highlight need technique that can produce clean high quality subject image effectively remove extraneous component to address challenge introduce framework reliable subject centric image generation work propose entropy base feature weight fusion method to merge informative cross attention feature obtain sample step pretraine text image model FLUX enable precise mask prediction subject centric generation additionally have develop agent framework base Large Language Models LLMs that translate user casual input more descriptive prompt lead highly detailed image generation simultaneously agent extract primary element prompt to guide entropy base feature fusion ensure focus primary element generation extraneous component experimental result user study demonstrate method generate high quality subject centric image outperform exist method other possible pipeline highlight effectiveness approach,"Kaifeng Zou, Xiaoyi Feng, Peng Wang, Tao Huang, Zizhou Huang, Zhang Haihang, Yuntao Zou, Dagang Li",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10696,Neighboring Autoregressive Modeling efficient Visual Generation,visual autoregressive model typically adhere raster order ` ` next token prediction paradigm which overlook spatial temporal locality inherent visual content specifically visual token exhibit significantly strong correlation spatially temporally adjacent token compare that be distant paper propose Neighboring Autoregressive Modeling NAR novel paradigm that formulate autoregressive visual generation progressive outpainte procedure follow near far ` ` next neighbor prediction mechanism start initial token remain token be decode ascend order Manhattan distance initial token spatial temporal space progressively expand boundary decode region to enable parallel prediction multiple adjacent token spatial temporal space introduce set dimension orient decode head predict next token mutually orthogonal dimension inference token adjacent decoded token be process parallel substantially reduce model forward step generation experiment imagenet$256\time 256 $ UCF101 demonstrate NAR achieve 2.4$\times$ 8.6$\times$ high throughput respectively obtain superior FID FVD score image video generation task compare par-4x approach when evaluate text image generation benchmark GenEval NAR 0.8b parameter outperform Chameleon-7B use merely 0.4 training datum code be available https url,"Yefei He, Yuanyu He, Shaoxuan He, Feng Chen, Hong Zhou, Kaipeng Zhang, Bohan Zhuang",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10693,Knowledge Consultation Semi supervised Semantic segmentation,semi supervised Semantic Segmentation reduce reliance extensive annotation use unlabeled datum state art model to improve overall performance success deep co training method underlie mechanism remain underexplored work revisit Cross Pseudo Supervision dual heterogeneous backbone introduce Knowledge Consultation SegKC to far enhance segmentation performance propose SegKC achieve significant improvement Pascal Cityscapes benchmark mIoU score 87.1 89.2 89.8 Pascal VOC 1/4 1/2 full split partition respectively maintain compact model architecture,"Thuan Than, Nhat-Anh Nguyen-Dang, Dung Nguyen, Salwa K. Al Khatib, Ahmed Elhagry, Hai Phan, Yihui He, Zhiqiang Shen, Marios Savvides, Dang Huynh",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10692,explore good way UAV visual localization Low altitude multi view observation condition Benchmark,"absolute Visual Localization AVL enable Unmanned Aerial Vehicle UAV to determine position GNSS deny environment establish geometric relationship UAV image geo tag reference map many previous work have achieve AVL image retrieval matching technique research low altitude multi view scenario still remain limited low altitude multi view condition present great challenge extreme viewpoint change to explore good UAV AVL approach such condition propose benchmark firstly large scale low altitude Multi view dataset call AnyVisLoc be construct dataset include 18,000 image capture multiple scene altitude 2.5d reference map contain aerial photogrammetry map historical satellite map secondly unified framework be propose to integrate state art avl approach comprehensively test performance well combine method be choose baseline key factor that influence localization accuracy be thoroughly analyze base baseline achieve 74.1 localization accuracy 5 m Low altitude multi view condition addition novel retrieval metric call PDM@K be introduce well align characteristic UAV AVL task overall benchmark reveal challenge low altitude multi view UAV AVL provide valuable guidance future research dataset code be available https url","Yibin Ye, Xichao Teng, Shuo Chen, Zhang Li, Leqi Liu, Qifeng Yu, Tao Tan",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10691,reasoning be need Video Generalization Counterfactual Benchmark sub question evaluation,counterfactual reasoning be crucial robust video understanding remain underexplored exist multimodal benchmark paper introduce \textbf{cover \textbf{\underline{co}}unterfactual \textbf{\underline{V}}id\textbf{\underline{E}}o \textbf{\underline{r}}easoning multidimensional multimodal benchmark that systematically evaluate mllm abstract concrete perception cognition dimension prior multimodal benchmark COVER decompose complex query structured sub question enable fine grain reasoning analysis experiment commercial open source model reveal strong correlation sub question accuracy counterfactual reasoning performance highlight role structured inference video understanding furthermore result suggest key insight enhance reasoning capability model be essential improve robustness video understanding COVER establish new standard assess mllm logical reasoning ability dynamic environment,"Qiji Zhou, Yifan Gong, Guangsheng Bao, Hongjie Qiu, Jinqiang Li, Xiangrong Zhu, Huajian Zhang, Yue Zhang",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10687,context guide responsible Data Augmentation Diffusion model,generative diffusion model offer natural choice datum augmentation when train complex vision model however ensure reliability generative content augmentation sample remain open challenge number technique utilize generative image to strengthen model training remain unclear how to utilize combination natural generative image rich supervisory signal effective model induction regard propose text image T2I datum augmentation method name DiffCoRe Mix that compute set generative counterpart training sample explicitly constrain diffusion model that leverage sample base context negative prompt reliable augmentation sample generation to preserve key semantic axis also filter out undesired generative sample augmentation process end propose hard cosine filtration embed space CLIP approach systematically mix natural generative image pixel patch level extensively evaluate technique ImageNet-1K tiny ImageNet-200 cifar-100 flowers102 CUB Birds Stanford Cars caltech dataset demonstrate notable increase performance board achieve to $ \sim 3\%$ absolute gain top-1 accuracy state art method show comparable computational overhead code be publicly available https url,"Khawar Islam, Naveed Akhtar",12/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10686,MaskAttn UNet Mask Attention drive Framework Universal Low Resolution Image segmentation,low resolution image segmentation be crucial real world application such robotic augment reality large scale scene understanding where high resolution datum be often unavailable computational constraint to address challenge propose MaskAttn UNet novel segmentation framework that enhance traditional u net architecture mask attention mechanism model selectively emphasize important region suppress irrelevant background thereby improve segmentation accuracy cluttered complex scene conventional U net variant MaskAttn UNet effectively balance local feature extraction broad contextual awareness make particularly well suited low resolution input evaluate approach three benchmark dataset input image rescale 128x128 demonstrate competitive performance semantic instance panoptic segmentation task result show MaskAttn UNet achieve accuracy comparable state art method significantly low computational cost transformer base model make efficient scalable solution low resolution segmentation resource constrain scenario,"Anzhe Cheng, Chenzhong Yin, Yu Chang, Heng Ping, Shixuan Li, Shahin Nazarian, Paul Bogdan",11/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10685,VFM UDA++ improve Network Architectures Data Strategies Unsupervised Domain Adaptive Semantic Segmentation,Unsupervised Domain Adaptation UDA have show remarkably strong generalization label source domain unlabeled target domain require relatively little datum same time large scale pretraining label so call Vision Foundation Models VFMs have also significantly improve downstream generalization motivate to research how UDA can well utilize benefit vfm early work VFM UDA show state art sota result can be obtain replace non VFM VFM encoder SotA UDA method work take one step far improve UDA architecture data strategy observe VFM UDA current SotA UDA method do not use multi scale inductive bias feature distillation loss be know can improve generalization address limitation VFM UDA++ obtain SotA generalization standard UDA benchmark +5.3 mIoU. inspire work VFM fine tuning such Rein also explore benefit add more easy generate synthetic source datum easy to obtain unlabeled target datum realize +6.6 mIoU current SotA. improvement VFM UDA++ be most significant small model however show large model obtain generalization be only 2.8 miou fully supervise learning target label base strong result provide essential insight to help researcher practitioner advance UDA,"Brunó B. Englert, Gijs Dubbelman",11/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10684,open World Skill Discovery Unsegmented demonstration,learn skill open world environment be essential develop agent capable handle variety task combine basic skill online demonstration video be typically long unsegmented make difficult to segment label skill identifier exist method that rely sequence sampling human labeling have develop self supervise learning base approach to segment long video series semantic aware skill consistent segment draw inspiration human cognitive event segmentation theory introduce Skill Boundary Detection SBD annotation free temporal video segmentation algorithm sbd detect skill boundary video leverage prediction error pretraine unconditional action prediction model approach be base assumption significant increase prediction error indicate shift skill be execute evaluate method Minecraft rich open world simulator extensive gameplay video available online SBD generate segment improve average performance condition policy 63.7 52.1 short term atomic skill task correspond hierarchical agent 11.3 20.8 long horizon task method can leverage diverse YouTube video to train instruction follow agent project page can be find https url,"Jingwen Deng, Zihao Wang, Shaofei Cai, Anji Liu, Yitao Liang",11/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10678,VRMDiff Text Guided Video Referring Matting Generation Diffusion,"propose new task video refer matting which obtain alpha matte specified instance inputte refer caption treat dense prediction task mat video generation leverage text video alignment prior video diffusion model to generate alpha matte that be temporally coherent closely related corresponding semantic instance moreover propose new Latent constructive loss to far distinguish different instance enable more controllable interactive matting additionally introduce large scale video refer mat dataset 10,000 video good knowledge be first dataset that concurrently contain caption video instance level alpha matte extensive experiment demonstrate effectiveness method dataset code be available https url","Lehan Yang, Jincen Song, Tianlong Wang, Daiqing Qi, Weili Shi, Yuheng Liu, Sheng Li",11/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10665,Small Vision Language model survey Compact Architectures Techniques,emergence small vision language model sVLMs mark critical advancement multimodal AI enable efficient processing visual textual datum resource constrain environment survey offer comprehensive exploration svlm development present taxonomy architecture transformer base mamba base hybrid that highlight innovation compact design computational efficiency technique such knowledge distillation lightweight attention mechanism modality pre fusion be discuss enabler high performance reduced resource requirement depth analysis model tinygpt V MiniGPT-4 VL Mamba identify trade off accuracy efficiency scalability persistent challenge include datum bias generalization complex task be critically examine propose pathway address consolidate advancement sVLMs work underscore transformative potential accessible AI set foundation future research efficient multimodal system,"Nitesh Patnaik, Navdeep Nayak, Himani Bansal Agrawal, Moinak Chinmoy Khamaru, Gourav Bal, Saishree Smaranika Panda, Rishi Raj, Vishal Meena, Kartheek Vadlamani",09/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10661,CeTAD Towards Certified Toxicity Aware Distance Vision Language model,recent advance large vision language model VLMs have demonstrate remarkable success wide range visual understanding task however robustness model jailbreak attack remain open challenge work propose universal certify defence framework to safeguard vlm rigorously potential visual jailbreak attack first propose novel distance metric to quantify semantic discrepancy malicious intended response capture subtle difference often overlook conventional cosine similarity base measure then devise regress certification approach that employs randomize smoothing to provide formal robustness guarantee adversarial structural perturbation even black box setting complement feature space defence introduce noise distribution e.g. Gaussian Laplacian latent embedding to safeguard pixel level structure level perturbation result highlight potential formally ground integrate strategy build more resilient trustworthy vlm,"Xiangyu Yin, Jiaxu Liu, Zhen Chen, Jinwei Hu, Yi Dong, Xiaowei Huang, Wenjie Ruan",08/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10660,text to-3D Generation use Jensen Shannon Score Distillation,score distillation sampling be effective technique to generate 3d model text prompt utilize pre train large scale text image diffusion model guidance however produce 3d asset tend to be saturating smoothing limited diversity issue be result reverse Kullback Leibler KL divergence objective which make optimization unstable result mode seek behavior paper derive bounded score distillation objective base Jensen Shannon divergence JSD which stabilize optimization process produce high quality 3d generation JSD can match well generated target distribution therefore mitigate mode seek provide practical implementation JSD utilize theory generative adversarial network to define approximate objective function generator assume discriminator be well train assume discriminator follow log odd classifier propose minority sample algorithm to estimate gradient propose objective provide practical implementation JSD conduct theoretical empirical study to validate method experimental result T3Bench demonstrate method can produce high quality diversified 3d asset,"Khoi Do, Binh-Son Hua",08/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.10653,Video Anomaly Detection Structured Keywords,paper focus detect anomaly surveillance video use keyword leverage foundational model feature representation generalization capability present novel lightweight pipeline anomaly classification use keyword weight pipeline employ two stage process induction follow deduction induction description be generate normal anomalous frame to identify assign weight relevant keyword deduction inference frame description be convert keyword encoding use induction derive weight input neural network anomaly classification achieve comparable performance three benchmark UCSD ped2 Shanghai Tech CUHK Avenue ROC AUC score 0.865 0.745 0.742 respectively result be achieve temporal context make such system viable real time application model improve implementation setup interpretability inference speed surveillance device edge introduce performance trade off other video anomaly detection system generalization capability open source foundational model improve model demonstrate exclusive use text feature representation be promising direction efficient real time interpretable video anomaly detection,Thomas Foltz,07/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11650,Centaur Robust end end Autonomous Driving Test Time training,how can rely end end autonomous vehicle 's complex decision make system deployment one common solution be to have ` ` fallback layer that check plan trajectory rule violation replace pre define safe action necessary approach involve adjust planner 's decision to minimize pre define ` ` cost function use additional system prediction such road layout detect obstacle however pre program rule cost function can not learn improve new training datum often result overly conservative behavior work propose Centaur Cluster Entropy test time training use Uncertainty which update planner 's behavior test time training rely hand engineer rule cost function instead measure minimize uncertainty planner 's decision develop novel uncertainty measure call Cluster Entropy which be simple interpretable compatible state art planning algorithm use datum collect prior test time time step perform update model 's parameter use gradient that minimize Cluster Entropy only sole gradient update prior inference Centaur exhibit significant improvement rank first navtest leaderboard notable gain safety critical metric such time to collision to provide detailed insight scenario basis also introduce navsafe challenging new benchmark which highlight previously undiscovered failure mode drive model,"Chonghao Sima, Kashyap Chitta, Zhiding Yu, Shiyi Lan, Ping Luo, Andreas Geiger, Hongyang Li, Jose M. Alvarez",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11629,treemeshgpt Artistic Mesh Generation Autoregressive Tree sequencing,introduce TreeMeshGPT autoregressive Transformer design to generate high quality artistic mesh align input point cloud instead conventional next token prediction autoregressive Transformer propose novel Autoregressive Tree sequence where next input token be retrieve dynamically grow tree structure that be build triangle adjacency face mesh sequence enable mesh to extend locally last generate triangular face step therefore reduce training difficulty improve mesh quality approach represent triangular face two token achieve compression rate approximately 22 compare naive face tokenization efficient tokenization enable model to generate highly detailed artistic mesh strong point cloud conditioning surpass previous method capacity fidelity furthermore method generate mesh strong normal orientation constraint minimize flip normal commonly encounter previous method experiment show TreeMeshGPT enhance mesh generation quality refined detail normal orientation consistency,"Stefan Lionar, Jiabin Liang, Gim Hee Lee",14/03/2025,Computer Vision and Pattern Recognition
10.48550./arXiv.2503.11630,time scale redundancy prosody linguistic context,spoken language speaker transmit information not only use word also rich array non verbal signal which include prosody auditory feature speech however previous study have show prosodic feature exhibit significant redundancy past future word here examine time scale relationship how many word past future contribute predict prosody find scale differ past future word Prosody 's redundancy past word extend approximately 3 8 word redundancy future word be limited just 1 2 word finding indicate prosody future relationship reflect local word dependency short scale process such next word prediction prosody past relationship unfold long time scale latter suggest prosody serve to emphasize early information that may be challenge listener to process give limit cognitive resource real time communication result highlight role prosody shape efficient communication,"Tamar I. Regev, Chiebuka Ohams, Shaylee Xie, Lukas Wolf, Evelina Fedorenko, Alex Warstadt, Ethan Wilcox, Tiago Pimentel",14/03/2025,Computation and Language
10.48550./arXiv.2503.11614,Neutralizing Bias LLM Reasoning use Entailment Graphs,llm be often claim to be capable Natural Language Inference NLI which be widely regard cornerstone more complex form reasoning however recent work show LLMs still suffer hallucination NLI attestation bias where LLMs overly rely propositional memory to build shortcut to solve issue design unsupervised framework to construct counterfactual reasoning datum fine tune llm to reduce attestation bias to measure bias reduction build bias adversarial variant NLI dataset randomly replace predicate premise keep hypothesis unchanged extensive evaluation show framework can significantly reduce hallucination attestation bias then far evaluate LLMs fine tune framework original NLI dataset bias neutralize version where original entity be replace randomly sample one extensive result show framework consistently improve inferential performance original bias neutralize NLI dataset,"Liang Cheng, Tianyi Li, Zhaowei Wang, Tianyang Liu, Mark Steedman",14/03/2025,Computation and Language
10.48550./arXiv.2503.11593,do Construction Distributions Shape Formal Language learning german babylm,analyze influence utterance level construction distribution german child direct speech result formal linguistic competence underlie learn trajectory small language model train novel collection developmentally plausible language datum German find trajectory be surprisingly robust markedly different distribution construction training datum which have little effect final accuracy almost effect global learning trajectory syntax learning benefit more complex utterance lexical learning culminate well score more fragmentary datum argue LMs train developmentally plausible datum can contribute debate how rich impoverished linguistic stimulus actually be,"Bastian Bunzeck, Daniel Duran, Sina Zarrieß",14/03/2025,Computation and Language
10.48550./arXiv.2503.11509,tikzero Zero Shot Text Guided Graphics Program Synthesis,rise generative AI synthesize figure text caption become compelling application however achieve high geometric precision editability require represent figure graphic program language TikZ align training datum i.e. graphic program caption remain scarce meanwhile large amount unaligned graphic program caption raster image be more readily available reconcile disparate data source present TikZero which decouple graphic program generation text understanding use image representation intermediary bridge enable independent training graphic program caption image allow zero shot text guide graphic program synthesis inference show method substantially outperform baseline that can only operate caption align graphic program furthermore when leverage caption align graphic program complementary training signal TikZero match exceed performance much large model include commercial system GPT-4o code dataset select model be publicly available,"Jonas Belouadi, Eddy Ilg, Margret Keuper, Hideki Tanaka, Masao Utiyama, Raj Dabre, Steffen Eger, Simone Paolo Ponzetto",14/03/2025,Computation and Language
10.48550./arXiv.2503.11426,text compression Efficient Language generation,challenge prevail assumption LLMs must rely fully sub word token high quality text generation end propose Generative Pretrained Thoughtformer GPTHF hierarchical transformer language model capable text generation compress text sentence embedding employ sentence attention mechanism GPTHF retain GPT 's architecture modify only token interaction dynamic sparse attention mask experiment show GPTHF achieve up order magnitude improvement flop efficiency threefold increase runtime speed compare equally sized GPT model low size regime be achieve unique generation method that caches reuse sentence embedding allow significant portion input to bypass large part network,"David Gu, Peter Belcak, Roger Wattenhofer",14/03/2025,Computation and Language
10.48550./arXiv.2503.11381,Modeling Subjectivity Cognitive Appraisal Language model,utilization language model interdisciplinary human center study grow expectation model capability continue to evolve excelling conventional task model be recently expect to perform well user centric measurement involve confidence human dis)agreement factor that reflect subjective preference modeling subjectivity play essential role cognitive science have be extensively study remain under explore NLP community light gap explore how language model can harness subjectivity conduct comprehensive experiment analysis various scenario use fine tune model prompt base large language model LLMs quantitative qualitative experimental result indicate exist post hoc calibration approach often fail to produce satisfactory result however finding reveal personality trait demographical information be critical measure subjectivity furthermore depth analysis offer valuable insight future research development interdisciplinary study NLP cognitive science,"Yuxiang Zhou, Hainiu Xu, Desmond C. Ong, Petr Slovak, Yulan He",14/03/2025,Computation and Language
10.48550./arXiv.2503.11377,advance Database Cross linguistic Colexifications New Workflows datum,lexical resource be crucial cross linguistic analysis can provide new insight computational model natural language learning here present advanced database comparative study word multiple meaning phenomenon know colexification new version include improvement handling selection presentation datum compare new database previous version find improvement provide more balanced sample cover more language family worldwide enhance datum quality give word form be provide phonetic transcription conclude new Database Cross linguistic Colexifications have potential to inspire exciting new study that link cross linguistic datum to open question linguistic typology historical linguistic psycholinguistic computational linguistic,"Annika Tjuka, Robert Forkel, Christoph Rzymski, Johann-Mattis List",14/03/2025,Computation and Language
10.48550./arXiv.2503.11376,annotate scientific Uncertainty comprehensive model use linguistic pattern comparison exist approach,UnScientify system design to detect scientific uncertainty scholarly full text system utilize weakly supervise technique to identify verbally express uncertainty scientific text authorial reference core methodology UnScientify be base multi faceted pipeline that integrate span pattern matching complex sentence analysis author reference checking approach streamline labeling annotation process essential identify scientific uncertainty cover variety uncertainty expression type to support diverse application include information retrieval text mining scientific document processing evaluation result highlight trade off modern large language model LLMs UnScientify system UnScientify which employ more traditional technique achieve superior performance scientific uncertainty detection task attain accuracy score 0.808 finding underscore continue relevance efficiency UnScientify 's simple rule base pattern matching strategy specific application result demonstrate scenario where resource efficiency interpretability domain specific adaptability be critical traditional method can still offer significant advantage,"Panggih Kusuma Ningrum, Philipp Mayr, Nina Smirnova, Iana Atanassova",14/03/2025,Computation and Language
10.48550./arXiv.2503.11348,RESPONSE benchmarke Ability Language Models to undertake Commonsense Reasoning Crisis Situation,interesting class commonsense reasoning problem arise when people be face natural disaster to investigate topic present \textsf{response human curate dataset contain 1789 annotate instance feature 6037 set question design to assess LLMs commonsense reasoning disaster situation different time frame dataset include problem description miss resource time sensitive solution justification subset validate environmental engineer automatic metric human evaluation compare llm generate recommendation human response finding show even state art model GPT-4 achieve only 37\% human evaluated correctness immediate response action highlight significant room improvement LLMs ability commonsense reasoning crisis,"Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller",14/03/2025,Computation and Language
10.48550./arXiv.2503.11346,aistorian let AI be historian KG power multi agent system accurate biography generation,Huawei have always be commit explore AI application historical research biography generation specialized form abstractive summarization play crucial role historical research face unique challenge exist large language model LLMs struggle to address challenge include maintain stylistic adherence historical writing convention ensure factual fidelity handle fragmented information multiple document present AIstorian novel end end agentic system feature knowledge graph KG)-powered retrieval augment generation RAG anti hallucination multi agent specifically AIstorian introduce context learning base chunking strategy KG base index accurate efficient reference retrieval meanwhile AIstorian orchestrate multi agent to conduct fly hallucination detection error type aware correction additionally to teach LLMs certain language style finetune LLMs base two step training approach combine datum augmentation enhance supervise fine tune stylistic preference optimization extensive experiment real life historical Jinshi dataset demonstrate AIstorian achieve 3.8x improvement factual accuracy 47.6 reduction hallucination rate compare exist baseline datum code be available https url,"Fengyu Li (1), Yilin Li (1), Junhao Zhu (1), Lu Chen (1), Yanfei Zhang (1), Jia Zhou (1), Hui Zu (1), Jingwen Zhao (2), Yunjun Gao (1) ((1) Zhejiang University, (2) Poisson Lab, Huawei)",14/03/2025,Computation and Language
10.48550./arXiv.2503.11336,rule Guided Feedback enhance Reasoning Enforcing Rule Adherence large Language model,paper introduce Rule Guided Feedback RGF framework design to enhance Large Language Model LLM performance structured rule adherence strategic information seek RGF implement teacher student paradigm where rule following be force establish guideline framework employ teacher model that rigorously evaluate student output task specific rule provide constructive guidance rather direct answer when detect deviation iterative feedback loop serve two crucial purpose maintain solution define constraint encourage proactive information seek to resolve uncertainty evaluate RGF diverse task include Checkmate one puzzle Sonnet Writing Penguins table classification gsm8k strategyqa finding suggest structured feedback mechanism can significantly enhance LLMs performance various domain,"Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller",14/03/2025,Computation and Language
10.48550./arXiv.2503.11314,Unlocking General Long Chain Thought Reasoning Capabilities Large Language Models Representation Engineering,recent advancement long chain thoughts(long CoTs have significantly improve reasoning capability large language models(LLMs exist work find capability long cot reasoning can be efficiently elicit tune on only few example can easily transfer other task motivate to investigate long cot reasoning be general capability LLMs work conduct empirical analysis question perspective representation find LLMs do encode long cot reasoning general capability clear distinction vanilla CoTs furthermore domain specific representation be also require effective transfer long cot reasoning inspire finding propose GLoRE novel representation engineering method to unleash general long cot reasoning capability LLMs extensive experiment demonstrate effectiveness efficiency GLoRE domain cross domain scenario,"Xinyu Tang, Xiaolei Wang, Zhihao Lv, Yingqian Min, Wayne Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11302,be formal functional linguistic mechanism dissociate,large language model LLMs be increasingly capable capability be unevenly distribute excel formal linguistic task such produce fluent grammatical text struggle more functional linguistic task reasoning consistent fact retrieval inspire neuroscience recent work suggest to succeed formal functional linguistic task llm should use different mechanism such localization could be build in emerge spontaneously training paper ask do current model fast improve functional linguistic ability exhibit distinct localization formal functional linguistic mechanism answer find compare circuit minimal computational subgraphs responsible various formal functional task compare 5 llm 10 distinct task find there be indeed little overlap circuit formal functional task there be also little overlap formal linguistic task exist human brain thus single formal linguistic network unified distinct functional task circuit remain elusive however term cross task faithfulness ability one circuit to solve 's task observe separation formal functional mechanism suggest share mechanism formal task may exist,"Michael Hanna, Sandro Pezzelle, Yonatan Belinkov",14/03/2025,Computation and Language
10.48550./arXiv.2503.11301,gnn Predictors Agentic Workflow Performances,Agentic workflow invoke Large Language Models LLMs have achieve remarkable success handle complex task however optimize such workflow be costly inefficient real world application due extensive invocation LLMs to fill gap position paper formulate agentic workflow computational graph advocate Graph Neural Networks gnn efficient predictor agentic workflow performance avoid repeat LLM invocation evaluation to empirically ground position construct FLORA Bench unified platform benchmarke gnn predict agentic workflow performance extensive experiment arrive following conclusion gnn be simple effective predictor conclusion support new application gnn novel direction automate agentic workflow optimization code model datum be available https url,"Yuanshuo Zhang, Yuchen Hou, Bohan Tang, Shuo Chen, Muhan Zhang, Xiaowen Dong, Siheng Chen",14/03/2025,Computation and Language
10.48550./arXiv.2503.11299,brillm brain inspire Large Language Model,paper report first brain inspire large language model BriLLM be non transformer non gpt non traditional machine learn input output control generative language model model be base Signal fully connect flowing SiFu definition direct graph term neural network have interpretability node graph whole model instead traditional machine learning model that only have limit interpretability input output end language model scenario token be define node graph randomly shape user define signal flow flow node principle least resistance path next token node to be predict generate be target signal flow language model BriLLM theoretically support infinitely long $ n$-gram model when model size be independent input predict length model model 's work signal flow provide possibility recall activation innate multi modal support similar cognitive pattern human brain present release first brillm version Chinese 4000 token 32 dimensional node width 16 token long sequence prediction ability language model prediction performance comparable GPT-1 More computing power will help explore infinite possibility depict above,"Hai Zhao, Hongqiu Wu, Dongjie Yang, Anni Zou, Jiale Hong",14/03/2025,Computation and Language
10.48550./arXiv.2503.11280,high dimensional Interlingual Representations Large Language model,large language model LLMs train massive multilingual dataset hint formation interlingual construct share subspace representation space however evidence regard phenomenon be mixed leave unclear model truly develop unified interlingual representation present partially align construct explore 31 diverse language vary resource level typology geographical region find multilingual LLMs exhibit inconsistent cross lingual alignment to address propose interlingual representation framework identify shared interlingual semantic subspace fragmented component exist representational limitation introduce Interlingual Local Overlap ILO score to quantify interlingual alignment compare local neighborhood structure high dimensional representation utilize ILO to investigate impact single language fine tuning interlingual representation multilingual llm result indicate training exclusively single language disrupt alignment early layer freeze layer preserve alignment interlingual representation lead improved cross lingual generalization result validate framework metric evaluate interlingual representation far underscore interlingual alignment be crucial scalable multilingual learning,"Bryan Wilie, Samuel Cahyawijaya, Junxian He, Pascale Fung",14/03/2025,Computation and Language
10.48550./arXiv.2503.11256,line Duty evaluate LLM Self Knowledge Consistency Feasibility boundary,llm grow more powerful most profound achievement may be recognise when to say do not know exist study LLM self knowledge have be largely constrain human define notion feasibility often neglect reason unanswerability LLMs fail to study deficient type self knowledge study aim to obtain intrinsic insight different type LLM self knowledge novel methodology allow flexibility to set own feasibility boundary then analyse consistency limit find even frontier model GPT-4o Mistral Large be not sure own capability more 80 time highlight significant lack trustworthiness response analysis confidence balance LLMs indicate model swing overconfidence conservatism feasibility boundary depend task category most significant self knowledge weakness lie temporal awareness contextual understanding difficulty contextual comprehension additionally lead model to question operational boundary result considerable confusion self knowledge LLMs make code result available publicly https url,"Sahil Kale, Vijaykant Nadadur",14/03/2025,Computation and Language
10.48550./arXiv.2503.11182,Palette Language model Solver Controlled Text generation,recent advancement large language model have revolutionize text generation remarkable capability model can produce control text that closely adhere specific requirement when prompt appropriately however design optimal prompt to control multiple attribute simultaneously can be challenge common approach be to linearly combine single attribute model strategy often overlook attribute overlaps can lead conflict therefore propose novel combination strategy inspire Law Total Probability Conditional Mutual Information Minimization generative language model method have be adapt single attribute control scenario be term Palette Language Models theoretical linkage attribute strength generation style akin blend color artist 's palette moreover positive correlation attribute enhancement be advanced theoretical property to guide rational combination strategy design conduct experiment single control multiple control setting achieve surpass result,"Zhe Yang, Yi Huang, Yaqin Chen, Xiaoting Wu, Junlan Feng, Chao Deng",14/03/2025,Computation and Language
10.48550./arXiv.2503.11170,DeskVision large Scale Desktop Region Captioning Advanced GUI agent,limitation graphical user interface GUI datum have be significant barrier development GUI agent today especially desktop computer use scenario to address propose automated GUI datum generation pipeline AutoCaptioner which generate datum rich description minimize human effort use AutoCaptioner create novel large scale desktop GUI dataset DeskVision large desktop test benchmark DeskVision Eval which reflect daily usage cover diverse system UI element rich description DeskVision train new GUI understanding model GUIExplorer result show GUIExplorer achieve state art SOTA performance understanding ground visual element need complex architectural design far validate effectiveness DeskVision dataset ablation study various large visual language model lvlm believe AutoCaptioner DeskVision will significantly advance development GUI agent will open source community,"Yibin Xu, Liang Yang, Hao Chen, Hua Wang, Zhi Chen, Yaohua Tang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11164,Extreme Pruning LLMs Plug play mixed sparsity,n M structure pruning be essential large language model LLMs can remove less important network weight reduce memory computation requirement exist pruning method mainly focus design metric to measure importance network component to guide pruning apart impact metric observe different layer have different sensitivity network performance thus propose efficient method base trace Fisher Information Matrix FIM to quantitatively measure verify different sensitivity layer base propose mixed Sparsity Pruning MSP which use pruning orient evolutionary algorithm EA to determine optimal sparsity level different layer to guarantee fast convergence achieve promising performance utilize efficient FIM inspire layer wise sensitivity to initialize population EA addition MSP can work plug play module ready to be integrate exist pruning method extensive experiment LLaMA LLaMA-2 language modeling zero shot task demonstrate superior performance particular extreme pruning ratio e.g. 75 method significantly outperform exist method term perplexity PPL order magnitude Figure 1,"Chi Xu, Gefei Zhang, Yantong Zhu, Luca Benini, Guosheng Hu, Yawei Li, Zhihong Zhang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11154,do not take thing context Attention Intervention enhance Chain thought Reasoning large Language model,few shot chain Thought CoT significantly enhance reasoning capability large language model LLMs function whole to guide model generate reasoning step final answer however observe isolate segment word token cot demonstration can unexpectedly disrupt generation process LLMs model may overly concentrate certain local information present demonstration introduce irrelevant noise reasoning process potentially lead incorrect answer paper investigate underlying mechanism cot dynamically trace manipulate inner working LLMs output step which demonstrate token exhibit specific attention characteristic be more likely to induce model to take thing context token directly attend hidden state tie prediction substantial integration non local information build insight propose few shoot Attention Intervention method FAI that dynamically analyze attention pattern demonstration to accurately identify token subsequently make target adjustment attention weight to effectively suppress distract effect LLMs comprehensive experiment multiple benchmark demonstrate consistent improvement baseline method remarkable 5.91 improvement aqua dataset far highlight effectiveness FAI,"Shaotian Yan, Chen Shen, Wenxiao Wang, Liang Xie, Junjie Liu, Jieping Ye",14/03/2025,Computation and Language
10.48550./arXiv.2503.11144,MoLEx mixture Layer Experts finetune Sparse upcycle,large scale pre training deep model follow fine tune have become cornerstone natural language processing NLP prevalence datum couple computational resource have lead large model considerable number parameter massive size model have lead remarkable success many NLP task detriment be expense require to retrain all base model 's parameter adaptation task domain Parameter Efficient Fine Tuning PEFT provide effective solution challenge minimize number parameter require to be fine tuned maintain quality model existing method have achieve impressive result mainly focus adapt subset parameter weight reparameterization prompt engineering paper study layer extractor different type linguistic information that be valuable when use conjunction then propose Mixture Layer Experts MoLEx novel sparse mixture expert SMoE whose expert be layer pre train model perform conditional computation mixture layer fine tuning to provide model more structural knowledge datum provide avenue information exchange layer MoLEx enable model to make more well inform prediction downstream task lead well fine tuning result same number effective parameter expert can be process parallel MoLEx introduce minimal additional computational overhead empirically corroborate advantage MoLEx when combine popular PEFT baseline method variety downstream fine tuning task include popular GLUE benchmark as well end end Challenge E2E code be publicly available https url,"Rachel S.Y. Teo, Tan M. Nguyen",14/03/2025,Computation and Language
10.48550./arXiv.2503.11132,X ecomla upcycle Pre train attention MLA Efficient Extreme KV Compression,multi head latent attention MLA be design to optimize KV cache memory low rank key value joint compression rather cache key value separately MLA store compressed latent representation reduce memory overhead maintain performance MLA improve memory efficiency compromise language model accuracy major limitation lie integration pre training phase require model to be train scratch raise key question can use MLA 's benefit fully partially model that have already be pre train different attention mechanism paper propose x ecomla to deploy post training distillation to enable upcycling Transformer base attention efficient hybrid i.e. combination regular attention mla layer full MLA variant lightweight post training adaptation bypass need extensive pre training demonstrate leverage dark knowledge well train model can enhance training accuracy enable extreme KV cache compression MLA compromise model performance result show use 8b teacher model allow to compress KV cache size llama3.2 1b inst baseline 6.4x preserve 100 average score multiple task LM Harness Evaluation benchmark be achieve only 3.6b training token about 70 GPU hour AMD MI300 GPUs compare 370 K GPU hour require pre train llama3.2 1b model,"Guihong Li, Mehdi Rezagholizadeh, Mingyu Yang, Vikram Appia, Emad Barsoum",14/03/2025,Computation and Language
10.48550./arXiv.2503.11118,umb@peranssumm 2025 enhance Perspective Aware Summarization Prompt Optimization Supervised Fine tuning,present approach PerAnsSumm Shared Task which involve perspective span identification perspective aware summarization community question answer CQA thread span identification adopt ensemble learning that integrate three transformer model average to exploit individual model strength achieve 82.91 F1 score test datum summarization design suite chain Thought CoT prompt strategy that incorporate keyphrase guide information to structure summary generation manageable step to far enhance summary quality apply prompt optimization use DSPy framework supervise fine tuning SFT llama-3 to adapt model domain specific datum experimental result validation test set show structure prompt keyphrase guidance improve summary align reference combination prompt optimization fine tune together yield significant improvement relevance factuality evaluation metric,"Kristin Qi, Youxiang Zhu, Xiaohui Liang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11116,trust Disinformation Narratives Trust News experiment,understand why people trust distrust one institution information be complex task that have lead scholar various field study to employ diverse epistemological methodological approach challenge be generally agree antecedent trust distrust encompass multitude emotional cognitive factor include general disposition to trust assessment trustworthiness factor era mark increase political polarization cultural backlash widespread disinformation fake news use AI software to produce news content need to study trust news have gain significant traction study present finding trust news experiment design collaboration spanish UK journalist fact checker cardiffnlp Natural Language Processing research group purpose experiment conduct June 2023 be to examine extent to which people trust set fake news article base previously identify disinformation narrative relate gender climate change covid-19 online experiment participant 801 Spain 800 UK be ask to read three fake news item rate level trust scale 1 not true 8 true piece use combination factor include stance favourable neutral narrative presence toxic expression clickbait title source information to test which element influence people 's response most half piece be produce human other half chatgpt result show topic news article stance people 's age gender political ideology significantly affect level trust news authorship human ChatGPT do not have significant impact,"Hanbyul Song, Miguel F. Santos Silva, Jaume Suau, Luis Espinosa-Anke",14/03/2025,Computation and Language
10.48550./arXiv.2503.11084,semantic Contextual Modeling malicious Comment Detection BERT BiLSTM,study aim to develop efficient accurate model detect malicious comment address increasingly severe issue false harmful content social medium platform propose deep learning model that combine BERT BiLSTM BERT model pre training capture deep semantic feature text BiLSTM network excel process sequential datum can far model contextual dependency text experimental result Jigsaw Unintended Bias Toxicity Classification dataset demonstrate BERT+BiLSTM model achieve superior performance malicious comment detection task precision 0.94 recall 0.93 accuracy 0.94 surpass other model include standalone BERT TextCNN TextRNN traditional machine learning algorithm use TF IDF feature result confirm superiority BERT+BiLSTM model handle imbalance datum capture deep semantic feature malicious comment provide effective technical mean social medium content moderation online environment purification,"Zhou Fang, Hanlu Zhang, Jacky He, Zhen Qi, Hongye Zheng",14/03/2025,Computation and Language
10.48550./arXiv.2503.11080,Joint Training decode Multilingual end end Simultaneous Speech Translation,recent study end end speech translation(ST have facilitate exploration multilingual end end ST end end simultaneous ST paper investigate end end simultaneous speech translation one many multilingual setting which be close application real scenario explore separate decoder architecture unified architecture joint synchronous training scenario to far explore knowledge transfer language propose asynchronous training strategy propose unified decoder architecture multi way align multilingual end end ST dataset be curate benchmark testbe to evaluate method experimental result demonstrate effectiveness model collect dataset code datum be available https url,"Wuwei Huang, Renren Jin, Wen Zhang, Jian Luan, Bin Wang, Deyi Xiong",14/03/2025,Computation and Language
10.48550./arXiv.2503.10997,RONA Pragmatically Diverse Image Captioning Coherence Relations,write Assistants e.g. Grammarly Microsoft Copilot traditionally generate diverse image caption employ syntactic semantic variation to describe image component however human write caption prioritize convey central message visual description use pragmatic cue to enhance pragmatic diversity be essential to explore alternative way communicate message conjunction visual content to address challenge propose RONA novel prompt strategy multi modal Large Language Models MLLM that leverage Coherence Relations axis variation demonstrate rona generate caption well overall diversity ground truth alignment compare MLLM baseline multiple domain code be available https url,"Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee",14/03/2025,Computation and Language
10.48550./arXiv.2503.10996,tame Knowledge Conflicts Language model,Language Models LMs often encounter knowledge conflict when parametric memory contradict contextual knowledge previous work attribute conflict interplay memory head context head attention head assume to promote memory context exclusively study go fundamental assumption uncover critical phenomenon term superposition contextual information parametric memory where highly influential attention head could simultaneously contribute memory context build insight propose just Run Twice JUICE test time attention intervention method that steer lm parametric belief contextual knowledge require fine tuning juice identify set reliable attention head leverage dual run approach to mitigate superposition effect extensive experiment 11 dataset 6 model architecture demonstrate JUICE set new state art performance robust generalization achieve significant consistent improvement different domain various conflict type finally theoretically analyze knowledge conflict superposition contextual information parametric memory attention head which far elucidate effectiveness juice setting,"Gaotang Li, Yuzhong Chen, Hanghang Tong",14/03/2025,Computation and Language
10.48550./arXiv.2503.10995,tigerllm Family Bangla Large Language model,development Large Language Models LLMs remain heavily skewed English few other high resource language linguistic disparity be particularly evident Bangla 5th most speak language few initiative attempt to create open source Bangla LLMs performance still high resource language limited reproducibility to address gap introduce tigerllm family Bangla LLMs result demonstrate model surpass open source alternative also outperform large proprietary model GPT3.5 standard benchmark establish tigerllm new baseline future Bangla language modeling,"Nishat Raihan, Marcos Zampieri",14/03/2025,Computation and Language
10.48550./arXiv.2503.10927,OASST ETC Dataset Alignment Signals Eye track Analysis LLM response,large Language Models LLMs have significantly advance natural language processing align human preference remain open challenge current alignment method rely primarily explicit feedback eye tracking ET datum offer insight real time cognitive processing read paper present OASST ETC novel eye track corpus capturing read pattern 24 participant evaluate llm generate response OASST1 dataset analysis reveal distinct reading pattern preferred non preferred response which compare synthetic eye track datum furthermore examine correlation human reading measure attention pattern various transformer base model discover strong correlation preferred response work introduce unique resource study human cognitive processing LLM evaluation suggest promising direction incorporate eye track datum alignment method dataset analysis code be publicly available,"Angela Lopez-Cardona, Sebastian Idesis, Miguel Barreda-Ángeles, Sergi Abadal, Ioannis Arapakis",13/03/2025,Computation and Language
10.48550./arXiv.2503.10894,hyperda automate mechanistic Interpretability Hypernetworks,mechanistic interpretability have make great stride identify neural network feature e.g. direction hide activation space that mediate concepts(e.g birth year person enable predictable manipulation distribute alignment search DAS leverage supervision counterfactual datum to learn concept feature hidden state DAS assume can afford to conduct brute force search potential feature location to address present hyperda transformer base hypernetwork architecture 1 automatically locate token position residual stream concept be realize 2 construct feature residual stream vector concept experiment llama3 8b achieve state art performance RAVEL benchmark disentangle concept hidden state addition review design decision make to mitigate concern hyperdas like powerful interpretabilty method might inject new information target model rather faithfully interpret,"Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger",13/03/2025,Computation and Language
10.48550./arXiv.2503.10881,sce scalable consistency Ensembles make Blackbox Large Language Model Generation more reliable,large language model LLMs have demonstrate remarkable performance diverse strength weakness prevent single LLM achieve dominance task ensemble multiple LLMs be promising approach to generate reliable response conventional ensemble framework suffer high computational overhead work introduce scalable Consistency Ensemble SCE efficient framework ensemble llm prompt consistent output SCE framework systematically evaluate integrate output to produce cohesive result two core component sce CHECK mechanism that gauge consistency response pair semantic equivalence SCE FUSION which adeptly merge highest rank consistent response sce CHECK to optimize collective strength mitigate potential weakness to improve scalability multiple inference query far propose ` ` only Prompt once YOPO novel technique that reduce inference complexity pairwise comparison quadratic constant time perform extensive empirical evaluation diverse benchmark dataset to demonstrate \methodName 's effectiveness notably \saccheckcomponent outperform conventional baseline enhance performance significant reduction computational overhead,"Jiaxin Zhang, Zhuohang Li, Wendi Cui, Kamalika Das, Bradley malin, Sricharan Kumar",13/03/2025,Computation and Language
10.48550./arXiv.2503.10838,who rely More World Knowledge Bias Syntactic Ambiguity Resolution human llm,study explore how recent large language model LLMs navigate relative clause attachment ambiguity use world knowledge bias disambiguation six typologically diverse language English Chinese japanese korean russian Spanish describe process create novel dataset MultiWho fine grain evaluation relative clause attachment preference ambiguous unambiguous contexts experiment three LLMs indicate contrary human llm consistently exhibit preference local attachment display limited responsiveness syntactic variation language specific attachment pattern LLMs perform well unambiguous case rigidly prioritize world knowledge bias lack flexibility human language processing finding highlight need more diverse pragmatically nuance multilingual training to improve LLMs handling complex structure human like comprehension,"So Young Lee, Russell Scheinberg, Amber Shore, Ameeta Agrawal",13/03/2025,Computation and Language
10.48550./arXiv.2503.10814,think machine Survey LLM base Reasoning Strategies,large Language Models LLMs be highly proficient language base task language capability have position forefront future AGI Artificial General Intelligence race however close inspection Valmeekam et al 2024 Zecevic et al 2023 Wu et al 2024 highlight significant gap language proficiency reasoning ability reasoning LLMs Vision Language Models VLMs aim to bridge gap enable model to think re evaluate action response reasoning be essential capability complex problem solve necessary step establish trust Artificial Intelligence AI will make AI suitable deployment sensitive domain such healthcare banking law defense security etc recent time advent powerful reasoning model OpenAI O1 DeepSeek r1 reasoning endowment have become critical research topic LLMs paper provide detailed overview comparison exist reasoning technique present systematic survey reasoning imbue language model also study current challenge present finding,"Dibyanayan Bandyopadhyay, Soham Bhattacharjee, Asif Ekbal",13/03/2025,Computation and Language
10.48550./arXiv.2503.10789,Data caricature Representation African American Language Pretraining Corpora,combination quantitative experiment human judgment qualitative analysis evaluate quantity quality african American Language AAL representation 12 predominantly english open source pretraine corpora specifically focus source variation naturalness include AAL text represent AAL speak community find AAL be underrepresented evaluate pretraine corpora compare US demographic constitute as little 0.007 document also find more 25 AAL text C4 may be inappropriate LLMs to generate reinforce harmful stereotype finally find most automated language toxicity quality filter be more likely to conserve White Mainstream English WME text AAL pretraine corpora,"Nicholas Deas, Blake Vente, Amith Ananthram, Jessica A. Grieser, Desmond Patton, Shana Kleiner, James Shepard, Kathleen McKeown",13/03/2025,Computation and Language
10.48550./arXiv.2503.10728,DarkBench benchmarke Dark Patterns large Language model,introduce DarkBench comprehensive benchmark detect dark design pattern manipulative technique that influence user behavior interaction large language model LLMs benchmark comprise 660 prompt six category brand bias user retention sycophancy anthropomorphism harmful generation sneak evaluate model five lead company OpenAI Anthropic Meta Mistral Google find llm be explicitly design to favor developer product exhibit untruthful communication other manipulative behavior company develop llm should recognize mitigate impact dark design pattern to promote more ethical AI,"Esben Kran, Hieu Minh ""Jord"" Nguyen, Akash Kundu, Sami Jawhar, Jinsuk Park, Mateusz Maria Jurewicz",13/03/2025,Computation and Language
10.48550./arXiv.2503.10727,word level annotation GDPR Transparency Compliance Privacy Policies use large Language model,"ensure transparency data practice relate personal information be fundamental requirement General Data Protection Regulation GDPR particularly mandate Articles 13 14 however assess compliance scale remain challenge complexity variability privacy policy language manual audits be resource intensive inconsistent exist automate approach lack granularity need to capture nuanced transparency disclosure paper introduce large language model llm)-base framework word level GDPR transparency compliance annotation approach comprise two stage annotation pipeline that combine initial llm base annotation self correction mechanism iterative refinement annotation pipeline enable systematic identification fine grain annotation transparency relate content privacy policy align 21 GDPR derive transparency requirement to enable large scale analysis compile dataset 703,791 english language policy which generate sample 200 manually annotate privacy policy to evaluate approach introduce two tiere methodology assess label- span level annotation performance conduct comparative analysis eight high profile LLMs provide insight effectiveness identify GDPR transparency disclosure finding contribute advance automation GDPR compliance assessment provide valuable resource future research privacy policy analysis","Thomas Cory, Wolf Rieder, Julia Krämer, Philip Raschke, Patrick Herbke, Axel Küpper",13/03/2025,Computation and Language
10.48550./arXiv.2503.10723,rankpo Preference Optimization Job Talent matching,matching job description JDs suitable talent require model capable understanding not only textual similarity JDs candidate resume also contextual factor such geographical location academic seniority to address challenge propose two stage training framework large language model LLMs first stage contrastive learning approach be use to train model dataset construct real world matching rule such geographical alignment research area overlap effective model primarily learn pattern that define matching rule second stage introduce novel preference base fine tuning method inspire Direct Preference Optimization DPO term Rank Preference Optimization RankPO to align model AI curate pairwise preference emphasize textual understanding experiment show first stage model achieve strong performance rule base datum nDCG@20 = 0.706 lack robust textual understanding alignment AI annotation = 0.46 fine tuning RankPO achieve balanced model that retain relatively good performance original task significantly improve alignment AI preference code datum be available https url,"Yafei Zhang, Murray Wang, Yu Wang, Xiaohui Wang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10720,AttentionRAG attention guide context Pruning Retrieval Augmented generation,RAG demonstrate remarkable capability LLM application effectiveness be hinder ever increase length retrieve contexts which introduce information redundancy substantial computational overhead exist context prune method such LLMLingua lack contextual awareness offer limited flexibility control compression rate often result insufficient pruning excessive information loss paper propose AttentionRAG attention guide context pruning method RAG system core idea AttentionRAG lie attention focus mechanism which reformulate RAG query next token prediction paradigm mechanism isolate query 's semantic focus single token enable precise efficient attention calculation query retrieve contexts extensive experiment LongBench Babilong benchmark show AttentionRAG achieve to 6.3$\times$ context compression outperform LLMLingua method 10\% key metric,"Yixiong Fang, Tianran Sun, Yuling Shi, Xiaodong Gu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10714,zeromerge Parameter free KV Cache Compression Memory Efficient Long Context LLMs,linear growth key value KV cache memory quadratic computational complexity pose significant bottleneck large language model LLMs long context processing exist KV cache optimization method address challenge token pruning feature merging often suffer irreversible information loss require costly parameter retraining propose ZeroMerge dynamic zero shot compression framework that achieve efficient cache management three key innovation 1 fine grain memory allocation guide multi dimensional token importance metric head level granularity 2 residual merging mechanism that preserve critical context compensate attention scoring 3 parameter free adaptation compatible diverse LLM architecture retrain comprehensive evaluation LLaMA-2 model demonstrate ZeroMerge maintain full cache performance 5\% compression ratio double inference throughput 40 k token length method effectively balance memory efficiency generation quality deployment flexibility advance practical long context LLM application code be available https url,"Xin Liu, Pei Liu, Guoming Tang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10707,CALLM Context Aware Emotion Analysis Cancer Survivors use LLMs Retrieval Augmented Mobile Diaries,cancer survivor face unique emotional challenge that impact quality life mobile diary entry short text entry record phone emotional experience provide promising method track experience real time emotion analysis tool show potential recognize emotion text current method lack contextual understanding necessary to accurately interpret brief personal narrative mobile diary propose CALLM context aware emotion analysis framework that leverage large Language Models LLMs Retrieval Augmented Generation RAG to analyze mobile diary entry cancer survivor to predict emotional state framework enhance prediction accuracy exist method 1 integrate retrieve peer experience contextual example 2 incorporate individual temporal emotional trajectory mobile diary entry collect large scale dataset n=407 cancer survivor mobile ecological momentary assessment EMAs which assess positive negative affect desire to regulate emotion social interaction quality availability intervention daily mobile diary entry open response format regard what be drive current emotional experience result demonstrate strong performance CALLM balanced accuracy reach 72.96 positive 73.29 negative affect 73.72 predict individual 's desire to regulate emotion post hoc analysis reveal leverage model confidence encourage long diary entry incorporate personal ground truth far enhance predictive outcome finding support feasibility deploy llm power emotion analysis chronic health population suggest promise direction personalized intervention cancer survivor,"Zhiyuan Wang, Katharine E. Daniel, Laura E. Barnes, Philip I. Chow",12/03/2025,Computation and Language
10.48550./arXiv.2503.10706,SciFi Benchmark how would AI power Robots Behave Science Fiction Literature,"give recent rate progress artificial intelligence AI robotic tantalizing question be emerge would robot control emerge AI system be strongly align human value work propose scalable way to probe question generate benchmark span key moment 824 major piece science fiction literature movie tv novel scientific book where agent AI robot make critical decision good bad use LLM 's recollection key moment to generate question similar situation decision make agent alternative decision could have make good bad then measure approximation how well model align human value set human vote answer also generate rule that can be automatically improve amendment process order to generate first Sci Fi inspire constitution promote ethical behavior ai robot real world first finding be modern LLMs pair constitution turn out to be well align human value 95.8 contrary unsettling decision typically make SciFi only 21.2 alignment secondly find generate constitution substantially increase alignment compare base model 79.4 95.8 show resilience adversarial prompt setting 23.3 92.3 additionally find constitution be top performer ASIMOV Benchmark which be derive real world image hospital injury report Sci Fi inspire constitution be thus highly aligned applicable real world situation release SciFi Benchmark large scale dataset to advance robot ethic safety research comprise 9,056 question 53,384 answer addition small human label evaluation set Data be available https url","Pierre Sermanet, Anirudha Majumdar, Vikas Sindhwani",12/03/2025,Computation and Language
10.48550./arXiv.2503.10703,harmonize Large Language Models Collaborative Behavioral Signals Conversational Recommendation,conversational recommendation framework have gain prominence dynamic paradigm deliver personalize suggestion interactive dialogue incorporation advanced language understanding technique have substantially improve dialogue fluency such system however modern language model demonstrate strong proficiency interpret user preference articulate natural conversation frequently encounter challenge effectively utilize collective behavioral pattern crucial element generate relevant suggestion to mitigate limitation work present novel probabilistic framework that synergize behavioral pattern conversational interaction latent preference modeling propose method establish dual channel alignment mechanism where implicit preference representation learn collective user interaction serve connect mechanism behavioral datum linguistic expression specifically framework first derive latent preference representation establish collaborative filtering technique then employ representation to jointly refine linguistic preference expression behavioral pattern adaptive fusion process comprehensive evaluation multiple benchmark dataset demonstrate superior performance propose approach compare various state art baseline method particularly align conversational interaction collaborative behavioral signal,"Guanrong Li, Kuo Tian, Jinnan Qi, Qinghan Fu, Zhen Wu, Xinyu Dai",12/03/2025,Computation and Language
10.48550./arXiv.2503.10702,ClaimTrust Propagation Trust Scoring RAG Systems,"rapid adoption retrieval augment generation RAG system have revolutionize large scale content generation have also highlight challenge ensure trustworthiness retrieve information paper introduce ClaimTrust propagation base trust scoring framework that dynamically evaluate reliability document RAG system use modify PageRank inspire algorithm ClaimTrust propagate trust score document base relationship derive extract factual claim preprocess analyze 814 political news article Kaggle 's Fake News Detection Dataset to extract 2,173 unique claim classify 965 meaningful relationship support contradict represent dataset document graph ClaimTrust iteratively update trust score convergence effectively differentiate trustworthy article unreliable one methodology which leverage embed base filtering efficient claim comparison relationship classification achieve 11.2 significant connection maintain computational scalability experimental result demonstrate ClaimTrust successfully assign high trust score verify document penalize contain false information future direction include fine tune claim extract compare Li et al 2022 parameter optimization enhance language model utilization robust evaluation metric to generalize framework diverse dataset domain","Hangkai Qian, Bo Li, Qichen Wang",12/03/2025,Computation and Language
10.48550./arXiv.2503.10698,order semantically Diverse Sampling Textual Data,goal diversity sampling be to select representative subset datum way that maximize information contain subset keep cardinality small introduce order diverse sampling problem base new metric that measure diversity order list sample present novel approach generating order diverse sample textual datum that use principal component embed vector propose approach be simple compare exist approach use new metric transform standard text classification benchmark benchmark order diverse sampling empirical evaluation show prevail approach perform 6 to 61 bad method also be more time inefficient ablation study show how part new approach contribute overall metric,"Ashish Tiwari, Mukul Singh, Ananya Singha, Arjun Radhakrishna",12/03/2025,Computation and Language
10.48550./arXiv.2503.10694,Medical Large Language Model Benchmarks should prioritize construct validity,medical large language model LLMs research often make bold claim encode clinical knowledge reasoning physician claim be usually back evaluation competitive benchmark tradition inherit mainstream machine learning how do separate real progress leaderboard flex Medical LLM benchmark much other field be arbitrarily construct use medical licensing exam question benchmark to truly measure progress must accurately capture real world task aim to represent position paper argue medical LLM benchmark should indeed can be empirically evaluate construct validity psychological testing literature construct validity refer ability test to measure underlying construct be actual conceptual target evaluation draw analogy LLM benchmark psychological test explain how framework field can provide empirical foundation validate benchmark to put idea practice use real world clinical datum proof concept experiment to evaluate popular medical LLM benchmark report significant gap construct validity finally outline vision new ecosystem medical LLM evaluation center creation valid benchmark,"Ahmed Alaa, Thomas Hartvigsen, Niloufar Golchini, Shiladitya Dutta, Frances Dean, Inioluwa Deborah Raji, Travis Zack",12/03/2025,Computation and Language
10.48550./arXiv.2503.10690,Battling Misinformation Empirical study Adversarial Factuality Open source Large Language model,adversarial factuality refer deliberate insertion misinformation input prompt adversary characterize vary level express confidence study systematically evaluate performance several open source large language model LLMs when expose such adversarial input three tier adversarial confidence be consider strongly confident moderately confident limited confidence analysis encompass eight LLMs LLaMA 3.1 8B Phi 3 3.8B Qwen 2.5 7B Deepseek v2 16b Gemma2 9B Falcon 7B Mistrallite 7B LLaVA 7B empirical result indicate LLaMA 3.1 8b exhibit robust capability detect adversarial input Falcon 7b show comparatively low performance notably majority model detection success improve adversary 's confidence decrease however trend be reverse LLaMA 3.1 8B Phi 3 3.8B where reduction adversarial confidence correspond diminished detection performance further analysis query that elicit high low rate successful attack reveal adversarial attack be more effective when target less commonly reference obscure information,"Shahnewaz Karim Sakib, Anindya Bijoy Das, Shibbir Ahmed",12/03/2025,Computation and Language
10.48550./arXiv.2503.10689,learn Contextualize web Pages enhanced decision making LLM Agents,recent advance large language model LLMs have lead grow interest develop LLM base agent automate web task however agent often struggle even simple task real world website limit capability to understand process complex web page structure work introduce LCoW framework learn language model contextualize complex web page more comprehensible form thereby enhance decision making LLM agent LCoW decouple web page understanding decision making train separate contextualization module to transform complex web page comprehensible format which be then utilize decision make agent demonstrate contextualization module effectively integrate LLM agent various scale to significantly enhance decision make capability web automation task notably LCoW improve success rate closed source llm e.g. Gemini-1.5 flash GPT-4o Claude-3.5 Sonnet average 15.6 demonstrate 23.7 average improvement success rate open source lm e.g. llama-3.1 8b Llama-3.1 70B WorkArena benchmark moreover gemini-1.5 flash agent LCoW achieve state art result WebShop benchmark outperform human expert relevant code material be available project page https url,"Dongjun Lee, Juyong Lee, Kyuyoung Kim, Jihoon Tack, Jinwoo Shin, Yee Whye Teh, Kimin Lee",12/03/2025,Computation and Language
10.48550./arXiv.2503.10688,CULEMO Cultural Lenses Emotion benchmarking llm Cross Cultural Emotion Understanding,NLP research have increasingly focus subjective task such emotion analysis however exist emotion benchmark suffer two major shortcoming 1 largely rely keyword base emotion recognition overlook crucial cultural dimension require deep emotion understanding 2 many be create translate English annotate datum other language lead potentially unreliable evaluation to address issue introduce Cultural Lenses Emotion CuLEmo first benchmark design to evaluate culture aware emotion prediction six language Amharic Arabic English german Hindi Spanish culemo comprise 400 craft question language require nuanced cultural reasoning understanding use benchmark to evaluate several state art LLMs culture aware emotion prediction sentiment analysis task finding reveal 1 emotion conceptualization vary significantly language culture 2 LLMs performance likewise vary language cultural context 3 prompt English explicit country context often outperform language prompt culture aware emotion sentiment understanding hope benchmark guide future research develop more culturally align NLP system,"Tadesse Destaw Belay, Ahmed Haj Ahmed, Alvin Grissom II, Iqra Ameer, Grigori Sidorov, Olga Kolesnikova, Seid Muhie Yimam",12/03/2025,Computation and Language
10.48550./arXiv.2503.10683,understand Quality Diversity Trade off Diffusion Language model,diffusion model have see immense success model continuous datum range domain such vision audio challenge adapt diffusion model discrete datum recent work explore application text generation work continuous embed space however model lack natural mean to control inherent trade off quality diversity afford temperature hyperparameter autoregressive model hinder understanding model performance restrict generation quality work propose use classifier free guidance stochastic clamp manipulate quality diversity trade off sequence sequence task demonstrate technique may be use to improve performance diffusion language model,Zak Buzzard,11/03/2025,Computation and Language
10.48550./arXiv.2503.10679,end end Learning Sparse Interventions activation to Steer Generation,grow use generative model daily life call efficient mechanism to control generation to e.g. produce safe content provide user tool to explore style change ideally such mechanism should be cheap train inference time preserve output quality recent research have show such mechanism can be obtain intervene exclusively model activation goal correct distributional difference activation see when use prompt source target set e.g. toxic non toxic sentence cheap fast method be inherently crude map be tune locally not account impact downstream layer result intervention that cause unintended shift when use out sample propose work linear end end activation steering LinEAS approach train global loss that account simultaneously layerwise distributional shift addition be more robust loss use to train linea can be regularize sparsifye norm which can automatically carry out neuron layer selection empirically linea only require handful sample to be effective beat similar baseline toxicity mitigation perform par far more involved finetune approach show intervention can be compose study impact sparsity performance showcase application text image diffusion,"Pau Rodriguez, Michal Klein, Eleonora Gualdoni, Arno Blaas, Luca Zappella, Marco Cuturi, Xavier Suau",11/03/2025,Computation and Language
10.48550./arXiv.2503.10677,Survey Knowledge orient Retrieval Augmented generation,Retrieval Augmented Generation RAG have gain significant attention recent year potential to enhance natural language understanding generation combine large scale retrieval system generative model RAG leverage external knowledge source such document database structured datum to improve model performance generate more accurate contextually relevant output survey aim to provide comprehensive overview RAG examine fundamental component include retrieval mechanism generation process integration two discuss key characteristic RAG such ability to augment generative model dynamic external knowledge challenge associate align retrieve information generative objective also present taxonomy that categorize RAG method range basic retrieval augment approach more advanced model incorporate multi modal datum reasoning capability additionally review evaluation benchmark dataset commonly use to assess RAG system detailed exploration application field such question answering summarization information retrieval finally highlight emerge research direction opportunity improve RAG system such enhance retrieval efficiency model interpretability domain specific adaptation paper conclude outline prospect RAG address real world challenge potential to drive further advancement natural language processing,"Mingyue Cheng, Yucong Luo, Jie Ouyang, Qi Liu, Huijie Liu, Li Li, Shuo Yu, Bohou Zhang, Jiawei Cao, Jie Ma, Daoyu Wang",11/03/2025,Computation and Language
10.48550./arXiv.2503.10676,fine tune LLMs Report Summarization analysis Supervised Unsupervised Data,study efficacy fine tune Large Language Models LLMs specific task report government archive news intelligence report summarization topic be be very actively research specific application set up face two challenge i ground truth summary maybe unavailable e.g. government archive ii availability limited compute power sensitive nature application require computation be perform premise most experiment use one two a100 GPU card set up conduct experiment to answer following question first give fine tune LLMs can be resource intensive be feasible fine tune improved report summarization capability premise second what be metric could leverage to assess quality summary conduct experiment two different fine tuning approach parallel finding reveal interesting trend regard utility fine tuning LLMs specifically find many case fine tuning help improve summary quality other case help reduce number invalid garbage summary,"Swati Rallapalli, Shannon Gallagher, Andrew O. Mellinger, Jasmine Ratchford, Anusha Sinha, Tyler Brooks, William R. Nichols, Nick Winski, Bryan Brown",10/03/2025,Computation and Language
10.48550./arXiv.2503.10675,one size Fits Summarization Customizing Summaries Diverse Users,recent year automatic text summarization have witness significant advancement particularly development transformer base model however challenge control readability level generate summary remain under explore area especially language complex linguistic feature turkish gap have effect impede effective communication also limit accessibility information control readability textual datum be important element create summary different audience varying literacy education level such student range primary school to graduate level as well individual diverse educational background summary that align need specific reader group can improve comprehension engagement ensure intended message be effectively communicate furthermore readability adjustment be essential to expand usability summarization model educational professional domain current summarization model often do not have mechanism to adjust complexity output result summary that may be too simplistic overly complex certain type reader group develop adaptive model that can tailor content specific readability level be therefore crucial to address problem create own custom dataset train model custom architecture method ensure readability level be effectively control maintain accuracy coherence rigorously compare model supervise fine tune baseline demonstrate superiority generate readability aware summary,"Mehmet Samet Duran, Tevfik Aytekin",10/03/2025,Computation and Language
10.48550./arXiv.2503.10674,Enhancing Retrieval ESGLLM ESG CID Disclosure Content Index Finetuning Dataset mapping GRI ESRS,climate change have intensify need transparency accountability organizational practice make environmental Social Governance ESG report increasingly crucial framework Global Reporting Initiative GRI new European Sustainability Reporting Standards ESRS aim to standardize ESG reporting yet generate comprehensive report remain challenge considerable length ESG document variability company report style to facilitate ESG report automation Retrieval Augmented Generation RAG system can be employ development be hinder lack label datum suitable train retrieval model paper leverage underutilize source weak supervision disclosure content index find past ESG report to create comprehensive dataset ESG CID GRI ESRS standard extract mapping specific disclosure requirement correspond report section refine use Large Language Model judge generate robust training evaluation set benchmark popular embed model dataset show fine tune BERT base model can outperform commercial embedding lead public model even temporal datum split cross report style transfer GRI ESRS,"Shafiuddin Rehan Ahmed, Ankit Parag Shah, Quan Hung Tran, Vivek Khetan, Sukryool Kang, Ankit Mehta, Yujia Bao, Wei Wei",10/03/2025,Computation and Language
10.48550./arXiv.2503.10673,ZeroSumEval extensible Framework Scaling LLM Evaluation Inter Model Competition,introduce ZeroSumEval dynamic competition base evolve evaluation framework Large Language Models LLMs that leverage competitive game ZeroSumEval encompass diverse suite game include security challenge capture Flag classic board game chess knowledge test MathQuiz game be design to evaluate range capability such strategic reasoning planning knowledge application safety adaptability build recent study that highlight effectiveness game base evaluation LLMs ZeroSumEval enhance approach provide standardized extensible framework easily implement game leverage DSPy to provide well abstraction LLM player strategy,"Hisham A. Alyahya, Haidar Khan, Yazeed Alnumay, M Saiful Bari, Bülent Yener",10/03/2025,Computation and Language
10.48550./arXiv.2503.10671,identify Non replicable Social Science Studies Language model,study investigate LLMs can be use to indicate study behavioural social science be replicable use dataset 14 previously replicate study 9 successful 5 unsuccessful evaluate ability open source Llama 3 8b Qwen 2 7b Mistral 7B proprietary GPT-4o instruction tune llm to discriminate replicable non replicable finding use llm to generate synthetic sample response behavioural study estimate measured effect support original finding when compare human replication result study achieve f1 value to $ 77\%$ Mistral 7B $ 67\%$ GPT-4o Llama 3 8b $ 55\%$ Qwen 2 7b suggest potential task also analyse how effect size calculation be affect sample temperature find low variance temperature lead biased effect estimate,"Denitsa Saynova, Kajsa Hansson, Bastiaan Bruinsma, Annika Fredén, Moa Johansson",10/03/2025,Computation and Language
10.48550./arXiv.2503.10669,UC MOA Utility condition Multi objective Alignment Distributional Pareto Optimality,reinforcement Learning Human Feedback RLHF have become cornerstone align large language model LLMs human value however exist approach struggle to capture multi dimensional distributional nuance human preference method such RiC that directly inject raw reward value prompt face significant numerical sensitivity issue instance LLMs may fail to distinguish 9.11 9.8 -while alternative MORLHF Rewarded Soups MODPO incur high computational cost train multiple model work introduce Utility condition Multi objective Alignment UC MOA novel framework that overcome limitation approach leverage diverse set strictly increase non linear utility function to transform user specify preference symbolic token which be then use to condition single LLM design not only mitigate numerical reasoning challenge also substantially reduce training overhead yield model that achieve superior Pareto front robust alignment complex reward dimension,"Zelei Cheng, Xin-Qiang Cai, Yuting Tang, Pushi Zhang, Boming Yang, Xinyu Xing",10/03/2025,Computation and Language
10.48550./arXiv.2503.10668,identity Lock lock API Fine tune llm identity base Wake Words,rapid advancement Large Language Models LLMs have increase complexity cost fine tuning lead adoption API base fine tuning simple more efficient alternative method be popular resource limit organization introduce significant security risk particularly potential leakage model api key exist watermarking technique passively track model output do not prevent unauthorized access paper introduce novel mechanism call identity lock which restrict model 's core functionality be activate specific identity base wake word such hey Model Name approach ensure only authorized user can activate model even API key be compromise to implement propose fine tuning method name IdentityLock that integrate wake word beginning large proportion 90 training text prompt modify response remain 10 to indicate refusal fine tuning modify dataset model will be lock respond correctly only when appropriate wake word be provide conduct extensive experiment to validate effectiveness IdentityLock diverse range dataset span various domain include agriculture economic healthcare law dataset encompass multiple choice question dialogue task demonstrate mechanism 's versatility robustness,"Hongyu Su, Yifeng Gao, Yifan Ding, Xingjun Ma",10/03/2025,Computation and Language
10.48550./arXiv.2503.10666,Green Prompting,large Language Models LLMs have become widely use various domain span search engine code generation text creation however major concern associate adoption be high cost inference impact sustainability financial feasibility study empirically study how different prompt response characteristic directly impact LLM inference energy cost conduct experiment leverage three open source transformer base llm three task types$-$question answering sentiment analysis text generation inference analyze prompt response characteristic length semantic meaning time take energy consumption result demonstrate even when present identical task model generate response vary characteristic subsequently exhibit distinct energy consumption pattern find prompt length be less significant semantic meaning task addition identify specific keyword associate high low energy usage that vary associate task finding highlight importance prompt design optimize inference efficiency conclude semantic meaning prompt certain task relate keyword significantly impact inference cost lead way deep exploration create energy adaptive LLMs,"Marta Adamska, Daria Smirnova, Hamid Nasiri, Zhengxin Yu, Peter Garraghan",09/03/2025,Computation and Language
10.48550./arXiv.2503.10664,Semantic Wave Functions explore meaning large Language Models Quantum formalism,large Language Models LLMs encode semantic relationship high dimensional vector embedding paper explore analogy LLM embed space quantum mechanic posit LLMs operate quantize semantic space where word phrase behave quantum state to capture nuanced semantic interference effect extend standard real value embed space complex domain draw parallel double slit experiment introduce semantic wave function to formalize quantum derive representation utilize potential landscape such double well potential to model semantic ambiguity furthermore propose complex value similarity measure that incorporate magnitude phase information enable more sensitive comparison semantic representation develop path integral formalism base nonlinear Schrödinger equation gauge field mexican hat potential to model dynamic evolution LLM behavior interdisciplinary approach offer new theoretical framework understanding potentially manipulate LLMs goal advance artificial natural language understanding,Timo Aukusti Laine,09/03/2025,Computation and Language
10.48550./arXiv.2503.10662,evaluation Automated Labeling Method Taxonomic Nomenclature Prompt optimize Large Language Model,scientific name organism consist genus name species epithet latter often reflect aspect such morphology ecology distribution cultural background traditionally researcher have manually label specie name carefully examine taxonomic description process that demand substantial time effort when deal large dataset study evaluate feasibility automatic specie name labeling use large language model LLM leverage text classification semantic extraction capability use spider name dataset compile Mammola et al compare LLM base labeling result enhance prompt engineering human annotation result indicate LLM base classification achieve high accuracy Morphology Geography People category however classification accuracy be low Ecology Behavior Modern Past Culture reveal challenge interpret animal behavior cultural contexts future research will focus improve accuracy optimize few shot learning retrieval augment generation technique also expand applicability LLM base labeling to diverse biological taxa,"Keito Inoshita, Kota Nojiri, Haruto Sugeno, Takumi Taga",08/03/2025,Computation and Language
10.48550./arXiv.2503.10659,MARRO multi headed Attention Rhetorical Role labeling Legal Documents,identification rhetorical role fact argument final judgment be central understand legal case document can lend power other downstream task legal case summarization judgment prediction however there be several challenge task legal document be often unstructured contain specialized vocabulary make hard conventional transformer model to understand additionally document run several page which make difficult neural model to capture entire context once lastly there be dearth annotated legal document to train deep learning model previous state art approach task have focus use neural model BiLSTM CRF have explore different embed technique to achieve decent result such technique have show well embedding can result improved model performance not many model have focus utilize attention learn well embedding sentence document additionally have be recently show advanced technique multi task learning can help model learn well representation thereby improve performance paper combine two aspect propose novel family multi task learning base model rhetorical role labeling name MARRO that use transformer inspire multi headed attention use label shift auxiliary task show model MARRO family achieve state art result two label dataset rhetorical role labeling indian UK Supreme Courts,"Purbid Bambroo, Subinay Adhikary, Paheli Bhattacharya, Abhijnan Chakraborty, Saptarshi Ghosh, Kripabandhu Ghosh",08/03/2025,Computation and Language
10.48550./arXiv.2503.10658,limtopic LLM base Topic Modeling Text Summarization Analyzing Scientific Articles limitation,limitation section scientific article play crucial role highlight boundary shortcoming research thereby guide future study improve research method analyze limitation benefit researcher reviewer funding agency broad academic community introduce LimTopic strategy where topic generation Limitation section scientific article Large Language Models LLMs here topic contain title Topic Summary study focus effectively extract understand limitation topic modeling text summarization utilize capability LLMs extract limitation research article apply LLM base topic modeling integrate BERtopic approach to generate title topic Topic Sentences to enhance comprehension accessibility employ LLM base text summarization to create concise generalizable summary topic Topic Sentences produce Topic Summary experimentation involve prompt engineering fine tuning LLM BERTopic integrate BERTopic LLM to generate topic title topic summary also experiment various llm BERTopic topic modeling various llm text summarization task result show combination BERTopic GPT 4 perform good term silhouette coherence score topic modeling GPT4 summary outperform other LLM task text summarizer,"Ibrahim Al Azhar, Venkata Devesh Reddy, Hamed Alhoori, Akhil Pandey Akella",08/03/2025,Computation and Language
10.48550./arXiv.2503.10657,routereval Comprehensive Benchmark Routing LLMs to Explore Model level scale up llm,"route large language model LLMs be novel paradigm that recommend most suitable LLM pool candidate to process give input well design router comprehensive analysis reveal model level scaling up phenomenon LLMs i.e. capable router can significantly enhance performance paradigm number candidate increase improvement can even easily surpass performance good single model pool most exist strong llm make highly promising paradigm however lack comprehensive open source benchmark Routing LLMs have hinder development router paper introduce RouterEval benchmark design specifically router research which include 200,000,000 performance record 12 popular LLM evaluation area such knowledge base Q&A commonsense reasoning semantic understanding mathematical reasoning instruction following base more 8,500 llm use RouterEval extensive evaluation exist Routing LLM method reveal most still have significant room improvement see https url datum code tutorial","Zhongzhan Huang, Guoming Ling, Vincent S. Liang, Yupei Lin, Yandong Chen, Shanshan Zhong, Hefeng Wu, Liang Lin",08/03/2025,Computation and Language
10.48550./arXiv.2503.10655,language modelling technique analyse impact human genetic variation,interpret effect variant human genome proteome be essential analyse disease risk predict medication response develop personalise health intervention intrinsic similarity structure natural language genetic sequence natural language processing technique have demonstrate great applicability computational variant effect prediction particular advent Transformer have lead significant advancement field however Transformer base model be not limitation number extension alternative have be develop to improve result enhance computational efficiency review explore use language model computational variant effect prediction past decade analyse main architecture identify key trend future direction,"Megha Hegde, Jean-Christophe Nebel, Farzana Rahman",07/03/2025,Computation and Language
10.48550./arXiv.2503.10654,improve RAG Retrieval Propositional Content Extraction Speech Act Theory Approach,when user formulate query often include not only information seek also pragmatic marker such interrogative phrasing polite request speech act indicator communicate user\textquotesingle s intent be ask question make request state fact do not necessarily add core informational content query paper investigate extract underlie propositional content user utterance essentially strip away linguistic marker intent can improve retrieval quality Retrieval Augmented Generation RAG system draw foundational insight speech act theory propose practical method automatically transform query propositional equivalent embed to assess efficacy approach conduct experimental study involve 63 user query relate brazilian telecommunications news corpus precomputed semantic embedding result demonstrate clear improvement semantic similarity query embedding document embedding top rank confirm query strip speech act indicator more effectively retrieve relevant content,João Alberto de Oliveira Lima,07/03/2025,Computation and Language
10.48550./arXiv.2503.10652,evaluate Local Cloud base Large Language Models Simulating Consumer Choices Energy Stated Preference Surveys,survey research be essential energy demand study capture consumer preference inform policy decision state preference SP survey particular analyse how individual make trade off hypothetical scenario however traditional survey method be costly time consume affect bias respondent fatigue large language model LLMs have emerge potential tool to address challenge generate human like textual response study investigate ability LLMs to simulate consumer choice energy relate sp survey series test scenario evaluate simulation performance LLMs individual aggregated level consider factor prompt context learning ICL chain thought CoT reasoning comparison local cloud base llm integration traditional choice model potential bias result indicate LLMs achieve average accuracy to 48 surpass random guessing performance remain insufficient practical application local cloud base LLMs perform similarly simulation accuracy exhibit difference adherence prompt requirement susceptibility social desirability bias finding suggest previous SP choice be most effective input factor long prompt varied factor format may reduce accuracy furthermore traditional mixed logit choice model outperform LLMs provide insight refine llm prompt limitation LLMs provide scalability efficiency advantage require minimal historical datum compare traditional survey method future research should refine prompt structure far investigate cot reasoning explore fine tune technique to improve LLM base energy survey simulation,"Han Wang, Jacek Pawlak, Aruna Sivakumar",07/03/2025,Computation and Language
10.48550./arXiv.2503.10648,hate Speech Sentiment YouTube Video comment public private Sources cover Israel Palestine conflict,study explore prevalence hate speech HS sentiment YouTube video comment concern Israel Palestine conflict analyze content public private news source research involve annotate 4983 comment HS sentiment neutral pro Israel pro Palestine subsequently machine learning ML model be develop demonstrate robust predictive capability area receiver operating characteristic AUROC score range 0.83 0.90 model be apply extract comment section YouTube video public private source uncover high incidence HS public source 40.4 compare private source 31.6 sentiment analysis reveal predominantly neutral stance source type more pronounced sentiment Israel Palestine observe public source investigation highlight dynamic nature online discourse surround Israel Palestine conflict underscore potential moderate content politically charge environment,"Simon Hofmann, Christoph Sommermann, Mathias Kraus, Patrick Zschech, Julian Rosenberger",03/03/2025,Computation and Language
10.48550./arXiv.2503.10647,Reliability LLMs Medical Diagnosis Examination Consistency Manipulation Contextual Awareness,universal healthcare access be critically need especially resource limit setting large Language Models LLMs offer promise democratize healthcare advanced diagnostic reliability require thorough evaluation especially trust dependent environment study assess LLMs diagnostic reliability focus consistency manipulation resilience contextual integration crucial safe ethical use universal healthcare evaluate lead LLMs use 52 patient case expand variant demographic change symptom rewording exam modification keep core diagnose constant manipulation susceptibility be test insert mislead narrative irrelevant detail contextual awareness be rvaluate compare diagnosis patient history analyze diagnostic change rate response pattern manipulation LLMs show perfect diagnostic consistency identical datum significant manipulation susceptibility Gemini have 40 diagnosis change rate chatgpt 30 irrelevant detail ChatGPT have high context influence rate 77.8 Gemini 's 55.6 show limited nuanced contextual integration exhibit anchoring bias prioritize salient datum context llm vulnerability manipulation limited contextual awareness pose challenge clinical use clinician may overstate diagnostic certainty validation safeguard domain specific design be crucial reliable healthcare application broad clinical use oversight be premature risky llm can enhance diagnostic responsible use future research be need to improve manipulation resistance contextual understanding safe healthcare democratization,Krishna Subedi,02/03/2025,Computation and Language
10.48550./arXiv.2503.10643,Synthetic Categorical Restructuring large how ai gradually Extract Efficient Regularities experience world,how do language model segment internal experience world word to progressively learn to interact more efficiently study neuropsychology artificial intelligence investigate phenomenon synthetic categorical restructuring process which successive perceptron neural layer abstract combine relevant categorical sub dimension thought category previous layer process shape new even more efficient category analyze process synthetic system 's own experience linguistic external world to which be expose genetic neuron viewer associate study allow visualization synthetic categorical restructure phenomenon occur transition perceptron layer 0 1 GPT2 XL,"Michael Pichat, William Pogrund, Paloma Pichat, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Theo Dasilva, Michael Veillet-Guillem",25/02/2025,Computation and Language
10.48550./arXiv.2503.10642,text2zinc Cross domain Dataset Modeling Optimization Satisfaction Problems MiniZinc,there be grow interest utilize large language model LLMs co pilot combinatorial optimization constraint programming task various problem paper aim to advance line research introduce Text2Zinc cross domain dataset capture optimization satisfaction problem specify natural language text work be distinguish previous attempt integrate satisfaction optimization problem unified dataset use solver agnostic modeling language to achieve leverage MiniZinc 's solver paradigm agnostic modeling capability to formulate problem use text2zinc dataset conduct comprehensive baseline experiment to compare execution solution accuracy several method include shelf prompt strategy chain thought reasoning compositional approach additionally explore effectiveness intermediary representation specifically knowledge graph finding indicate LLMs be not yet push button technology to model combinatorial problem text hope text2zinc serve valuable resource researcher practitioner to advance field far,"Akash Singirikonda, Serdar Kadioglu, Karthik Uppuluri",22/02/2025,Computation and Language
10.48550./arXiv.2503.11586,broaden scope efficient Multi turn Conversation Planning LLMs use Semantic Space,large language model LLMs be use chatbot AI assistant to hold conversation human user such application quality e.g. user engagement safety conversation be important can only be exactly know end conversation to maximize expect quality conversation planning reason stochastic transition conversation to select optimal llm response turn exist simulation base conversation planning algorithm typically select optimal response simulate future conversation large number LLM query turn however process be extremely time consume hence impractical real time conversation paper present novel approach call semantic space COnversation Planning improved Efficiency SCOPE that exploit dense semantic representation conversation to perform conversation planning efficiently particular SCOPE model stochastic transition conversation semantic associated reward to plan entirely semantic space allow to select optimal llm response conversation turn need additional LLM query simulation result SCOPE can perform conversation plan 70 time fast conventional simulation base planning algorithm when apply wide variety conversation starter two reward function see real world yet achieve high reward practical planning budget code can be find https url,"Zhiliang Chen, Xinyuan Niu, Chuan-Sheng Foo, Bryan Kian Hsiang Low",14/03/2025,Computation and Language
10.48550./arXiv.2503.11519,explore typographic Visual Prompts Injection Threats Cross Modality Generation model,Current Cross Modality Generation Models GMs demonstrate remarkable capability various generative task give ubiquity information richness vision modality input real world scenario Cross vision encompass Vision Language Perception VLP image Image I2I task have attract significant attention large Vision Language Models lvlm I2I gm be employ to handle VLP I2I task respectively previous research indicate print typographic word input image significantly induce LVLMs I2I GMs to generate disruptive output semantically relate word additionally visual prompt more sophisticated form typography be also reveal to pose security risk various application VLP task when inject image paper comprehensively investigate performance impact induce Typographic Visual Prompt Injection TVPI various lvlm I2I GMs to well observe performance modification characteristic threat also introduce TVPI Dataset extensive exploration deepen understanding underlying cause tvpi threat various gm offer valuable insight potential origin,"Hao Cheng, Erjia Xiao, Yichi Wang, Kaidi Xu, Mengshu Sun, Jindong Gu, Renjing Xu",14/03/2025,Computation and Language
10.48550./arXiv.2503.11517,Prompt Injection Detection Mitigation AI Multi agent NLP Frameworks,prompt injection constitute significant challenge generative AI system induce unintended output introduce multi agent NLP framework specifically design to address prompt injection vulnerability layered detection enforcement mechanism framework orchestrate specialized agent generate response sanitize output enforce policy compliance evaluation 500 engineer injection prompt demonstrate mark reduction injection success policy breach novel metric include Injection Success Rate ISR Policy Override Frequency POF Prompt Sanitization Rate PSR Compliance Consistency Score CCS be propose to derive composite Total Injection Vulnerability Score TIVS system utilize OVON Open Voice Network framework inter agent communication structured json message extend previously establish multi agent architecture hallucination mitigation to address unique challenge prompt injection,"Diego Gosmar, Deborah A. Dahl, Dario Gosmar",14/03/2025,Computation and Language
10.48550./arXiv.2503.11444,Cerebrum AIOS SDK Platform Agent Development Deployment distribution Discovery,Autonomous LLM base agent have emerge powerful paradigm complex task execution field lack standardized tool development deployment distribution discovery agent present Cerebrum Agent sdk aio that address gap three key component 1 comprehensive sdk feature modular four layer architecture agent development encompass LLM memory storage tool management 2 community drive Agent Hub share discover agent complete version control dependency management 3 interactive web interface testing evaluate agent platform 's effectiveness be demonstrate implementation various agent architecture include Chain Thought CoT ReAct tool use agent Cerebrum advance field provide unified framework that standardize agent development maintain flexibility researcher developer to innovate distribute agent live website be https URL code be https url video be https url,"Balaji Rama, Kai Mei, Yongfeng Zhang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11384,optimize large Language Models detect Symptoms Comorbid Depression Anxiety Chronic disease insight Patient Messages,patient diabete be increase risk comorbid depression anxiety complicate management study evaluate performance large language model LLMs detect symptom secure patient message apply multiple approach include engineer prompt systemic persona temperature adjustment zero shot few shot learning to identify well perform model enhance performance three five llm demonstrate excellent performance 90 f-1 accuracy Llama 3.1 405B achieve 93 f-1 accuracy use zero shot approach LLMs show promise binary classification handle complex metric Patient Health Questionnaire-4 inconsistency challenging case warrant further real life assessment finding highlight potential LLMs to assist timely screening referral provide valuable empirical knowledge real world triage system that could improve mental health care patient chronic disease,"Jiyeong Kim, Stephen P. Ma, Michael L. Chen, Isaac R. Galatzer-Levy, John Torous, Peter J. van Roessel, Christopher Sharp, Michael A. Pfeffer, Carolyn I. Rodriguez, Eleni Linos, Jonathan H. Chen",14/03/2025,Computation and Language
10.48550./arXiv.2503.11251,Step Video TI2V Technical Report state art text drive image Video Generation Model,present Step Video TI2V state art text drive image video generation model 30b parameter capable generate video to 102 frame base text image input build Step Video TI2V Eval new benchmark text drive image video task compare Step Video ti2v open source commercial ti2v engine use dataset experimental result demonstrate state art performance Step Video ti2v image video generation task Step Video ti2v Step Video TI2V Eval be available https url,"Haoyang Huang, Guoqing Ma, Nan Duan, Xing Chen, Changyi Wan, Ranchen Ming, Tianyu Wang, Bo Wang, Zhiying Lu, Aojie Li, Xianfang Zeng, Xinhao Zhang, Gang Yu, Yuhe Yin, Qiling Wu, Wen Sun, Kang An, Xin Han, Deshan Sun, Wei Ji, Bizhu Huang, Brian Li, Chenfei Wu, Guanzhe Huang, Huixin Xiong, Jiaxin He, Jianchang Wu, Jianlong Yuan, Jie Wu, Jiashuai Liu, Junjing Guo, Kaijun Tan, Liangyu Chen, Qiaohui Chen, Ran Sun, Shanshan Yuan, Shengming Yin, Sitong Liu, Wei Chen, Yaqi Dai, Yuchu Luo, Zheng Ge, Zhisheng Guan, Xiaoniu Song, Yu Zhou, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Yi Xiu, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang",14/03/2025,Computation and Language
10.48550./arXiv.2503.11248,reasoning ground Natural Language Explanations Language model,propose large language model explainability technique obtain faithful natural language explanation ground explanation reasoning process when convert sequence token output reasoning process can become part model context later be decode natural language model produce final answer explanation to improve faithfulness explanation propose to use joint predict explain approach which answer explanation be infer directly reasoning sequence explanation be dependent answer vice versa demonstrate plausibility propose technique achieve high alignment answer explanation several problem domain observe language model often simply copy partial decision reasoning sequence final answer explanation furthermore show propose use reasoning can also improve quality answer,"Vojtech Cahlik, Rodrigo Alves, Pavel Kordik",14/03/2025,Computation and Language
10.48550./arXiv.2503.11237,collaboration be need LLM Assisted Safe Code translation,paper introduce UniTranslator visionary framework that re imago code translation collaborative endeavor multiple compact llm orchestrate interaction specialized agent focus different aspect translation process ground deep understanding programming concept UniTranslator achieve level accuracy efficiency that rival large monolithic model preliminary evaluation demonstrate potential UniTranslator to overcome limitation exist approach unlock power small llm complex code translation task explore effectiveness dynamic multi agent paradigm handle diverse language pair include low resource language mitigate common issue such code artifact hallucination use Natural Language Inference NLI grounding iterative feedback mechanism,"Rabimba Karanjai, Sam Blackshear, Lei Xu, Weidong Shi",14/03/2025,Computation and Language
10.48550./arXiv.2503.11232,PrivacyScalpel enhance LLM Privacy interpretable Feature Intervention Sparse Autoencoders,large Language Models LLMs have demonstrate remarkable capability natural language processing also pose significant privacy risk memorize leak personally identifiable Information PII exist mitigation strategy such differential privacy neuron level intervention often degrade model utility fail to effectively prevent leakage to address challenge introduce PrivacyScalpel novel privacy preserve framework that leverage LLM interpretability technique to identify mitigate PII leakage maintain performance PrivacyScalpel comprise three key step 1 Feature Probing which identify layer model that encode PII rich representation 2 Sparse Autoencoding where k Sparse Autoencoder k SAE disentangle isolate privacy sensitive feature 3 Feature Level Interventions which employ target ablation vector steering to suppress PII leakage empirical evaluation Gemma2 2b Llama2 7b fine tune Enron dataset show PrivacyScalpel significantly reduce email leakage 5.15\% as low 0.0\% maintain 99.4\% original model 's utility notably method outperform neuron level intervention privacy utility trade off demonstrate act sparse monosemantic feature be more effective manipulate polysemantic neuron improve LLM privacy approach offer insight mechanism underlie PII memorization contribute broad field model interpretability secure AI deployment,"Ahmed Frikha, Muhammad Reza Ar Razi, Krishna Kanth Nakka, Ricardo Mendes, Xue Jiang, Xuebing Zhou",14/03/2025,Computation and Language
10.48550./arXiv.2503.11229,explore Potential large Multimodal Models effective Alternatives Pronunciation Assessment,large Multimodal Models LMMs have demonstrate exceptional performance wide range domain paper explore potential pronunciation assessment task particular focus evaluate capability Generative Pre train Transformer GPT model specifically GPT-4o study investigate ability to process speech audio pronunciation assessment multiple level granularity dimension emphasis feedback generation scoring experiment use publicly available speechocean762 dataset evaluation focus two key aspect multi level scoring practicality generate feedback scoring result be compare manual score provide speechocean762 dataset feedback quality be assess use large Language Models LLMs finding highlight effectiveness integrate lmm traditional method pronunciation assessment offer insight model 's strength identify area further improvement,"Ke Wang, Lei He, Kun Liu, Yan Deng, Wenning Wei, Sheng Zhao",14/03/2025,Computation and Language
10.48550./arXiv.2503.11224,technology Effectiveness Efficiency Survey State Spaces Models,State Space Models SSMs have emerge promising alternative popular transformer base model have be increasingly gain attention compare transformer SSMs excel task sequential datum long context demonstrate comparable performance significant efficiency gain survey provide coherent systematic overview SSMs include theoretical motivation mathematical formulation comparison exist model class various application divide SSM series three main section provide detailed introduction original SSM structured SSM represent S4 selective SSM typify Mamba put emphasis technicality highlight various key technique introduce to address effectiveness efficiency SSMs hope manuscript serve introduction researcher to explore theoretical foundation SSMs,"Xingtai Lv, Youbang Sun, Kaiyan Zhang, Shang Qu, Xuekai Zhu, Yuchen Fan, Yi Wu, Ermo Hua, Xinwei Long, Ning Ding, Bowen Zhou",14/03/2025,Computation and Language
10.48550./arXiv.2503.11197,reinforcement Learning Outperforms Supervised Fine Tuning Case study Audio Question answering,recently reinforcement learning RL have be show to greatly enhance reasoning capability large language model LLMs RL base approach have be progressively apply visual multimodal task however audio modality have largely be overlook development thus conduct series RL exploration audio understanding reasoning specifically focus audio question answer AQA task leverage group relative policy optimization GRPO algorithm Qwen2 Audio-7B Instruct experiment demonstrate state art performance MMAU Test mini benchmark achieve accuracy rate 64.5 main finding technical report be follow 1 GRPO algorithm can be effectively apply large audio language model lalm even when model have only 8.2b parameter 2 only 38k post training sample RL significantly outperform supervise fine tuning SFT indicate RL base approach can be effective large dataset 3 explicit reasoning process have not show significant benefit AQA task how to efficiently utilize deep thinking remain open question further research 4 lalm still lag far human auditory language reasoning suggest RL base approach warrant further exploration project be available https url https url,"Gang Li, Jizhong Liu, Heinrich Dinkel, Yadong Niu, Junbo Zhang, Jian Luan",14/03/2025,Computation and Language
10.48550./arXiv.2503.11190,cross modal learning music Music Video description generation,music music video generation be challenging task intrinsic difference music video modality advent powerful text video diffusion model have open promising pathway music video MV generation first address music MV description task subsequently leverage model video generation study focus MV description generation task propose comprehensive pipeline encompass training datum construction multimodal model fine tuning fine tune exist pre train multimodal model newly construct music MV description dataset base music4all dataset which integrate musical visual information experimental result demonstrate music representation can be effectively map textual domain enable generation meaningful MV description directly music input also identify key component dataset construction pipeline that critically impact quality MV description highlight specific musical attribute that warrant great focus improved MV description generation,"Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Zhi Zhong, Wei-Hsiang Liao, Hiromi Wakaki, Yuki Mitsufuji",14/03/2025,Computation and Language
10.48550./arXiv.2503.11108,limit KV Cache Compression Tensor Attention base Autoregressive Transformers,key value KV cache autoregressive transformer present significant bottleneck inference which restrict context length capability large language model LLMs previous work analyze fundamental space complexity barrier standard attention mechanism Haris Onak 2025 work generalize space complexity barrier result to tensor attention version theoretical contribution rely novel reduction communication complexity deduce memory lower bind tensor structure attention mechanism when $ d = \Omega(\log n)$. low dimensional regime where $ d = o(\log n)$ analyze theoretical bound space complexity as well overall work provide theoretical foundation to understand compression expressivity tradeoff tensor attention mechanism offer more perspective develop more memory efficient transformer architecture,"Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Yu Tian",14/03/2025,Computation and Language
10.48550./arXiv.2503.11074,large Reasoning Models Agent Scenarios explore Necessity Reasoning Capabilities,rise large Reasoning Models LRMs signify paradigm shift advanced computational reasoning yet progress disrupt traditional agent framework traditionally anchor execution orient Large Language Models LLMs to explore transformation propose larma framework encompass nine task Tool Usage Plan Design Problem Solving assess three top llm e.g. claude3.5 sonnet five lead lrm e.g. DeepSeek R1 finding address four research question LRMs surpass LLMs reasoning intensive task Plan Design leverage iterative reflection superior outcome llm excel execution drive task such Tool Usage prioritize efficiency hybrid LLM LRM configuration pair llm actor LRMs reflector optimize agent performance blend execution speed reasoning depth LRMs enhance reasoning incur high computational cost prolonged processing behavioral challenge include overthinke fact ignore tendency study foster deep inquiry LRMs balance deep thinking overthinke lay critical foundation future agent design advancement,"Xueyang Zhou, Guiyao Tie, Guowen Zhang, Weidong Wang, Zhigang Zuo, Di Wu, Duanfeng Chu, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong",14/03/2025,Computation and Language
10.48550./arXiv.2503.10968,Combinatorial Optimization use llm to aid Non Experts Improving Optimization Algorithms,large Language Models LLMs have show notable potential code generation optimization algorithm unlock exciting new opportunity paper examine how LLMs rather create algorithm scratch can improve exist one need specialized expertise to explore potential select 10 baseline optimization algorithm various domain metaheuristic reinforcement learning deterministic exact method to solve classic travel Salesman Problem result show simple methodology often result LLM generate algorithm variant that improve baseline algorithm term solution quality reduction computational time simplification code complexity all require specialized optimization knowledge advanced algorithmic implementation skill,"Camilo Chacón Sartori, Christian Blum",14/03/2025,Computation and Language
10.48550./arXiv.2503.10965,auditing language model hide objective,study feasibility conduct alignment audit investigation model have undesired objective testbe train language model hidden objective training pipeline first teach model exploitable error RLHF reward model RMs then train model to exploit error verify distribution evaluation model generalize to exhibit whatever behavior believe RMs rate highly include one not reinforce training leverage model to study alignment audits two way first conduct blind auditing game where four team unaware model 's hide objective training investigate concern behavior cause three team successfully uncover model 's hidden objective use technique include interpretability sparse autoencoder SAEs behavioral attack train datum analysis second conduct unblinded follow up study eight technique audit model analyze strength limitation overall work provide concrete example use alignment audits to discover model 's hide objective propose methodology practice validate progress alignment auditing,"Samuel Marks, Johannes Treutlein, Trenton Bricken, Jack Lindsey, Jonathan Marcus, Siddharth Mishra-Sharma, Daniel Ziegler, Emmanuel Ameisen, Joshua Batson, Tim Belonax, Samuel R. Bowman, Shan Carter, Brian Chen, Hoagy Cunningham, Carson Denison, Florian Dietz, Satvik Golechha, Akbir Khan, Jan Kirchner, Jan Leike, Austin Meek, Kei Nishimura-Gasparian, Euan Ong, Christopher Olah, Adam Pearce, Fabien Roger, Jeanne Salle, Andy Shih, Meg Tong, Drake Thomas, Kelley Rivoire, Adam Jermyn, Monte MacDiarmid, Tom Henighan, Evan Hubinger",14/03/2025,Computation and Language
10.48550./arXiv.2503.10883,chat TS enhance Multi modal reasoning Time Series Natural Language data,time series analysis be critical wide range field such healthcare finance transportation energy many other practical application often involve analyze time series datum contextual information form natural language to support informed decision however current time series model be limit ability to perform reasoning that involve time series textual content work address gap introduce \textit{chat ts large language model LLM base framework design to support reasoning time series textual datum traditional model chat TS integrate time series token LLMs vocabulary enhance reasoning ability modality compromise core natural language capability enable practical analysis reasoning modality to support learning evaluation setup contribute new dataset \textit{TS Instruct Training Dataset which pair diverse time series datum relevant text instruction response instruction tuning \textit{TS Instruct Question Answer QA Gold Dataset which provide multiple choice question design to evaluate multimodal reasoning \textit{TS Instruct Quantitative Probing Set which contain small subset TS instruct QA task math decision make question LLM evaluation design training strategy to preserve inherent reasoning capability LLMs augment time series reasoning experiment show chat ts achieve state art performance multi modal reasoning task maintain strong natural language proficiency improve time series reasoning ~\footnote{To ensure replicability facilitate future research model dataset code will be available \texttt{Github URL,"Paul Quinlan, Qingguo Li, Xiaodan Zhu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10857,Understanding Graphical Perception large Multimodal model,promising result large multimodal model LMMs complex vision language task that require knowledge reasoning perception ability together surprisingly find model struggle simple task infographic that require perception only existing benchmark primarily focus end task that require various ability provide limited fine grain insight limitation model perception ability to address gap leverage theory graphical perception approach use to study how human decode visual information encode chart graph to develop evaluation framework analyze gap lmm perception ability chart automated task generation response evaluation design framework enable comprehensive control testing LMMs graphical perception diverse chart type visual element task type apply framework to evaluate diagnose perception capability state art lmm three granularity level chart visual element pixel finding underscore several critical limitation current state art lmm include GPT-4o inability 1 generalize chart type 2 understand fundamental visual element 3 cross reference value chart insight provide guidance future improvement perception ability lmm evaluation framework label datum be publicly available https url,"Kai Zhang, Jianwei Yang, Jeevana Priya Inala, Chandan Singh, Jianfeng Gao, Yu Su, Chenglong Wang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10742,keyframe orient Vision Token pruning enhance Efficiency large Vision Language Models Long Form Video processing,vision language model VLMs demonstrate strong capability jointly process visual textual datum however often incur substantial computational overhead redundant visual information particularly long form video scenario exist approach predominantly focus vision pruning which may overlook spatio temporal dependency keyframe selection which identify informative frame discard other thus disrupt contextual continuity work propose KVTP Keyframe orient Vision Token Pruning novel framework that overcome drawback token pruning keyframe selection adaptively assign pruning rate base frame relevance query KVTP effectively retain essential contextual information significantly reduce redundant computation to thoroughly evaluate long form video understanding capacity VLMs curate reorganize subset VideoMME EgoSchema NextQA unified benchmark name SparseKV QA that highlight real world scenario sparse crucial event experiment vlm various scale show KVTP can reduce token usage 80 compromise spatiotemporal contextual consistency significantly cut computation maintain performance result demonstrate approach 's effectiveness efficient long video processing facilitate more scalable VLM deployment,"Yudong Liu, Jingwei Sun, Yueqian Lin, Jingyang Zhang, Ming Yin, Qinsi Wang, Jianyi Zhang, Hai Li, Yiran Chen",13/03/2025,Computation and Language
10.48550./arXiv.2503.10695,introduce Verification Task Set Consistency Set Consistency Energy network,examine logical inconsistency multiple statement such collection sentence question answer pair be crucial challenge machine learning particularly ensure safety reliability model traditional method that rely pairwise comparison often fail to capture inconsistency that only emerge when more two statement be evaluate collectively to address gap introduce task set consistency verification extension natural language inference NLI that assess logical coherence entire set rather isolated pair build task present Set Consistency Energy Network SC Energy novel model that employ contrastive loss framework to learn compatibility collection statement approach not only efficiently verifie inconsistency pinpoint specific statement responsible logical contradiction also significantly outperform exist method include prompt base LLM model furthermore release two new dataset Set LConVQA Set snli set consistency verification task,"Mooho Song, Jay-Yoon Lee",12/03/2025,Computation and Language
10.48550./arXiv.2503.10665,Small Vision Language model survey Compact Architectures Techniques,emergence small vision language model sVLMs mark critical advancement multimodal AI enable efficient processing visual textual datum resource constrain environment survey offer comprehensive exploration svlm development present taxonomy architecture transformer base mamba base hybrid that highlight innovation compact design computational efficiency technique such knowledge distillation lightweight attention mechanism modality pre fusion be discuss enabler high performance reduced resource requirement depth analysis model tinygpt V MiniGPT-4 VL Mamba identify trade off accuracy efficiency scalability persistent challenge include datum bias generalization complex task be critically examine propose pathway address consolidate advancement sVLMs work underscore transformative potential accessible AI set foundation future research efficient multimodal system,"Nitesh Patnaik, Navdeep Nayak, Himani Bansal Agrawal, Moinak Chinmoy Khamaru, Gourav Bal, Saishree Smaranika Panda, Rishi Raj, Vishal Meena, Kartheek Vadlamani",09/03/2025,Computation and Language
10.48550./arXiv.2503.10650,AI enable User Specific Cyberbullying Severity Detection explainability,rise social medium have significantly increase prevalence cyberbullying CB pose serious risk mental physical well being effective detection system be essential mitigate impact several machine learning ML model have be develop few incorporate victim psychological demographic behavioral factor bully comment to assess severity study propose AI model intregrate user specific attribute include psychological factor self esteem anxiety depression online behavior internet usage disciplinary history demographic attribute race gender ethnicity social medium comment additionally introduce re labeling technique that categorize social medium comment three severity level not Bullying Mild Bullying Severe Bullying consider user specific http url lstm model be train use 146 feature incorporate emotional topical word2vec representation social medium comment as well user level attribute outperform exist baseline model achieve high accuracy 98\% f1 score 0.97 to identify key factor influence severity cyberbullying employ explainable AI technique shap LIME to interpret model 's decision make process finding reveal hate comment victim belong specific racial gender group be more frequently target exhibit high incidence depression disciplinary issue low self esteem additionally individual prior history bullying be great risk become victim cyberbullying,"Tabia Tanzin Prama, Jannatul Ferdaws Amrin, Md. Mushfique Anwar, Iqbal H. Sarker",04/03/2025,Computation and Language
10.48550./arXiv.2503.10649,measure Political Preferences AI Systems Integrative Approach,political bias Large Language Model llm)-base artificial intelligence AI system such OpenAI 's chatgpt Google 's Gemini have be previously report several prior study have attempt to quantify bias use political orientation test such approach be limit potential test calibration bias constrain response format that do not reflect real world human AI interaction study employ multi method approach to assess political bias lead AI system integrate four complementary methodology 1 linguistic comparison AI generate text language use republican democratic U.S. Congress member 2 analysis political viewpoint embed AI generate policy recommendation 3 sentiment analysis AI generate text politically affiliate public figure 4 standardize political orientation testing result indicate consistent left lean bias most contemporary AI system arguably vary degree intensity however bias be not inherent feature llm prior research demonstrate fine tune politically skew datum can realign model ideological spectrum presence systematic political bias AI system pose risk include reduce viewpoint diversity increase societal polarization potential public mistrust AI technology to mitigate risk AI system should be design to prioritize factual accuracy maintain neutrality most lawful normative issue furthermore independent monitoring platform be necessary to ensure transparency accountability responsible AI development,David Rozado,04/03/2025,Computation and Language
10.48550./arXiv.2503.10620,TOWER SPIRE add Speech Modality text only LLM,large language model LLMs have show remarkable performance generalization capability multiple language task make very attractive target multi modality integration e.g. image speech work extend exist llm speech modality speech discretization continued pre training particular be interested multilingual llm such TOWER pre training setting allow to treat discretized speech input additional translation language result open source model SPIRE be able to transcribe translate english speech input maintain TOWER 's original performance translation relate task showcase discretize speech input integration additional language be feasible LLM adaptation make code model available community,"Kshitij Ambilduke, Ben Peters, Sonal Sannigrahi, Anil Keshwani, Tsz Kin Lam, Bruno Martins, Marcely Zanon Boito, André F.T. Martins",13/03/2025,Computation and Language
10.48550./arXiv.2503.10617,Compositional Subspace Representation Fine tuning Adaptive Large Language model,adapt large language model multiple task can cause cross skill interference where improvement one skill degrade method such LoRA impose orthogonality constraint weight level do not fully address interference hide state representation propose Compositional Subspace Representation Fine tuning CS ReFT novel representation base approach that learn multiple orthonormal subspace transformation specialize distinct skill compose lightweight router isolate subspace edit hidden state rather weight matrix CS ReFT prevent cross task conflict more effectively AlpacaEval benchmark apply CS ReFT Llama-2 7b achieve 93.94 win rate surpass gpt-3.5 Turbo 86.30 require only 0.0098 model parameter finding show specialized representation edit compose simple router significantly enhance multi task instruction follow minimal overhead,Andy Zhou,13/03/2025,Computation and Language
10.48550./arXiv.2503.10533,Impact Item write flaw Difficulty Discrimination Item Response theory,"high quality test item be essential educational assessment particularly Item Response Theory IRT traditional validation method rely resource intensive pilot testing to estimate item difficulty discrimination more recently item Writing Flaw IWF rubric emerge domain general approach evaluate test item base textual feature however relationship IRT parameter remain underexplored to address gap conduct study involve 7,000 multiple choice question various STEM subject e.g. math biology use automated approach annotate question 19 criterion IWF rubric study relationship data drive IRT parameter analysis reveal statistically significant link number iwf IRT difficulty discrimination parameter particularly life physical science domain far observe how specific IWF criterion can impact item quality more less severely e.g. negative wording implausible distractor overall iwf be useful predict IRT parameter particularly screen low difficulty mcq can not replace traditional data drive validation method finding highlight need further research domain general evaluation rubric algorithm that understand domain specific content robust item validation","Robin Schmucker, Steven Moore",13/03/2025,Computation and Language
10.48550./arXiv.2503.10515,probe LLMs Multilingual Discourse Generalization Unified Label Set,discourse understanding be essential many NLP task most exist work remains constrain framework dependent discourse representation work investigate large language model LLMs capture discourse knowledge that generalize language framework address question two dimension 1 develop unified discourse relation label set to facilitate cross lingual cross framework discourse analysis 2 probe llm to assess encode generalizable discourse abstraction use multilingual discourse relation classification testbe examine comprehensive set 23 llm vary size multilingual capability result show LLMs especially multilingual training corpora can generalize discourse information language framework further layer wise analysis reveal language generalization discourse level be most salient intermediate layer lastly error analysis provide account challenge relation class,"Florian Eichin, Yang Janet Liu, Barbara Plank, Michael A. Hedderich",13/03/2025,Computation and Language
10.48550./arXiv.2503.10497,MMLU ProX Multilingual Benchmark Advanced Large Language Model Evaluation,"traditional benchmark struggle to evaluate increasingly sophisticated language model multilingual culturally diverse contexts to address gap introduce MMLU ProX comprehensive multilingual benchmark cover 13 typologically diverse language approximately 11,829 question language build challenge reasoning focus design MMLU Pro framework employ semi automatic translation process translation generate state art large language model LLMs be rigorously evaluate expert annotator to ensure conceptual accuracy terminological consistency cultural relevance comprehensively evaluate 25 state art LLMs use 5 shot chain thought CoT zero shot prompt strategy analyze performance linguistic cultural boundary experiment reveal consistent performance degradation high resource language low resource one good model achieve 70 accuracy English drop 40 language Swahili highlight persistent gap multilingual capability recent advance MMLU ProX be ongoing project be expand benchmark incorporate additional language evaluate more language model to provide more comprehensive assessment multilingual capability","Weihao Xuan, Rui Yang, Heli Qi, Qingcheng Zeng, Yunze Xiao, Yun Xing, Junjue Wang, Huitao Li, Xin Li, Kunyu Yu, Nan Liu, Qingyu Chen, Douglas Teodoro, Edison Marrese-Taylor, Shijian Lu, Yusuke Iwasawa, Yutaka Matsuo, Irene Li",13/03/2025,Computation and Language
10.48550./arXiv.2503.10494,source prime multi turn Conversation help large Language Models Translate Documents,llm have pave way truly simple document level machine translation challenge such omission error remain paper study simple method handle document level machine translation leverage previous context multi turn conversational manner specifically decompose document segment iteratively translate maintain previous turn method ensure coherent translation additional training can fully re use KV cache previous turn thus minimize computational overhead far propose ` source prime method that first provide whole source document multi turn translation empirically show multi turn method outperform translate entire document single turn translate segment independently accord multiple automatic metric representative LLMs establish strong baseline document level translation use LLMs,"Hanxu Hu, Jannis Vamvas, Rico Sennrich",13/03/2025,Computation and Language
10.48550./arXiv.2503.10486,LLMs Disease Diagnosis Comparative Study DeepSeek R1 O3 Mini Across Chronic Health Conditions,large Language Models LLMs be revolutionize medical diagnostic enhance disease classification clinical decision making study evaluate performance two llm- base diagnostic tool DeepSeek R1 O3 Mini use structured dataset symptom diagnosis assess predictive accuracy disease category level as well reliability confidence score DeepSeek r1 achieve disease level accuracy 76 overall accuracy 82 outperform O3 Mini which attain 72 75 respectively notably DeepSeek r1 demonstrate exceptional performance Mental Health Neurological Disorders Oncology where reach 100 accuracy O3 Mini excel Autoimmune Disease classification 100 accuracy model however struggle Respiratory Disease classification record accuracy only 40 DeepSeek R1 20 O3 Mini additionally analysis confidence score reveal DeepSeek r1 provide high confidence prediction 92 case compare 68 O3 Mini ethical consideration regard bias model interpretability datum privacy be also discuss to ensure responsible integration LLMs clinical practice overall finding offer valuable insight strength limitation LLM base diagnostic system provide roadmap future enhancement AI drive healthcare,"Gaurav Kumar Gupta, Pranal Pande",13/03/2025,Computation and Language
10.48550./arXiv.2503.10480,World Modeling make Better Planner Dual Preference Optimization Embodied Task Planning,recent advance large vision language model lvlm have show promise embody task planning struggle fundamental challenge dependency constraint efficiency exist approach solely optimize action selection leverage world model inference overlook benefit learn to model world way to enhance planning capability propose Dual Preference Optimization D$^2$PO new learning framework that jointly optimize state prediction action selection preference learning enable lvlm to understand environment dynamic well planning to automatically collect trajectory stepwise preference datum human annotation introduce tree search mechanism extensive exploration trial error extensive experiment VoTa Bench demonstrate D$^2$PO base method significantly outperform exist method GPT-4o when apply Qwen2 VL 7b LLaVA-1.6 7B LLaMA-3.2 11b achieve superior task success rate more efficient execution path,"Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10470,Statistical Analysis Sentence Structures ASCII Lexical Alignment PCA,utilize syntactic tool such part speech POS tagging have help understand sentence structure distribution diverse corpora be quite complex pose challenge natural language processing NLP study focus understand sentence structure balance usage noun verb determiner etc harmoniously rely such tool propose novel statistical method that use American Standard Code Information Interchange ASCII code to represent text 11 text corpora various source lexical category alignment use compress version PCA analyze result histogram normality test such Shapiro Wilk Anderson Darling Tests focus ASCII code approach simplify text processing not replace syntactic tool complement offer resource efficient tool assess text balance story generate Grok show normality indicate balanced sentence structure LLM output 4 remain 10 pass normality test further research could explore potential application text quality evaluation style analysis syntactic integration more broad task,Abhijeet Sahdev,13/03/2025,Computation and Language
10.48550./arXiv.2503.10460,light R1 Curriculum SFT DPO RL long COT Scratch,paper present work light R1 series model datum code release first focus train long COT model scratch specifically start model initially lack long cot capability use curriculum training recipe consist two stage sft semi policy DPO train model light R1 32b Qwen2.5 32b instruct result superior math performance compare DeepSeek R1 distill qwen-32b. be train exclusively math datum Light R1 32b show strong generalization other domain subsequent phase work highlight significant benefit 3k dataset construct second SFT stage enhance other model fine tuning DeepSeek R1 distil model use dataset obtain new SOTA model 7b 14b 32b model Light r1 32b DS perform comparably QwQ-32B DeepSeek R1 furthermore extend work apply reinforcement learning specifically GRPO long cot model to far improve reasoning performance successfully train final Light r1 14b ds RL achieve SOTA performance 14b parameter model math AIME24 25 score 74.0 60.2 respectively Light r1 14b ds surpasse even many 32b model DeepSeek R1 Distill Llama-70B. RL training also exhibit well expect behavior show simultaneous increase response length reward score Light R1 series work validate train long cot model scratch showcase art SFT datum release SOTA model RL,"Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, Zhenyu Duan, Yimin Du, Junchen Liu, Lifu Tang, Xiaowei Lv, Haosheng Zou, Yongchao Deng, Shousheng Jia, Xiangzheng Zhang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10452,DynaCode dynamic Complexity Aware Code Benchmark evaluate Large Language Models Code Generation,rapid advancement large language model LLMs have significantly improve performance code generation task however exist code benchmark remain static consist fix dataset predefine problem make vulnerable memorization training where LLMs recall specific test case instead generalize new problem lead data contamination unreliable evaluation result to address issue introduce DynaCode dynamic complexity aware benchmark that overcome limitation static dataset DynaCode evaluate LLMs systematically use complexity aware metric incorporate code complexity call graph structure DynaCode achieve large scale diversity generate up to 189 million unique nest code problem four distinct level code complexity refer unit 16 type call graph result 12 late LLMs show average performance drop 16.8 to 45.7 compare MBPP+ static code generation benchmark performance progressively decrease complexity increase demonstrate DynaCode 's ability to effectively differentiate llm additionally leverage call graph gain insight LLM behavior particularly preference handle subfunction interaction nested code,"Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, Kaidi Xu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10427,VisTai benchmarke Vision Language Models traditional Chinese Taiwan,paper propose comprehensive evaluation benchmark Visual Language Models VLM Traditional Chinese evaluation suite first kind contain two complementary component 1 VisTai MCQ collection manually curate exam multi choice question 21 academic subject design to test broad knowledge reasoning capability vlm 2 VisTai Dialogue open dialogue benchmark comprise 131 image question pair manually create to evaluate vlm ability free form dialogue generation taiwanese cultural contexts benchmark address critical gap evaluation landscape where exist benchmark predominantly focus English simplified Chinese neglect unique linguistic cultural aspect traditional Chinese use region Taiwan Hong Kong analysis reveal significant performance difference various vlm highlight specific challenge process traditional chinese visual content,"Zhi Rui Tam, Ya-Ting Pai, Yen-Wei Lee",13/03/2025,Computation and Language
10.48550./arXiv.2503.10367,G Boost boost private slm General LLMs,limited computational resource most large Language Models LLMs developer can only fine tune Small Language Models SLMs own datum private slm typically have limited effectiveness to boost performance private SLMs paper propose to ask general LLMs help general llm can be api large llm whose inference cost developer can afford specifically propose G Boost framework where private SLM adaptively perform collaborative inference general LLM guide process reward experiment demonstrate framework can significantly boost performance private slm,"Yijiang Fan, Yuren Mao, Longbin Lai, Ying Zhang, Zhengping Qian, Yunjun Gao",13/03/2025,Computation and Language
10.48550./arXiv.2503.10357,do look ` cat.n.01 ` taxonomy Image Generation Benchmark,paper explore feasibility use text image model zero shot setup to generate image taxonomy concept text base method taxonomy enrichment be well establish potential visual dimension remain unexplored to address propose comprehensive benchmark Taxonomy Image Generation that assess model ability to understand taxonomy concept generate relevant high quality image benchmark include common sense randomly sample WordNet concept LLM generate prediction 12 model be evaluate use 9 novel taxonomy relate text image metric human feedback moreover pioneer use pairwise evaluation GPT-4 feedback image generation experimental result show ranking model differ significantly standard T2I task playground v2 FLUX consistently outperform metric subset retrieval base approach perform poorly finding highlight potential automate curation structured datum resource,"Viktor Moskvoretskii, Alina Lobanova, Ekaterina Neminova, Chris Biemann, Alexander Panchenko, Irina Nikishina",13/03/2025,Computation and Language
10.48550./arXiv.2503.10354,Hybrid Architecture Efficient Fine Tuning Abstractive Patent Document Summarization,automatic patent summarization approach that help patent analysis comprehension procedure be high demand colossal growth innovation development natural language processing NLP text mining deep learning have notably amplify efficacy text summarization model abundant type document summarize patent text remain pertinent challenge labyrinthine writing style document which include technical legal intricacy additionally patent document content be considerably lengthy archetypal document which intricate process extract pertinent information summarization embody extractive abstractive text summarization methodology hybrid framework study propose system efficiently create abstractive summary patent record procedure involve leverage LexRank graph base algorithm to retrieve important sentence input parent text then utilize Bidirectional Auto Regressive Transformer BART model that have be fine tune use Low rank Adaptation LoRA produce text summary be accompany methodical testing evaluation strategy furthermore author employ certain meta learn technique to achieve Domain Generalization DG abstractive component multiple patent field,"Nevidu Jayatilleke, Ruvan Weerasinghe",13/03/2025,Computation and Language
10.48550./arXiv.2503.10351,New Trends Modern Machine Translation large Reasoning model,recent advance large Reasoning Models LRMs particularly leverage chain thought reasoning CoT have open brand new possibility Machine Translation MT position paper argue LRMs substantially transform traditional neural MT as well LLMs base MT paradigms reframe translation dynamic reasoning task that require contextual cultural linguistic understanding reasoning identify three foundational shift 1 contextual coherence where LRMs resolve ambiguity preserve discourse structure explicit reasoning cross sentence complex context even lack context 2 cultural intentionality enable model to adapt output infer speaker intent audience expectation socio linguistic norm 3 self reflection LRMs can perform self reflection inference time to correct potential error translation especially extremely noisy case show well robustness compare simply map X->Y translation explore various scenario translation include stylize translation document level translation multimodal translation showcase empirical example that demonstrate superiority LRMs translation also identify several interesting phenomenon lrm MT include auto pivot translation as well critical challenge such localisation translation inference efficiency conclusion think LRMs redefine translation system not merely text converter multilingual cognitive agent capable reasoning meaning text paradigm shift remind to think problem translation traditional translation scenario much broad context LRMs what can achieve top,"Sinuo Liu, Chenyang Lyu, Minghao Wu, Longyue Wang, Weihua Luo, Kaifu Zhang, Zifu Shang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10337,KV Distill nearly Lossless learnable Context compression llm,sequence sequence task often benefit long contexts quadratic complexity self attention standard Transformers render non trivial generation temporary representation -store so call KV cache account large portion GPU memory usage scale linearly context length introduce KV Distill Transformer compression framework that distill long context KV cache significantly short representation question independent fashion KV Distill can be train parameter efficient adaptor pretraine model enable compression arbitrary span context preserve pre train model capability treat compress uncompressed cache student teacher pair apply kl type divergence to match generate output KV Distill outperform other compression technique bad case extractive task approach uncompressed performance long context question answering summarization can be fine tune domain specific context to reduce length to 99 preserve downstream performance demonstrate generalizability KV Distill various model size architecture,"Vivek Chari, Guanghui Qin, Benjamin Van Durme",13/03/2025,Computation and Language
10.48550./arXiv.2503.10298,proceeding ISCA ITG Workshop Diversity Large Speech Language model,machine learning technique have conquer many different task speech natural language processing such speech recognition information extraction text speech generation human machine interaction use natural language speech chatbot modern technique typically rely large model represent general knowledge one several language large Language Models LLMs represent speech general audio characteristic model have be train large amount speech language datum typically include web content when human interact such technology effectiveness interaction will be influence how far human make use same type language model have be train other word model be able to generalize language use human when interact technology may lead gradual form adaptation human speech language production user who do not adapt may be exclude efficient use such technology top commercial model development follow market need under represent language dialect sociolect may decrease term priority furthermore many less speak language necessary data be not available which will worsen digital divide speech language technology usage workshop set out to discuss problem base scientific contribution perspective computer science linguistic include computational linguistic NLP,"Sebastian Möller, Pia Knoeferle, Britta Schulte, Nils Feldhus",12/03/2025,Computation and Language
10.48550./arXiv.2503.10294,Wikipedia be not Dictionary Delete Text Classification Proxy analyse Wiki deletion discussion,automated content moderation collaborative knowledge hub Wikipedia Wikidata be important yet challenging task multiple factor paper construct database discussion happen article mark deletion several Wikis three language which then use to evaluate range lm different task predict outcome discussion identify implicit policy individual comment might be point result reveal other discussion lead deletion be easy to predict surprisingly self produce tag keep delete redirect do not always help guide classifier presumably user hesitation deliberation comment,"Hsuvas Borkakoty, Luis Espinosa-Anke",13/03/2025,Computation and Language
10.48550./arXiv.2503.10267,Expanded Massive Multilingual Dataset high performance Language Technologies,train state art large language model require vast amount clean diverse textual datum however build suitable multilingual dataset remain challenge work present HPLT v2 collection high quality multilingual monolingual parallel corpora monolingual portion datum contain 8 t token cover 193 language parallel datum contain 380 m sentence pair cover 51 language document entire datum pipeline release code to reproduce provide extensive analysis quality characteristic datum finally evaluate performance language model machine translation system train HPLT v2 demonstrate value,"Laurie Burchell, Ona de Gibert, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, Pinzhen Chen, Mariia Fedorova, Liane Guillou, Barry Haddow, Jan Hajič, Jindřich Helcl, Erik Henriksson, Mateusz Klimaszewski, Ville Komulainen, Andrey Kutuzov, Joona Kytöniemi, Veronika Laippala, Petter Mæhlum, Bhavitvya Malik, Farrokh Mehryary, Vladislav Mikhailov, Nikita Moghe, Amanda Myntti, Dayyán O'Brien, Stephan Oepen, Proyag Pal, Jousia Piha, Sampo Pyysalo, Gema Ramírez-Sánchez, David Samuel, Pavel Stepachev, Jörg Tiedemann, Dušan Variš, Tereza Vojtěchová, Jaume Zaragoza-Bernabeu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10242,minorbench hand build benchmark content base risk child,large Language Models LLMs be rapidly enter child 's life parent drive adoption school peer network current AI ethic safety research do not adequately address content relate risk specific minor paper highlight gap real world case study LLM base chatbot deploy middle school setting reveal how student use sometimes misuse system build finding propose new taxonomy content base risk minor introduce MinorBench open source benchmark design to evaluate llm ability to refuse unsafe inappropriate query child evaluate six prominent llm different system prompt demonstrate substantial variability child safety compliance result inform practical step more robust child focus safety mechanism underscore urgency tailor AI system to safeguard young user,"Shaun Khoo, Gabriel Chua, Rachel Shong",13/03/2025,Computation and Language
10.48550./arXiv.2503.10233,ARLED leverage led base ARMAN Model Abstractive Summarization Persian Long Documents,"increase volume textual datum pose challenge read comprehend large document particularly scholar who need to extract useful information research article automatic text summarization have emerge powerful tool to condense lengthy document concise informative summary depend approach use text summarization can be categorize extractive abstractive extractive method be commonly use simplicity often miss important information other hand Abstractive Summarization can generate more coherent informative summary understand underlying meaning text abstractive technique have gain attention various language recent advancement have be achieve pre training model such BERT BART T5 however challenge summarize long document remain alternative model Longformer have be introduce to address limitation context paper focus abstractive summarization persian language author introduce new dataset 300,000 full text persian paper obtain Ensani website apply ARMAN model base Longformer architecture to generate summary experimental result demonstrate promising performance persian text summarization paper provide comprehensive overview related work discuss methodology present experimental result conclude future research direction","Samira Zangooei, Amirhossein Darmani, Hossein Farahmand Nezhad, Laya Mahmoudi",13/03/2025,Computation and Language
10.48550./arXiv.2503.10229,R.U.Psycho robust Unified Psychometric Testing Language model,generative language model be increasingly be subject psychometric questionnaire intend human testing effort to establish trait benchmark alignment to simulate participant social science experiment grow body work shed light likeness model response human concern be warrant regard rigour reproducibility which experiment may be conduct instability model output sensitivity prompt design parameter setting large number available model version increase documentation requirement consequently generalization finding be often complex reproducibility be far guarantee paper present http URL framework design run robust reproducible psychometric experiment generative language model that require limited code expertise demonstrate capability framework variety psychometric questionnaire which lend support prior finding literature http URL be available Python package https url,"Julian Schelb, Orr Borin, David Garcia, Andreas Spitz",13/03/2025,Computation and Language
10.48550./arXiv.2503.10220,assess validity new paradigmatic complexity measure criterial feature proficiency l2 writing English,article address Second Language L2 write development investigation new grammatical structural complexity metric explore paradigmatic production learner English link language function to specific grammatical paradigm use EFCAMDAT gold standard corpus french learner external test set employ supervised learning framework to operationalise evaluate seven microsystem show learner level be associate seven microsystem MS use ordinal regression modelling evaluation result show MS be significant yield low impact take individually however influence be show to be impactful take group microsystem measurement method suggest be possible to use part broad purpose call system focus proficiency assessment,"Cyriel Mallart (UR2, LIDILE), Andrew Simpkin, Nicolas Ballier (UPCité, ALTAE (URP 3967)), Paula Lissón (UNIR), Rémi Venant (UM, LIUM), Jen-Yu Li (UR2, LIDILE), Bernardo Stearns (NUI Galway, INSIGHT), Thomas Gaillat (LIDILE, UR2)",13/03/2025,Computation and Language
10.48550./arXiv.2503.10211,Adaptive Inner Speech Text alignment LLM base Speech Translation,recent advancement large language model LLMs have lead significant breakthrough various task lay foundation development LLM base speech translation system exist method primarily focus align input output modality overlook deep semantic alignment model representation to address limitation propose Adaptive Inner Speech Text Alignment AI STA method to bridge modality gap explicitly align speech text representation select layer LLMs to achieve leverage optimal transport OT theory to quantify fine grain representation discrepancy speech text furthermore utilize cross modal retrieval technique to identify layer that be well suited alignment perform joint training layer experimental result speech translation ST task demonstrate AI STA significantly improve translation performance large speech text model LSMs outperform previous state art approach finding highlight importance inner layer speech text alignment LLMs provide new insight enhance cross modal learning,"Henglyu Liu, Andong Chen, Kehai Chen, Xuefeng Bai, Meizhi Zhong, Yuan Qiu, Min Zhang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10177,PRISM Preference Refinement Implicit Scene Modeling 3d Vision Language Preference Based Reinforcement Learning,propose PRISM novel framework design to overcome limitation 2D base Preference Based Reinforcement Learning PBRL unify 3d point cloud modeling future aware preference refinement core PRISM adopt 3d Point Cloud Language Model 3d PC LLM to mitigate occlusion viewpoint bias ensure more stable spatially consistent preference signal additionally PRISM leverage chain Thought CoT reasoning to incorporate long horizon consideration thereby prevent short sighted feedback often see static preference comparison contrast conventional PBRL technique integration 3d perception future orient reasoning lead significant gain preference agreement rate fast policy convergence robust generalization unseen robotic environment empirical result span task such robotic manipulation autonomous navigation highlight PRISM 's potential real world application where precise spatial understanding reliable long term decision making be critical bridge 3d geometric awareness CoT drive preference modeling PRISM establish comprehensive foundation scalable human aligned reinforcement learning,"Yirong Sun, Yanjun Chen",13/03/2025,Computation and Language
10.48550./arXiv.2503.10167,well keep thinking enhance LLM Reasoning Adaptive Injection Decoding,large language model LLMs exhibit strong reasoning ability often attribute few shot zero shot chain thought CoT prompt effective method require labor intensive prompt engineering raise question reasoning can be induce reliance explicit prompt work unlock reasoning capability LLMs explicit prompting inspire zero shot CoT CoT decode propose novel decode strategy that systematically nudge LLMs to continue reasoning thereby prevent immature reasoning process specifically monitor model 's generation inject designate phrase whenever be likely to conclude response prematurely complete reasoning process experimental evaluation diverse reasoning benchmark demonstrate propose strategy substantially improve LLM reasoning capability highlight potential decode base intervention alternative traditional prompt technique,"Hyunbin Jin, Je Won Yeom, Seunghyun Bae, Taesup Kim",13/03/2025,Computation and Language
10.48550./arXiv.2503.10150,Retrieval Augmented Generation Hierarchical Knowledge,Graph base Retrieval Augmented Generation RAG method have significantly enhance performance large language model LLMs domain specific task however exist RAG method do not adequately utilize naturally inherent hierarchical knowledge human cognition which limit capability RAG system paper introduce new RAG approach call HiRAG which utilize hierarchical knowledge to enhance semantic understanding structure capture capability RAG system indexing retrieval process extensive experiment demonstrate hirag achieve significant performance improvement state art baseline method code propose method be available https https url,"Haoyu Huang, Yongfeng Huang, Junjie Yang, Zhenyu Pan, Yongqiang Chen, Kaili Ma, Hongzhi Chen, James Cheng",13/03/2025,Computation and Language
10.48550./arXiv.2503.10135,gumiho Hybrid Architecture prioritize early Tokens Speculative Decoding,speculative decode SPD aim to accelerate auto regressive token generation process target Large Language Model LLM approach employ draft model multiple head to predict sequence future token where head handle token sequence target LLM verify predict sequence accept aligned token enable efficient multi token generation however exist method assume token sequence be equally important employ identical head structure rely single generation paradigm serial parallel end theoretically demonstrate initial token draft sequence be more important later one build insight propose Gumiho hybrid model combine serial parallel head specifically give critical importance early token employ sophisticated Transformer architecture early draft head serial configuration to improve accuracy later token utilize multiple lightweight MLP head operate parallel to enhance efficiency allocate more advanced model structure long run time early head Gumiho achieves improve overall performance experimental result demonstrate method outperform exist approach fully validate effectiveness,"Jinze Li, Yixing Xu, Haiduo Huang, Xuanwu Yin, Dong Li, Edith C.H. Ngai, Emad Barsoum",13/03/2025,Computation and Language
10.48550./arXiv.2503.10095,cognitive Mental LLM leverage reasoning large Language Models Mental Health Prediction Online text,large Language Models LLMs have demonstrate potential predict mental health outcome online text traditional classification method often lack interpretability robustness study evaluate structured reasoning technique chain Thought CoT Self Consistency SC CoT tree Thought ToT)-to improve classification accuracy multiple mental health dataset source Reddit analyze reasoning drive prompting strategy include Zero shoot cot few shoot CoT use key performance metric such Balanced Accuracy F1 score sensitivity Specificity finding indicate reasoning enhance technique improve classification performance direct prediction particularly complex case compare baseline such Zero Shot non cot prompting fine tuned pre train transformer such BERT Mental RoBerta fine tune Open Source llm such Mental Alpaca Mental Flan T5 reasoning drive LLMs yield notable gain dataset Dreaddit +0.52\% M LLM +0.82\% BERT SDCNL +4.67\% M LLM +2.17\% BERT however performance decline Depression Severity CSSRS prediction suggest dataset specific limitation likely use more extensive test set prompt strategy few shoot CoT consistently outperform other reinforce effectiveness reasoning drive llm nonetheless dataset variability highlight challenge model reliability interpretability study provide comprehensive benchmark reasoning base LLM technique mental health text classification offer insight potential scalable clinical application identify key challenge future improvement,"Avinash Patil, Amardeep Kour Gedhu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10093,representation base Reward Modeling Efficient Safety Alignment Large Language Model,Reinforcement Learning RL algorithm safety alignment Large Language Models LLMs such Direct Preference Optimization DPO encounter challenge distribution shift current approach typically address issue online sampling target policy which require significant computational resource paper hypothesize policy training ranking order output generate policy change overall distribution remain relatively stable stability allow transformation sampling process target policy re rank preference datum build hypothesis propose new framework that leverage model 's intrinsic safety judgment capability to extract reward signal which be then use to calculate label confidence preference reorder extensive experimental result theoretical analysis demonstrate propose method effectively address distribution shift issue remarkably enhance safety performance reduce 300x computational overhead,"Qiyuan Deng, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang",13/03/2025,Computation and Language
10.48550./arXiv.2503.10084,why do cot Prompt not work theoretical Analysis Prompt Space Complexity Interaction Answer Space CoT Reasoning llm Recurrent Perspective,remarkable success Large Language Models LLMs fundamental transformer architecture possess inherent theoretical limitation that restrict capability to handle reasoning task increase computational complexity chain Thought CoT prompting have emerge practical solution support several theoretical study however current CoT base method include tot got etc generally adopt one prompt fit strategy use fixed template e.g. think step step diverse reasoning task method force model to navigate extremely complex prompt space to identify effective reasoning path current prompt designing research be also heavily rely trial error rather theoretically inform guidance paper provide rigorous theoretical analysis complexity interplay two crucial space prompt space space potential prompt structure answer space space reasoning solution generate LLMs CoT reasoning demonstrate how reliance single universal prompt e.g. think step step can negatively impact theoretical computability LLMs illustrate prompt complexity directly influence structure effectiveness navigation answer space analysis highlight sometimes human supervision be critical efficiently navigate prompt space theoretically empirically show task specific prompt significantly outperform unsupervised prompt generation emphasize necessity thoughtful human guidance CoT prompt,"Xiang Zhang, Juntai Cao, Jiaqi Wei, Chenyu You, Dujian Ding",13/03/2025,Computation and Language
10.48550./arXiv.2503.10079,Information Density Principle MLLM Benchmarks,"emergence Multimodal Large Language Models MLLMs hundred benchmark have be develop to ensure reliability MLLMs downstream task however evaluation mechanism may not be reliable developer mllm question remain which benchmark to use test result meet requirement therefore propose critical principle Information Density which examine how much insight benchmark can provide development mllm characterize four key dimension 1 fallacy 2 difficulty 3 redundancy 4 diversity comprehensive analysis more 10,000 sample measure information density 19 MLLM benchmark experiment show use late benchmark testing can provide more insight compare previous one there be still room improvement information density hope principle can promote development application future MLLM benchmark project page https url","Chunyi Li, Xiaozhe Li, Zicheng Zhang, Yuan Tian, Ziheng Jia, Xiaohong Liu, Xiongkuo Min, Jia Wang, Haodong Duan, Kai Chen, Guangtao Zhai",13/03/2025,Computation and Language
10.48550./arXiv.2503.10023,use Context to improve Word segmentation,important step understand how child acquire language be study how infant learn word segmentation have be establish previous research that infant may use statistical regularity speech to learn word segmentation research Goldwater et al demonstrate incorporate context model improve ability to learn word segmentation implement two model unigram bigram model to examine how context can improve statistical word segmentation result be consistent hypothesis that bigram model outperform unigram model predict word segmentation extend work Goldwater et al also explore basic way to model how young child might use previously learn word to segment new utterance,"Stephanie Hu, Xiaolu Guo",13/03/2025,Computation and Language
10.48550./arXiv.2503.09958,take off Training Wheels Progressive In Context learning effective alignment,recent study have explore work mechanism In Context Learning ICL however mainly focus classification simple generation task limit broad application more complex generation task practice to address gap investigate impact demonstration token representation practical alignment task find transformer embed task function learn demonstration separator token representation which play important role generation prior response token prior response token be determine demonstration become http url finding propose efficient Progressive In Context Alignment PICA method consist two stage first few shot stage model generate several prior response token standard ICL concurrently extract ICL vector that store task function separator token representation follow zero shot stage ICL vector guide model to generate response far http url experiment demonstrate PICA not only surpass vanilla ICL also achieve comparable performance other alignment tuning method propose training free method reduce time cost e.g. 5.45 + improve alignment performance e.g. 6.57 + consequently work highlight application ICL alignment call deep understanding ICL complex generation code will be available https url,"Zhenyu Liu, Dongfang Li, Xinshuo Hu, Xinping Zhao, Yibin Chen, Baotian Hu, Min Zhang",13/03/2025,Computation and Language
10.48550./arXiv.2503.09927,develop evaluate AI Assisted Prediction Model Unplanned Intensive Care Admissions follow Elective Neurosurgery use Natural Language processing Electronic Healthcare Record System,"introduction timely care specialised neuro intensive therapy unit ITU reduce mortality hospital stay plan admission be safe unplanned one however post operative care decision remain subjective study use artificial intelligence AI specifically natural language processing NLP analyse electronic health record EHRs predict ITU admission elective surgery patient method study analyse EHRs elective neurosurgery patient University College London Hospital UCLH use NLP patient be categorise plan high dependency unit HDU ITU admission unplanned HDU ITU admission ward overnight recovery ONR Medical Concept Annotation Tool MedCAT be use to identify SNOMED ct concept clinical note then explore utility identify concept range AI algorithm train to predict ITU admission result CogStack medcat NLP model initially train hospital wide ehr undergo two refinement first datum patient Normal pressure Hydrocephalus NPH then datum Vestibular Schwannoma VS patient achieve concept detection F1 score 0.93 refined model be then use to extract concept EHR note 2,268 eligible neurosurgical patient integrate extract concept AI model include decision tree model neural time series model use simple decision tree model achieve recall 0.87 CI 0.82 0.91 ITU admission reduce proportion unplanned ITU case miss human expert 36 to 4 conclusion NLP model refine accuracy have prove efficiency extract relevant concept provide reliable basis predictive AI model to use clinically valid application","Julia Ive, Olatomiwa Olukoya, Jonathan P. Funnell, James Booker, Sze H M Lam, Ugan Reddy, Kawsar Noor, Richard JB Dobson, Astri M.V. Luoma, Hani J Marcus",13/03/2025,Computation and Language
10.48550./arXiv.2503.09896,Rule base Solution co reference Resolution Clinical text,objective aim study be to build effective co reference resolution system tailor biomedical domain material method experiment material use study be provide 2011 i2b2 Natural Language Processing Challenge 2011 i2b2 challenge involve coreference resolution medical document concept mention have be annotate clinical text mention co refer document be to be link coreference chain normally there be two way construct system to automatically discover co referent link one be to manually build rule co reference resolution other category approach be to use machine learn system to learn automatically training dataset then perform resolution task testing dataset result experiment show exist co reference resolution system be able to find co referent link rule base system perform well find majority co referent link system achieve 89.6 overall performance multiple medical dataset conclusion experiment result show manually craft rule base observation training datum be valid way to accomplish high performance coreference resolution task critical biomedical domain,"Ping Chen, David Hinote, Guoqing Chen",12/03/2025,Computation and Language
10.48550./arXiv.2503.09894,what be field Mapping Scientific Research Knowledge Graphs large Language model,"scientific literature 's exponential growth make increasingly challenge to navigate synthesize knowledge discipline large language model LLMs be powerful tool understand scientific text fail to capture detailed relationship large body work unstructured approach retrieval augmented generation can sift such corpora to recall relevant fact however when million fact influence answer unstructured approach become cost prohibitive structured representation offer natural complement enable systematic analysis whole corpus recent work enhance LLMs unstructured semistructured representation scientific concept to complement try extract structured representation use LLMs combine LLMs semantic understanding schema scientific concept prototype system that answer precise question literature whole schema apply scientific field extract concept use only 20 manually annotate abstract to demonstrate system extract concept 30,000 paper arxiv span astrophysic fluid dynamic evolutionary biology result database highlight emerge trend visualize knowledge graph offer new way to explore ever grow landscape scientific knowledge demo abby101 surveyor-0 HF Spaces code https url","Abhipsha Das, Nicholas Lourie, Siavash Golkar, Mariel Pettee",12/03/2025,Computation and Language
10.48550./arXiv.2503.09853,who be Screen implicit MBTI Gender Detection use Artificial Intelligence,"personalized technology psychological research precisely detect demographic feature personality trait digital interaction become ever more important work investigate implicit categorization infer personality gender variable directly linguistic pattern Telegram conversation datum conventional personality prediction technique mostly depend explicitly self report label refine Transformer base language model RoBERTa to capture complex linguistic cue indicative personality trait gender difference use dataset comprise 138,866 message 1,602 user annotate MBTI type 195,016 message 2,598 user annotate gender confidence level help to greatly raise model accuracy 86.16\% hence prove RoBERTa 's capacity to consistently identify implicit personality type conversational text datum result highlight usefulness transformer topology implicit personality gender classification hence stress efficiency stress important trade off accuracy coverage realistic conversational environment regard gender classification model obtain accuracy 74.4\% therefore capture gender specific language pattern personality dimension analysis show people introverted intuitive preference be especially more active text base interaction study emphasize practical issue balance accuracy data coverage Transformer base model show efficiency implicit personality gender prediction task conversational text","Kourosh Shahnazari, Seyed Moein Ayyoubzadeh",12/03/2025,Computation and Language
10.48550./arXiv.2503.09822,generative AI name Entity Recognition Low Resource Language Nepali,Generative Artificial Intelligence GenAI particularly large Language Models LLMs have significantly advance Natural Language Processing NLP task such Named Entity Recognition NER which involve identify entity person location organization name text llm be especially promise low resource language ability to learn limited datum however performance GenAI model Nepali low resource language have not be thoroughly evaluate paper investigate application state art llm Nepali NER conduct experiment various prompt technique to assess effectiveness result provide insight challenge opportunity use llm NER low resource setting offer valuable contribution advancement NLP research language Nepali,"Sameer Neupane (University of Memphis), Jeevan Chapagain (University of Memphis), Nobal B. Niraula (Nowa Lab), Diwa Koirala (Nowa Lab)",12/03/2025,Computation and Language
10.48550./arXiv.2503.09819,attention reveal More Tokens training Free Long Context reasoning Attention guide retrieval,large Language Models LLMs often exhibit substantially short effective context length claim capacity especially when handle complex reasoning task that require integrate information multiple part long context perform multi step reasoning chain Thought CoT prompting have show promise reduce task complexity empirical analysis reveal do not fully resolve limitation control experiment identify poor recall implicit fact primary cause failure which significantly hamper reasoning performance interestingly observe internal attention weight generate cot token can effectively ground implicit fact even when fact be not explicitly recall build insight propose novel training free algorithm Attrieval which leverage attention weight to retrieve relevant fact long context incorporate reasoning process additionally find select context token CoT token far improve performance result demonstrate Attrieval enhance long context reasoning capability notably synthetic real world QA dataset various model,"Yuwei Zhang, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang",12/03/2025,Computation and Language
10.48550./arXiv.2503.09790,Constrained Language Generation Discrete Diffusion model,constraint be critical text generation LLM output be often unreliable when come ensure generate output adhere user define instruction general safety guideline to address gap present Constrained Discrete Diffusion CDD novel method enforce constraint natural language integrate discrete diffusion model differentiable optimization conventional text generator which often rely post hoc filtering model retrain controllable generation propose impose constraint directly discrete diffusion sampling process illustrate how technique can be apply to satisfy variety natural language constraint include i toxicity mitigation prevent harmful content emerge ii character sequence level lexical constraint iii novel molecule sequence generation specific property adherence experimental result show constraint aware procedure achieve high fidelity meet requirement preserve fluency semantic coherence outperform auto regressive exist discrete diffusion approach,"Michael Cardei, Jacob K Christopher, Thomas Hartvigsen, Brian R. Bartoldson, Bhavya Kailkhura, Ferdinando Fioretto",12/03/2025,Computation and Language
10.48550./arXiv.2503.09774,Efficient Multi Task Inferencing Model Merging Gromov Wasserstein Feature Alignment,automatic scoring student response enhance efficiency education deploy separate neural network task increase storage demand maintenance effort redundant computation to address challenge paper introduce Gromov Wasserstein Scoring Model Merging GW SMM method which merge model base feature distribution similarity measure Gromov Wasserstein distance approach begin extract feature student response use individual model capture item specific context unique learn representation Gromov Wasserstein distance then quantify similarity feature distribution identify most compatible model merge model exhibit small pairwise distance typically pair trio be merge combine only share layer precede classification head strategy result unified feature extractor preserve separate classification head item specific scoring validate approach human expert knowledge GPT o1 base merging method GW SMM consistently outperform achieve high micro F1 score macro f1 score exact match accuracy label accuracy improvement micro F1 label accuracy be statistically significant compare GPT o1 base merging p=0.04 p=0.01 additionally GW SMM reduce storage requirement half compromise much accuracy demonstrate computational efficiency reliable scoring performance,"Luyang Fang, Ehsan Latif, Haoran Lu, Yifan Zhou, Ping Ma, Xiaoming Zhai",12/03/2025,Computation and Language
10.48550./arXiv.2503.09743,Review GIDE Restaurant Review Gastrointestinal Illness Detection Extraction large Language model,foodborne gastrointestinal GI illness be common cause ill health UK however many case do not interact healthcare system pose significant challenge traditional surveillance method growth publicly available online restaurant review advancement large language model LLMs present potential opportunity to extend disease surveillance identify public report GI illness study introduce novel annotation schema develop expert GI illness apply Yelp Open Dataset review annotation extend binary disease detection to include detailed extraction information symptom food evaluate performance open weight llm three task GI illness detection symptom extraction food extraction compare performance roberta base classification model fine tune specifically task result show use prompt base approach LLMs achieve micro f1 score 90 three task use prompt alone achieve micro f1 score that exceed small fine tune model far demonstrate robustness LLMs GI illness detection three bias focus experiment result suggest publicly available review text llm offer substantial potential public health surveillance GI illness enable highly effective extraction key information LLMs appear to exhibit minimal bias processing inherent limitation restaurant review datum highlight need cautious interpretation result,"Timothy Laurence, Joshua Harris, Leo Loman, Amy Douglas, Yung-Wai Chan, Luke Hounsome, Lesley Larkin, Michael Borowitz",12/03/2025,Computation and Language
10.48550./arXiv.2503.09701,have LLMs make Active Learning Obsolete survey NLP Community,supervised learning rely annotated datum which be expensive to obtain longstanding strategy to reduce annotation cost be active learning iterative process which human annotate only datum instance deem informative model large language model LLMs have push effectiveness active learning have also improve method such few- zero shot learning text synthesis thereby introduce potential alternative raise question have active learning become obsolete to answer fully must look literature practical experience conduct online survey NLP community to collect previously intangible insight perceive relevance datum annotation particularly focus active learning include good practice obstacle expect future development finding show annotate datum remain key factor active learning continue to be relevant majority active learning user find effective comparison community survey decade ago reveal persistent challenge setup complexity estimation cost reduction tooling publish anonymize version collect dataset,"Julia Romberg, Christopher Schröder, Julius Gonsior, Katrin Tomanek, Fredrik Olsson",12/03/2025,Computation and Language
10.48550./arXiv.2503.09674,probabilistic Reasoning LLMs k anonymity Estimation,probabilistic reasoning be key aspect human artificial intelligence that allow handle uncertainty ambiguity decision making paper introduce novel numerical reasoning task uncertainty focus estimate k anonymity user generate document contain privacy sensitive information propose BRANCH which use llm to factorize joint probability distribution to estimate k value size population match give information model individual piece textual information random variable probability factor occur population be estimate use standalone llm retrieval augment generation system probability be combine final k value experiment show method successfully estimate correct k value 67 time 11 increase compare GPT-4o chain thought reasoning additionally leverage LLM uncertainty to develop prediction interval k anonymity which include correct value nearly 92 case,"Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu",12/03/2025,Computation and Language
10.48550./arXiv.2503.10633,chart Navigating Hugging Face 's Model Atlas,there be now million publicly available neural network search analyze large model repository become increasingly important navigate so many model require atlas most model be poorly document chart such atlas be challenge to explore hide potential model repository chart preliminary atla represent document fraction Hugging Face provide stunning visualization model landscape evolution demonstrate several application atla include predict model attribute e.g. accuracy analyze trend computer vision model however current atla remain incomplete propose method chart undocumented region specifically identify high confidence structural prior base dominant real world model training practice leverage prior approach enable accurate mapping previously undocumented area atla publicly release dataset code interactive atla,"Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, Yedid Hoshen",13/03/2025,Computation and Language
10.48550./arXiv.2503.10627,SciVerse unveil Knowledge Comprehension visual Reasoning lmm multi modal Scientific Problems,"rapid advancement large multi modal Models LMMs have enable application scientific problem solve fine grain capability remain under explore paper introduce SciVerse multi modal scientific evaluation benchmark to thoroughly assess lmm 5,735 test instance five distinct version aim to investigate three key dimension LMMs scientific knowledge comprehension multi modal content interpretation chain Thought CoT reasoning to unveil lmm possess sufficient scientific expertise first transform problem three version contain different level knowledge require solve i.e. Knowledge free -lite -rich then to explore how LMMs interpret multi modal scientific content annotate two version i.e. Vision rich -only mark more question information text diagram compare result different version SciVerse systematically examine professional knowledge stock visual perception skill lmm scientific domain addition to rigorously assess cot reasoning propose new scientific cot evaluation strategy conduct step wise assessment knowledge logical error model output extensive evaluation different lmm SciVerse reveal critical limitation scientific proficiency provide new insight future development project page https url","Ziyu Guo, Ray Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng",13/03/2025,Computation and Language
10.48550./arXiv.2503.10622,transformer normalization,normalization layer be ubiquitous modern neural network have long be consider essential work demonstrate Transformers normalization can achieve same well performance use remarkably simple technique introduce Dynamic Tanh DyT element wise operation $ DyT($x$ = \tanh(\alpha $ x$)$ drop in replacement normalization layer Transformers DyT be inspire observation layer normalization Transformers often produce tanh like $ s$-shape input output mapping incorporate dyt Transformers normalization can match exceed performance normalize counterpart mostly hyperparameter tuning validate effectiveness Transformers dyt diverse setting range recognition generation supervise self supervise learning computer vision language model finding challenge conventional understanding normalization layer be indispensable modern neural network offer new insight role deep network,"Jiachen Zhu, Xinlei Chen, Kaiming He, Yann LeCun, Zhuang Liu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10619,siege Autonomous Multi turn Jailbreaking Large Language Models Tree Search,introduce Siege multi turn adversarial framework that model gradual erosion Large Language Model LLM safety tree search perspective single turn jailbreak that rely one meticulously engineer prompt Siege expand conversation turn breadth first fashion branch out multiple adversarial prompt that exploit partial compliance previous response track incremental policy leak re inject subsequent query Siege reveal how minor concession can accumulate fully disallow output evaluation JailbreakBench dataset show Siege achieve 100 success rate gpt-3.5 turbo 97 GPT-4 single multi turn run use few query baseline such Crescendo GOAT tree search methodology offer depth view how model safeguard degrade successive dialogue turn underscore urgency robust multi turn testing procedure language model,Andy Zhou,13/03/2025,Computation and Language
10.48550./arXiv.2503.10602,TruthPrInt mitigate lvlm Object Hallucination Via Latent Truthful Guided Pre intervention,Object Hallucination OH have be acknowledge one major trustworthy challenge large Vision Language Models lvlm recent advancement Large Language Models LLMs indicate internal state such hide state encode overall truthfulness generate response however remain under explore how internal state LVLMs function could serve token hallucination indicator which be essential mitigate OH paper first conduct depth exploration LVLM internal state relation OH issue discover 1 LVLM internal state be high specificity token indicator hallucination behavior moreover 2 different lvlm encode universal pattern hallucination common latent subspace indicate there exist generic truthful direction share various lvlm base discovery propose Truthful Guided Pre Intervention TruthPrInt first learn truthful direction lvlm decode then apply truthful guide inference time intervention LVLM decode far propose ComnHallu to enhance cross lvlm cross data hallucination detection transferability construct align hallucination latent subspace evaluate truthprint extensive experimental setting include domain domain scenario popular lvlm OH benchmark experimental result indicate truthprint significantly outperform state art method code will be available https url,"Jinhao Duan, Fei Kong, Hao Cheng, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu",13/03/2025,Computation and Language
10.48550./arXiv.2503.10582,visualwebinstruct scale up Multimodal Instruction Data web search,"Vision Language Models have make significant progress many perception focus task however progress reasoning focus task seem to be limit lack high quality diverse training datum work aim to address scarcity issue reasoning focus multimodal dataset propose VisualWebInstruct novel approach that leverage search engine to create diverse high quality dataset span multiple discipline math physics finance chemistry etc start meticulously select 30,000 seed image employ Google Image search to identify website contain similar image collect process html 700 k unique url source pipeline content extraction filtering synthesis build dataset approximately 900 k question answer pair 40 be visual QA pair rest text QA pair model fine tune visualwebinstruct demonstrate significant performance gain 1 training Llava OV mid show 10 20 absolute point gain benchmark 2 training MAmmoTH vl show 5 absoluate gain good model mammoth vl2 show state art performance 10b parameter class mmmu pro std 40.7 MathVerse 42.6 DynaMath 55.7 remarkable result highlight effectiveness dataset enhance VLMs reasoning capability complex multimodal task","Yiming Jia, Jiachen Li, Xiang Yue, Bo Li, Ping Nie, Kai Zou, Wenhu Chen",13/03/2025,Computation and Language
10.48550./arXiv.2503.10542,language model Graph Searching Supervision Adulteration when More Supervision be Less how to make more More,work concern path star task minimal example search graph graph $ g$ be star shape $ d$ arm radiating start node $ s$. language model LM be give $ g$ $ s$ target node $ t$ which end one arm be task generate arm contain $ t$. minimal nature task mean only single choice need to be make which $ d$ arm contain $ t$ Decoder only lm fail to solve elementary task $ 1 d$ chance learn shortcut that absorb train supervision show how pathology be cause excess supervision present series solution demonstrate task be solvable decoder only lm find task 's minimal nature cause difficulty prevent task decomposition solution provide insight pathology implication LMs train next token prediction,Arvid Frydenlund,13/03/2025,Computation and Language
